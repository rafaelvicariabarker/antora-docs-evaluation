{"version":3,"sources":["00-nav.js","01-header.js","03-page-versions.js","04-mobile-navbar.js","05-highlight.js","06-clipboard.js","07-on-this-page.js","08-lunr.js","09-search.js"],"names":["expandParents","element","panel","parentNode","matches","parentHeader","previousElementSibling","classList","remove","querySelector","add","Array","from","document","querySelectorAll","pop","select","versionVar","versions","getVersions","Object","entries","forEach","component","componentName","componentVersionIndex","componentSelectVersion","selectedIndex","setComponentVersion","options","value","i","length","getAttribute","setVersions","window","sessionStorage","setItem","JSON","stringify","parse","getItem","version","showSelector","hideSelector","navShow","s","addEventListener","event","this","versionIndex","disabled","x","mdc","ripple","MDCRipple","attachTo","target","item","parentElement","nextElementSibling","contains","navToggle","getElementById","iconButton","MDCIconButtonToggle","mainContainer","navContainer","topAppBar","MDCTopAppBar","toggle","selector","e","stopPropagation","documentElement","innerWidth","navbarToggles","prototype","slice","call","el","dataset","hljs","initHighlighting","codeBlocks","copyIcon","createElement","innerText","icon","cloneNode","insertBefore","childNodes","ClipboardJS","text","lines","split","splice","join","on","trigger","_tippy","setContent","tippy","delegate","content","animation","theme","delay","placement","hideOnClick","onHidden","instance","headers","toc","header","li","tagName","setAttribute","h","id","scroll","top","offsetTop","left","behavior","setTimeout","appendChild","referenceElement","activeHeader","lastActiveHeader","referencePoint","getBoundingClientRect","activeId","global","step2list","step3list","v","C","re_mgr0","re_mgr1","re_meq1","re_s_v","re_1a","re2_1a","re_1b","re2_1b","re_1b_2","re2_1b_2","re3_1b_2","re4_1b_2","re_1c","re_2","re_3","re_4","re2_4","re_5","re_5_1","re3_5","root","factory","lunr","config","builder","Builder","pipeline","trimmer","stopWordFilter","stemmer","searchPipeline","build","porterStemmer","w","stem","suffix","firstch","re","re2","re3","re4","substr","toUpperCase","test","replace","fp","exec","toLowerCase","utils","warn","message","console","asString","obj","toString","clone","create","keys","key","val","isArray","TypeError","FieldRef","docRef","fieldName","stringValue","_stringValue","joiner","fromString","n","indexOf","fieldRef","undefined","Set","elements","complete","intersect","other","union","empty","object","a","b","intersection","push","concat","idf","posting","documentCount","documentsWithTerm","Math","log","abs","Token","str","metadata","update","fn","tokenizer","map","t","trim","len","tokens","sliceEnd","sliceStart","sliceLength","charAt","match","separator","tokenMetadata","Pipeline","_stack","registeredFunctions","registerFunction","label","warnIfFunctionNotRegistered","load","serialised","fnName","Error","arguments","after","existingFn","newFn","pos","before","run","stackLength","memo","j","result","k","runString","token","reset","toJSON","Vector","_magnitude","positionForIndex","index","start","end","pivotPoint","floor","pivotIndex","insert","insertIdx","upsert","position","magnitude","sumOfSquares","elementsLength","sqrt","dot","otherVector","dotProduct","aLen","bLen","aVal","bVal","similarity","toArray","output","ational","tional","enci","anci","izer","bli","alli","entli","eli","ousli","ization","ation","ator","alism","iveness","fulness","ousness","aliti","iviti","biliti","logi","icate","ative","alize","iciti","ical","ful","ness","c","RegExp","generateStopWordFilter","stopWords","words","reduce","stopWord","TokenSet","final","edges","_nextId","fromArray","arr","finish","fromClause","clause","fromFuzzyString","term","editDistance","stack","node","editsRemaining","noEditNode","char","deletionNode","frame","substitutionNode","insertionNode","transposeNode","charA","charB","next","prefix","edge","_str","labels","sort","qNode","qEdges","qLen","nEdges","nLen","q","qEdge","nEdge","previousWord","uncheckedNodes","minimizedNodes","word","commonPrefix","minimize","child","nextNode","parent","downTo","childKey","Index","attrs","invertedIndex","fieldVectors","tokenSet","fields","search","queryString","query","QueryParser","Query","matchingFields","queryVectors","termFieldCache","requiredMatches","prohibitedMatches","clauses","terms","clauseMatches","usePipeline","m","termTokenSet","expandedTerms","presence","REQUIRED","field","expandedTerm","termIndex","_index","fieldPosting","matchingDocumentRefs","termField","matchingDocumentsSet","PROHIBITED","boost","l","fieldMatch","matchingDocumentRef","matchingFieldRef","MatchData","allRequiredMatches","allProhibitedMatches","matchingFieldRefs","results","isNegated","docMatch","fieldVector","score","matchData","combine","ref","serializedIndex","serializedVectors","serializedInvertedIndex","tokenSetBuilder","tuple","_ref","_fields","_documents","fieldTermFrequencies","fieldLengths","_b","_k1","metadataWhitelist","attributes","RangeError","number","k1","doc","extractor","fieldTerms","metadataKey","calculateAverageFieldLengths","fieldRefs","numberOfFields","accumulator","documentsWithField","averageFieldLength","createFieldVectors","fieldRefsLength","termIdfCache","fieldLength","termFrequencies","termsLength","fieldBoost","docBoost","scoreWithPrecision","tf","round","createTokenSet","use","args","unshift","apply","clonedMetadata","metadataKeys","otherMatchData","allFields","wildcard","String","NONE","LEADING","TRAILING","OPTIONAL","QueryParseError","name","QueryLexer","lexemes","escapeCharPositions","state","lexText","sliceString","subSlices","emit","type","escapeCharacter","EOS","width","ignore","backup","acceptDigitRun","charCode","charCodeAt","more","FIELD","TERM","EDIT_DISTANCE","BOOST","PRESENCE","lexField","lexer","lexTerm","lexEditDistance","lexBoost","lexEOS","termSeparator","currentClause","lexemeIdx","parseClause","peekLexeme","consumeLexeme","lexeme","nextClause","completedClause","parser","parsePresence","parseField","parseTerm","errorMessage","nextLexeme","possibleFields","f","parseEditDistance","parseBoost","parseInt","isNaN","define","amd","exports","module","searchButton","searchCancelButton","searchClearButton","clearSearch","searchInput","dispatchEvent","KeyboardEvent","enterOrSpacebarPressed","code","keyCode","which","toggleSearch","searchResult","toolbarContainer","regularTopBar","searchTopBar","antoraLunr","body","highlightText","hits","highlightSpan","textEnd","contextAfter","contextBefore","createTextNode","highlightTitle","hash","title","titles","filter","titleEnd","createSearchResult","store","searchResultDataset","url","includes","substring","positions","highlightHit","documentTitle","documentHit","documentHitLink","href","hit","searchResultItem","createSearchResultItem","searchIndex","firstChild","removeChild","createNoResult","init","data","func","wait","immediate","timeout","assign","context","callNow","clearTimeout"],"mappings":"CAAA,WACA,cAMA,SAAAA,EAAAC,GACA,IAAAC,EAAAD,EAAAE,WACA,IAAAD,EAAAE,QAAA,uBACA,OAEA,IAAAC,EAAAH,EAAAI,uBACAJ,EAAAK,UAAAC,OAAA,QACAH,EAAAI,cAAA,mBAAAF,UAAAG,IAAA,YACAV,EAAAK,GAVAL,CADAW,MAAAC,KAAAC,SAAAC,iBAAA,qBAAAC,MAAAZ,YAeA,IAAAa,EAAAH,SAAAC,iBAAA,mBACAG,EAAA,oBACAC,EAAAC,IAEA,GAAAD,EAOAE,OAAAC,QAAAH,GAAAI,QAAA,SAAAC,GACA,IAAAC,EAAAD,EAAA,GACAE,EAAAF,EAAA,GACAG,EAAAb,SAAAJ,cAAA,0BAAAe,EAAA,MACAE,EAAAC,cAAAF,EAEAG,EAAAJ,EADAE,EAAAG,QAAAJ,GAAAK,aAZA,CACAZ,EAAA,GACA,IAAA,IAAAa,EAAA,EAAAA,EAAAf,EAAAgB,OAAAD,IACAb,EAAAF,EAAAe,GAAAE,aAAA,mBAAA,EAEAC,EAAAhB,GAYA,SAAAgB,EAAAhB,GACA,OAAAiB,OAAAC,eAAAC,QAAApB,EAAAqB,KAAAC,UAAArB,IAGA,SAAAC,IACA,OAAAmB,KAAAE,MAAAL,OAAAC,eAAAK,QAAAxB,IAGA,SAAAW,EAAAL,EAAAmB,GACA,IAAAC,EAAA,sCAAApB,EAAA,oBAAAmB,EAAA,KACAE,EAAA,sCAAArB,EAAA,gBACAsB,EAAAhC,SAAAJ,cAAAkC,GACA9B,SAAAJ,cAAAmC,GACArC,UAAAG,IAAA,QACAmC,EAAAtC,UAAAC,OAAA,QAGA,IAAAuB,EAAA,EAAAA,EAAAf,EAAAgB,OAAAD,IAAA,CACA,IAAAe,EAAA9B,EAAAe,GACAe,EAAAC,iBAAA,SAAA,SAAAC,GACA,IAAAzB,EAAA0B,KAAAhB,aAAA,kBACAiB,EAAAD,KAAAtB,cACAe,EAAAO,KAAApB,QAAAqB,GAAApB,MACAZ,EAAAC,IACAD,EAAAK,GAAA2B,EACAhB,EAAAhB,GACAU,EAAAL,EAAAmB,KAIA,IAAAI,EAAAjB,QAAAG,SACAc,EAAAvC,UAAAG,IAAA,kBACAoC,EAAAK,UAAA,GAMA,IAAAC,EAAAvC,SAAAC,iBAAA,8DACA,IAAAiB,EAAA,EAAAA,EAAAqB,EAAApB,OAAAD,IACAsB,IAAAC,OAAAC,UAAAC,SAAAJ,EAAArB,IACAqB,EAAArB,GAAAgB,iBAAA,QAAA,SAAAC,GACA,IAAAS,EAAAT,EAAAS,OACAC,EAAAD,EAAArD,QAAA,QAAAqD,EAAAnD,uBAAAmD,EACAvD,EAAAwD,EAAAC,cAAAC,mBACAF,EAAAnD,UAAAsD,SAAA,aACAH,EAAAnD,UAAAC,OAAA,YACAN,EAAAK,UAAAG,IAAA,UAEAgD,EAAAnD,UAAAG,IAAA,YACAR,EAAAK,UAAAC,OAAA,WAMA,IAAAsD,EAAAjD,SAAAkD,eAAA,sBACAV,IAAAW,WAAAC,oBAAAT,SAAAM,GACAA,EAAAf,iBAAA,QAAA,WAEA,IAAAmB,EAAArD,SAAAJ,cAAA,QACA0D,EAAAtD,SAAAJ,cAAA,qBACA0D,EAAA5D,UAAAsD,SAAA,SACAK,EAAA3D,UAAAG,IAAA,QACAyD,EAAA5D,UAAAC,OAAA,UAGA0D,EAAA3D,UAAAC,OAAA,QACA2D,EAAA5D,UAAAG,IAAA,WA5GA,GCAA2C,IAAAe,UAAAC,aAAAb,SAAA3C,SAAAJ,cAAA,qBCAA,WACA,aAEA,IAAA6D,EAAAzD,SAAAJ,cAAA,uCACA,GAAA6D,EAAA,CAEA,IAAAC,EAAA1D,SAAAJ,cAAA,kBAEA6D,EAAAvB,iBAAA,QAAA,SAAAyB,GACAD,EAAAhE,UAAA+D,OAAA,aAEAE,EAAAC,oBAGA5D,SAAA6D,gBAAA3B,iBAAA,QAAA,WACAwB,EAAAhE,UAAAC,OAAA,gBAfA,GCAAK,SAAAkC,iBAAA,mBAAA,WAEAZ,OAAAwC,YAAA,MACA9D,SAAAJ,cAAA,qBACAF,UAAAG,IAAA,QAIA,IAAAkE,EAAAjE,MAAAkE,UAAAC,MAAAC,KAAAlE,SAAAC,iBAAA,kBAAA,GACA,IAAA8D,EAAA5C,QACA4C,EAAAtD,QAAA,SAAA0D,GACAA,EAAAjC,iBAAA,QAAA,SAAAyB,GACAA,EAAAC,kBACAO,EAAAzE,UAAA+D,OAAA,aACAzD,SAAAkD,eAAAiB,EAAAC,QAAAxB,QAAAlD,UAAA+D,OAAA,aACAzD,SAAA6D,gBAAAnE,UAAA+D,OAAA,4BAMAnC,OAAAY,iBAAA,SAAA,WAGA,GADAlC,SAAAJ,cAAA,iDACAF,UAAAsD,SAAA,QAAA,CAEA,IAAAK,EAAArD,SAAAJ,cAAA,QACAyD,EAAA3D,UAAAsD,SAAA,SACAK,EAAA3D,UAAAC,OAAA,QAIA,IAAA2D,EAAAtD,SAAAJ,cAAA,qBACA,KAAA0B,OAAAwC,YACAR,EAAA5D,UAAAsD,SAAA,SACAM,EAAA5D,UAAAC,OAAA,QAMA2B,OAAAwC,WAAA,OACAR,EAAA5D,UAAAsD,SAAA,SACAM,EAAA5D,UAAAG,IAAA,WCzCAwE,KAAAC,mBCFA,WACA,aAEA,IAAAC,EAAAvE,SAAAC,iBAAA,2BACAuE,EAAAxE,SAAAyE,cAAA,KACAD,EAAA9E,UAAA,gCACA8E,EAAAE,UAAA,YACA,IAAA,IAAAxD,EAAA,EAAAA,EAAAqD,EAAApD,OAAAD,IAAA,CACA,IAAAyD,EAAAH,EAAAI,WAAA,GACAL,EAAArD,GAAA2D,aAAAF,EAAAJ,EAAArD,GAAA4D,WAAA,IAIA,IAAAC,YAAA,iCAAA,CACAC,KAAA,SAAApC,GACA,IAAAqC,EAAArC,EAAAtD,WAAAoF,UAAAQ,MAAA,MAEA,OADAD,EAAAE,OAAA,EAAA,GACAF,EAAAG,KAAA,SAIAC,GAAA,UAAA,SAAA1B,GACAA,EAAA2B,QAAAC,OAAAC,WAAA,aAGAC,MAAAC,SAAA,0BAAA,CACA9C,OAAA,iCACA+C,QAAA,oBACAC,UAAA,aACAC,MAAA,YACAC,MAAA,CAAA,IAAA,GACAC,UAAA,SACAC,aAAA,EACAC,SAAA,SAAAC,GACAA,EAAAV,WAAA,wBAlCA,GCAA,WACA,aAKA,IAFA,IAAAW,EAAAnG,SAAAJ,cAAA,kBAAAK,iBAAA,0BACAmG,EAAApG,SAAAkD,eAAA,OACAhC,EAAA,EAAAA,EAAAiF,EAAAhF,OAAAD,IAAA,CACA,IAAAmF,EAAAF,EAAAjF,GACAoF,EAAAtG,SAAAyE,cAAA,MACA6B,EAAA5G,UAAAG,IAAA,YACAyG,EAAA5G,UAAAG,IAAAwG,EAAAE,SACAD,EAAA5B,UAAA2B,EAAA3B,UACA4B,EAAAE,aAAA,WAAAH,EAAAjF,aAAA,OACAkF,EAAApE,iBAAA,QAAA,WACA,IAAAuE,EAAAC,EAAAtE,KAAAhB,aAAA,YACAqF,EAAA,QAAAC,EAAA1G,SAAAkD,eAAAwD,GACA1G,SAAAJ,cAAA,MACA0B,OAAAqF,OAAA,CACAC,IAAAH,EAAAI,UAAA,GACAC,KAAA,EACAC,SAAA,WAEAN,EAAA/G,UAAAG,IAAA,iBACAmH,WAAA,WAAAP,EAAA/G,UAAAC,OAAA,kBAAA,OAEAyG,EAAAa,YAAAX,GAIA,IAAAY,EAAAlH,SAAAJ,cAAA,WAAAN,WACAgC,OAAAY,iBAAA,SAAA,WAGA,IAFA,IAAAiF,EAAAC,EAAApH,SAAAJ,cAAA,oBACAyH,EAAAH,EAAAL,UAAA,MACA3F,EAAAiF,EAAAhF,OAAA,EAAA,GAAAD,EAAAA,IAAA,CAEA,GADAiF,EAAAjF,GAAAoG,wBAAAV,IACAS,EAAA,CACA,IAAAE,EAAApB,EAAAjF,GAAAE,aAAA,MACA+F,EAAAnH,SAAAJ,cAAA,uBAAA2H,EAAA,MACA,OAKAJ,GAAAA,IAAAC,IACAD,EAAAzH,UAAAG,IAAA,UACAuH,GACAA,EAAA1H,UAAAC,OAAA,aA9CA,GCMA,WAiCA,IAoCA6H,EAw2BAC,EAwBAC,EAWAC,EACAC,EAQAC,EACAC,EACAC,EACAC,EAEAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EAEAC,EACAC,EAEAC,EAEAC,EACAC,EAEAC,EACAC,EACAC,EA64EAC,EAAAC,EA71GAC,EAAA,SAAAC,GACA,IAAAC,EAAA,IAAAF,EAAAG,QAaA,OAXAD,EAAAE,SAAA1J,IACAsJ,EAAAK,QACAL,EAAAM,eACAN,EAAAO,SAGAL,EAAAM,eAAA9J,IACAsJ,EAAAO,SAGAN,EAAAlF,KAAAmF,EAAAA,GACAA,EAAAO,SAo8BA,SAAAC,EAAAC,GACA,IAAAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EAEA,GAAAP,EAAA3I,OAAA,EAAA,OAAA2I,EAiBA,GAdA,MADAG,EAAAH,EAAAQ,OAAA,EAAA,MAEAR,EAAAG,EAAAM,cAAAT,EAAAQ,OAAA,IAKAH,EAAAjC,GADAgC,EAAAjC,GAGAuC,KAAAV,GAAAA,EAAAA,EAAAW,QAAAP,EAAA,QACAC,EAAAK,KAAAV,KAAAA,EAAAA,EAAAW,QAAAN,EAAA,SAIAA,EAAA/B,GADA8B,EAAA/B,GAEAqC,KAAAV,GAAA,CACA,IAAAY,EAAAR,EAAAS,KAAAb,IACAI,EAAArC,GACA2C,KAAAE,EAAA,MACAR,EAAA7B,EACAyB,EAAAA,EAAAW,QAAAP,EAAA,UAEA,GAAAC,EAAAK,KAAAV,GAAA,CAEAC,GADAW,EAAAP,EAAAQ,KAAAb,IACA,IACAK,EAAAnC,GACAwC,KAAAT,KAGAK,EAAA7B,EACA8B,EAAA7B,GAFA2B,EAAA7B,GAGAkC,KAJAV,EAAAC,GAIAD,GAAA,IACAM,EAAAI,KAAAV,IAAAI,EAAA7B,EAAAyB,EAAAA,EAAAW,QAAAP,EAAA,KACAG,EAAAG,KAAAV,KAAAA,GAAA,MAuCA,IAlCAI,EAAAzB,GACA+B,KAAAV,KAGAA,GADAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,IACA,MAIAI,EAAAxB,GACA8B,KAAAV,KAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,GACAE,EAAAU,EAAA,IACAR,EAAArC,GACA2C,KAAAT,KACAD,EAAAC,EAAAtC,EAAAuC,MAKAE,EAAAvB,GACA6B,KAAAV,KAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,GACAE,EAAAU,EAAA,IACAR,EAAArC,GACA2C,KAAAT,KACAD,EAAAC,EAAArC,EAAAsC,KAMAG,EAAAtB,GADAqB,EAAAtB,GAEA4B,KAAAV,GAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,IACAI,EAAApC,GACA0C,KAAAT,KACAD,EAAAC,QAEA,GAAAI,EAAAK,KAAAV,GAAA,CAEAC,GADAW,EAAAP,EAAAQ,KAAAb,IACA,GAAAY,EAAA,IACAP,EAAArC,GACA0C,KAAAT,KACAD,EAAAC,GA8BA,OAzBAG,EAAApB,GACA0B,KAAAV,KAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,GAEAK,EAAApC,EACAqC,EAAApB,IAFAkB,EAAApC,GAGA0C,KAAAT,IAAAI,EAAAK,KAAAT,KAAAK,EAAAI,KAAAT,MACAD,EAAAC,IAKAI,EAAArC,GADAoC,EAAAnB,GAEAyB,KAAAV,IAAAK,EAAAK,KAAAV,KACAI,EAAA7B,EACAyB,EAAAA,EAAAW,QAAAP,EAAA,KAKA,KAAAD,IACAH,EAAAG,EAAAW,cAAAd,EAAAQ,OAAA,IAGAR,EA9jCAX,EAAAtH,QAAA,QAUAsH,EAAA0B,MAAA,GASA1B,EAAA0B,MAAAC,MAAAtD,EAQApF,KANA,SAAA2I,GACAvD,EAAAwD,SAAAA,QAAAF,MACAE,QAAAF,KAAAC,KAiBA5B,EAAA0B,MAAAI,SAAA,SAAAC,GACA,OAAAA,MAAAA,EACA,GAEAA,EAAAC,YAoBAhC,EAAA0B,MAAAO,MAAA,SAAAF,GACA,GAAAA,MAAAA,EACA,OAAAA,EAMA,IAHA,IAAAE,EAAA7K,OAAA8K,OAAA,MACAC,EAAA/K,OAAA+K,KAAAJ,GAEAhK,EAAA,EAAAA,EAAAoK,EAAAnK,OAAAD,IAAA,CACA,IAAAqK,EAAAD,EAAApK,GACAsK,EAAAN,EAAAK,GAEA,GAAAzL,MAAA2L,QAAAD,GACAJ,EAAAG,GAAAC,EAAAvH,YADA,CAKA,GAAA,iBAAAuH,GACA,iBAAAA,GACA,kBAAAA,EAKA,MAAA,IAAAE,UAAA,yDAJAN,EAAAG,GAAAC,GAOA,OAAAJ,GAEAjC,EAAAwC,SAAA,SAAAC,EAAAC,EAAAC,GACA1J,KAAAwJ,OAAAA,EACAxJ,KAAAyJ,UAAAA,EACAzJ,KAAA2J,aAAAD,GAGA3C,EAAAwC,SAAAK,OAAA,IAEA7C,EAAAwC,SAAAM,WAAA,SAAAhK,GACA,IAAAiK,EAAAjK,EAAAkK,QAAAhD,EAAAwC,SAAAK,QAEA,IAAA,IAAAE,EACA,KAAA,6BAGA,IAAAE,EAAAnK,EAAAgC,MAAA,EAAAiI,GACAN,EAAA3J,EAAAgC,MAAAiI,EAAA,GAEA,OAAA,IAAA/C,EAAAwC,SAAAC,EAAAQ,EAAAnK,IAGAkH,EAAAwC,SAAA3H,UAAAmH,SAAA,WAKA,OAJAkB,MAAAjK,KAAA2J,eACA3J,KAAA2J,aAAA3J,KAAAyJ,UAAA1C,EAAAwC,SAAAK,OAAA5J,KAAAwJ,QAGAxJ,KAAA2J,cAYA5C,EAAAmD,IAAA,SAAAC,GAGA,GAFAnK,KAAAmK,SAAAhM,OAAA8K,OAAA,MAEAkB,EAAA,CACAnK,KAAAjB,OAAAoL,EAAApL,OAEA,IAAA,IAAAD,EAAA,EAAAA,EAAAkB,KAAAjB,OAAAD,IACAkB,KAAAmK,SAAAA,EAAArL,KAAA,OAGAkB,KAAAjB,OAAA,GAWAgI,EAAAmD,IAAAE,SAAA,CACAC,UAAA,SAAAC,GACA,OAAAA,GAGAC,MAAA,SAAAD,GACA,OAAAA,GAGA1J,SAAA,WACA,OAAA,IAWAmG,EAAAmD,IAAAM,MAAA,CACAH,UAAA,WACA,OAAArK,MAGAuK,MAAA,SAAAD,GACA,OAAAA,GAGA1J,SAAA,WACA,OAAA,IAUAmG,EAAAmD,IAAAtI,UAAAhB,SAAA,SAAA6J,GACA,QAAAzK,KAAAmK,SAAAM,IAWA1D,EAAAmD,IAAAtI,UAAAyI,UAAA,SAAAC,GACA,IAAAI,EAAAC,EAAAR,EAAAS,EAAA,GAEA,GAAAN,IAAAvD,EAAAmD,IAAAE,SACA,OAAApK,KAGA,GAAAsK,IAAAvD,EAAAmD,IAAAM,MACA,OAAAF,EAKAK,EAFA3K,KAAAjB,OAAAuL,EAAAvL,QACA2L,EAAA1K,KACAsK,IAEAI,EAAAJ,EACAtK,MAGAmK,EAAAhM,OAAA+K,KAAAwB,EAAAP,UAEA,IAAA,IAAArL,EAAA,EAAAA,EAAAqL,EAAApL,OAAAD,IAAA,CACA,IAAA9B,EAAAmN,EAAArL,GACA9B,KAAA2N,EAAAR,UACAS,EAAAC,KAAA7N,GAIA,OAAA,IAAA+J,EAAAmD,IAAAU,IAUA7D,EAAAmD,IAAAtI,UAAA2I,MAAA,SAAAD,GACA,OAAAA,IAAAvD,EAAAmD,IAAAE,SACArD,EAAAmD,IAAAE,SAGAE,IAAAvD,EAAAmD,IAAAM,MACAxK,KAGA,IAAA+G,EAAAmD,IAAA/L,OAAA+K,KAAAlJ,KAAAmK,UAAAW,OAAA3M,OAAA+K,KAAAoB,EAAAH,aAUApD,EAAAgE,IAAA,SAAAC,EAAAC,GACA,IAAAC,EAAA,EAEA,IAAA,IAAAzB,KAAAuB,EACA,UAAAvB,IACAyB,GAAA/M,OAAA+K,KAAA8B,EAAAvB,IAAA1K,QAGA,IAAAoB,GAAA8K,EAAAC,EAAA,KAAAA,EAAA,IAEA,OAAAC,KAAAC,IAAA,EAAAD,KAAAE,IAAAlL,KAWA4G,EAAAuE,MAAA,SAAAC,EAAAC,GACAxL,KAAAuL,IAAAA,GAAA,GACAvL,KAAAwL,SAAAA,GAAA,IAQAzE,EAAAuE,MAAA1J,UAAAmH,SAAA,WACA,OAAA/I,KAAAuL,KAuBAxE,EAAAuE,MAAA1J,UAAA6J,OAAA,SAAAC,GAEA,OADA1L,KAAAuL,IAAAG,EAAA1L,KAAAuL,IAAAvL,KAAAwL,UACAxL,MAUA+G,EAAAuE,MAAA1J,UAAAoH,MAAA,SAAA0C,GAEA,OADAA,EAAAA,GAAA,SAAA7L,GAAA,OAAAA,GACA,IAAAkH,EAAAuE,MAAAI,EAAA1L,KAAAuL,IAAAvL,KAAAwL,UAAAxL,KAAAwL,WAyBAzE,EAAA4E,UAAA,SAAA7C,EAAA0C,GACA,GAAA,MAAA1C,GAAAmB,MAAAnB,EACA,MAAA,GAGA,GAAApL,MAAA2L,QAAAP,GACA,OAAAA,EAAA8C,IAAA,SAAAC,GACA,OAAA,IAAA9E,EAAAuE,MACAvE,EAAA0B,MAAAI,SAAAgD,GAAArD,cACAzB,EAAA0B,MAAAO,MAAAwC,MASA,IAJA,IAAAD,EAAAzC,EAAAC,WAAA+C,OAAAtD,cACAuD,EAAAR,EAAAxM,OACAiN,EAAA,GAEAC,EAAA,EAAAC,EAAA,EAAAD,GAAAF,EAAAE,IAAA,CACA,IACAE,EAAAF,EAAAC,EAEA,GAHAX,EAAAa,OAAAH,GAGAI,MAAAtF,EAAA4E,UAAAW,YAAAL,GAAAF,EAAA,CAEA,GAAA,EAAAI,EAAA,CACA,IAAAI,EAAAxF,EAAA0B,MAAAO,MAAAwC,IAAA,GACAe,EAAA,SAAA,CAAAL,EAAAC,GACAI,EAAA,MAAAP,EAAAjN,OAEAiN,EAAAnB,KACA,IAAA9D,EAAAuE,MACAC,EAAA1J,MAAAqK,EAAAD,GACAM,IAKAL,EAAAD,EAAA,GAKA,OAAAD,GAUAjF,EAAA4E,UAAAW,UAAA,UAmCAvF,EAAAyF,SAAA,WACAxM,KAAAyM,OAAA,IAGA1F,EAAAyF,SAAAE,oBAAAvO,OAAA8K,OAAA,MAmCAlC,EAAAyF,SAAAG,iBAAA,SAAAjB,EAAAkB,GACAA,KAAA5M,KAAA0M,qBACA3F,EAAA0B,MAAAC,KAAA,6CAAAkE,GAGAlB,EAAAkB,MAAAA,EACA7F,EAAAyF,SAAAE,oBAAAhB,EAAAkB,OAAAlB,GASA3E,EAAAyF,SAAAK,4BAAA,SAAAnB,GACAA,EAAAkB,OAAAlB,EAAAkB,SAAA5M,KAAA0M,qBAGA3F,EAAA0B,MAAAC,KAAA,kGAAAgD,IAcA3E,EAAAyF,SAAAM,KAAA,SAAAC,GACA,IAAA5F,EAAA,IAAAJ,EAAAyF,SAYA,OAVAO,EAAA1O,QAAA,SAAA2O,GACA,IAAAtB,EAAA3E,EAAAyF,SAAAE,oBAAAM,GAEA,IAAAtB,EAGA,MAAA,IAAAuB,MAAA,sCAAAD,GAFA7F,EAAA1J,IAAAiO,KAMAvE,GAUAJ,EAAAyF,SAAA5K,UAAAnE,IAAA,WACAC,MAAAkE,UAAAC,MAAAC,KAAAoL,WAEA7O,QAAA,SAAAqN,GACA3E,EAAAyF,SAAAK,4BAAAnB,GACA1L,KAAAyM,OAAA5B,KAAAa,IACA1L,OAYA+G,EAAAyF,SAAA5K,UAAAuL,MAAA,SAAAC,EAAAC,GACAtG,EAAAyF,SAAAK,4BAAAQ,GAEA,IAAAC,EAAAtN,KAAAyM,OAAA1C,QAAAqD,GACA,IAAA,GAAAE,EACA,MAAA,IAAAL,MAAA,0BAGAK,GAAA,EACAtN,KAAAyM,OAAA1J,OAAAuK,EAAA,EAAAD,IAYAtG,EAAAyF,SAAA5K,UAAA2L,OAAA,SAAAH,EAAAC,GACAtG,EAAAyF,SAAAK,4BAAAQ,GAEA,IAAAC,EAAAtN,KAAAyM,OAAA1C,QAAAqD,GACA,IAAA,GAAAE,EACA,MAAA,IAAAL,MAAA,0BAGAjN,KAAAyM,OAAA1J,OAAAuK,EAAA,EAAAD,IAQAtG,EAAAyF,SAAA5K,UAAArE,OAAA,SAAAmO,GACA,IAAA4B,EAAAtN,KAAAyM,OAAA1C,QAAA2B,IACA,GAAA4B,GAIAtN,KAAAyM,OAAA1J,OAAAuK,EAAA,IAUAvG,EAAAyF,SAAA5K,UAAA4L,IAAA,SAAAxB,GAGA,IAFA,IAAAyB,EAAAzN,KAAAyM,OAAA1N,OAEAD,EAAA,EAAAA,EAAA2O,EAAA3O,IAAA,CAIA,IAHA,IAAA4M,EAAA1L,KAAAyM,OAAA3N,GACA4O,EAAA,GAEAC,EAAA,EAAAA,EAAA3B,EAAAjN,OAAA4O,IAAA,CACA,IAAAC,EAAAlC,EAAAM,EAAA2B,GAAAA,EAAA3B,GAEA,QAAA,IAAA4B,GAAA,KAAAA,EAEA,GAAAA,aAAAlQ,MACA,IAAA,IAAAmQ,EAAA,EAAAA,EAAAD,EAAA7O,OAAA8O,IACAH,EAAA7C,KAAA+C,EAAAC,SAGAH,EAAA7C,KAAA+C,GAIA5B,EAAA0B,EAGA,OAAA1B,GAaAjF,EAAAyF,SAAA5K,UAAAkM,UAAA,SAAAvC,EAAAC,GACA,IAAAuC,EAAA,IAAAhH,EAAAuE,MAAAC,EAAAC,GAEA,OAAAxL,KAAAwN,IAAA,CAAAO,IAAAnC,IAAA,SAAAC,GACA,OAAAA,EAAA9C,cAQAhC,EAAAyF,SAAA5K,UAAAoM,MAAA,WACAhO,KAAAyM,OAAA,IAUA1F,EAAAyF,SAAA5K,UAAAqM,OAAA,WACA,OAAAjO,KAAAyM,OAAAb,IAAA,SAAAF,GAGA,OAFA3E,EAAAyF,SAAAK,4BAAAnB,GAEAA,EAAAkB,SAwBA7F,EAAAmH,OAAA,SAAA/D,GACAnK,KAAAmO,WAAA,EACAnO,KAAAmK,SAAAA,GAAA,IAcApD,EAAAmH,OAAAtM,UAAAwM,iBAAA,SAAAC,GAEA,GAAA,GAAArO,KAAAmK,SAAApL,OACA,OAAA,EASA,IANA,IAAAuP,EAAA,EACAC,EAAAvO,KAAAmK,SAAApL,OAAA,EACAoN,EAAAoC,EAAAD,EACAE,EAAArD,KAAAsD,MAAAtC,EAAA,GACAuC,EAAA1O,KAAAmK,SAAA,EAAAqE,GAEA,EAAArC,IACAuC,EAAAL,IACAC,EAAAE,GAGAH,EAAAK,IACAH,EAAAC,GAGAE,GAAAL,IAIAlC,EAAAoC,EAAAD,EACAE,EAAAF,EAAAnD,KAAAsD,MAAAtC,EAAA,GACAuC,EAAA1O,KAAAmK,SAAA,EAAAqE,GAGA,OAAAE,GAAAL,GAIAA,EAAAK,EAHA,EAAAF,EAOAE,EAAAL,EACA,GAAAG,EAAA,QADA,GAcAzH,EAAAmH,OAAAtM,UAAA+M,OAAA,SAAAC,EAAAxF,GACApJ,KAAA6O,OAAAD,EAAAxF,EAAA,WACA,KAAA,qBAYArC,EAAAmH,OAAAtM,UAAAiN,OAAA,SAAAD,EAAAxF,EAAAsC,GACA1L,KAAAmO,WAAA,EACA,IAAAW,EAAA9O,KAAAoO,iBAAAQ,GAEA5O,KAAAmK,SAAA2E,IAAAF,EACA5O,KAAAmK,SAAA2E,EAAA,GAAApD,EAAA1L,KAAAmK,SAAA2E,EAAA,GAAA1F,GAEApJ,KAAAmK,SAAApH,OAAA+L,EAAA,EAAAF,EAAAxF,IASArC,EAAAmH,OAAAtM,UAAAmN,UAAA,WACA,GAAA/O,KAAAmO,WAAA,OAAAnO,KAAAmO,WAKA,IAHA,IAAAa,EAAA,EACAC,EAAAjP,KAAAmK,SAAApL,OAEAD,EAAA,EAAAA,EAAAmQ,EAAAnQ,GAAA,EAAA,CACA,IAAAsK,EAAApJ,KAAAmK,SAAArL,GACAkQ,GAAA5F,EAAAA,EAGA,OAAApJ,KAAAmO,WAAAhD,KAAA+D,KAAAF,IASAjI,EAAAmH,OAAAtM,UAAAuN,IAAA,SAAAC,GAOA,IANA,IAAAC,EAAA,EACA3E,EAAA1K,KAAAmK,SAAAQ,EAAAyE,EAAAjF,SACAmF,EAAA5E,EAAA3L,OAAAwQ,EAAA5E,EAAA5L,OACAyQ,EAAA,EAAAC,EAAA,EACA3Q,EAAA,EAAA6O,EAAA,EAEA7O,EAAAwQ,GAAA3B,EAAA4B,IACAC,EAAA9E,EAAA5L,KAAA2Q,EAAA9E,EAAAgD,IAEA7O,GAAA,EACA2Q,EAAAD,EACA7B,GAAA,EACA6B,GAAAC,IACAJ,GAAA3E,EAAA5L,EAAA,GAAA6L,EAAAgD,EAAA,GACA7O,GAAA,EACA6O,GAAA,GAIA,OAAA0B,GAUAtI,EAAAmH,OAAAtM,UAAA8N,WAAA,SAAAN,GACA,OAAApP,KAAAmP,IAAAC,GAAApP,KAAA+O,aAAA,GAQAhI,EAAAmH,OAAAtM,UAAA+N,QAAA,WAGA,IAFA,IAAAC,EAAA,IAAAlS,MAAAsC,KAAAmK,SAAApL,OAAA,GAEAD,EAAA,EAAA6O,EAAA,EAAA7O,EAAAkB,KAAAmK,SAAApL,OAAAD,GAAA,EAAA6O,IACAiC,EAAAjC,GAAA3N,KAAAmK,SAAArL,GAGA,OAAA8Q,GAQA7I,EAAAmH,OAAAtM,UAAAqM,OAAA,WACA,OAAAjO,KAAAmK,UAoBApD,EAAAO,SACAjC,EAAA,CACAwK,QAAA,MACAC,OAAA,OACAC,KAAA,OACAC,KAAA,OACAC,KAAA,MACAC,IAAA,MACAC,KAAA,KACAC,MAAA,MACAC,IAAA,IACAC,MAAA,MACAC,QAAA,MACAC,MAAA,MACAC,KAAA,MACAC,MAAA,KACAC,QAAA,MACAC,QAAA,MACAC,QAAA,MACAC,MAAA,KACAC,MAAA,MACAC,OAAA,MACAC,KAAA,OAGA3L,EAAA,CACA4L,MAAA,KACAC,MAAA,GACAC,MAAA,KACAC,MAAA,KACAC,KAAA,KACAC,IAAA,GACAC,KAAA,IAIAjM,EAAA,WACAC,EAAAiM,qBAQAhM,EAAA,IAAAiM,OALA,4DAMAhM,EAAA,IAAAgM,OAJA,8FAKA/L,EAAA,IAAA+L,OANA,gFAOA9L,EAAA,IAAA8L,OALA,kCAOA7L,EAAA,kBACAC,EAAA,iBACAC,EAAA,aACAC,EAAA,kBACAC,EAAA,KACAC,EAAA,cACAC,EAAA,IAAAuL,OAAA,sBACAtL,EAAA,IAAAsL,OAAA,IAAAlM,EAAAD,EAAA,gBAEAc,EAAA,mBACAC,EAAA,2IAEAC,EAAA,iDAEAC,EAAA,sFACAC,EAAA,oBAEAC,EAAA,WACAC,EAAA,MACAC,EAAA,IAAA8K,OAAA,IAAAlM,EAAAD,EAAA,gBAkIA,SAAAwI,GACA,OAAAA,EAAAtC,OAAAhE,KAIAV,EAAAyF,SAAAG,iBAAA5F,EAAAO,QAAA,WAmBAP,EAAA4K,uBAAA,SAAAC,GACA,IAAAC,EAAAD,EAAAE,OAAA,SAAApE,EAAAqE,GAEA,OADArE,EAAAqE,GAAAA,EACArE,GACA,IAEA,OAAA,SAAAK,GACA,GAAAA,GAAA8D,EAAA9D,EAAAhF,cAAAgF,EAAAhF,WAAA,OAAAgF,IAiBAhH,EAAAM,eAAAN,EAAA4K,uBAAA,CACA,IACA,OACA,QACA,SACA,QACA,MACA,SACA,OACA,KACA,QACA,KACA,MACA,MACA,MACA,KACA,KACA,KACA,UACA,OACA,MACA,KACA,MACA,SACA,QACA,OACA,MACA,KACA,OACA,SACA,OACA,OACA,QACA,MACA,OACA,MACA,MACA,MACA,MACA,OACA,KACA,MACA,OACA,MACA,MACA,MACA,UACA,IACA,KACA,KACA,OACA,KACA,KACA,MACA,OACA,QACA,MACA,OACA,SACA,MACA,KACA,QACA,OACA,OACA,KACA,UACA,KACA,MACA,MACA,KACA,MACA,QACA,KACA,OACA,KACA,QACA,MACA,MACA,SACA,OACA,MACA,OACA,MACA,SACA,QACA,KACA,OACA,OACA,OACA,MACA,QACA,OACA,OACA,QACA,QACA,OACA,OACA,MACA,KACA,MACA,OACA,KACA,QACA,MACA,KACA,OACA,OACA,OACA,QACA,QACA,QACA,MACA,OACA,MACA,OACA,OACA,QACA,MACA,MACA,SAGA5K,EAAAyF,SAAAG,iBAAA5F,EAAAM,eAAA,kBAqBAN,EAAAK,QAAA,SAAA2G,GACA,OAAAA,EAAAtC,OAAA,SAAA5L,GACA,OAAAA,EAAAwI,QAAA,OAAA,IAAAA,QAAA,OAAA,OAIAtB,EAAAyF,SAAAG,iBAAA5F,EAAAK,QAAA,WA2BAL,EAAAiL,SAAA,WACAhS,KAAAiS,OAAA,EACAjS,KAAAkS,MAAA,GACAlS,KAAAsE,GAAAyC,EAAAiL,SAAAG,QACApL,EAAAiL,SAAAG,SAAA,GAWApL,EAAAiL,SAAAG,QAAA,EASApL,EAAAiL,SAAAI,UAAA,SAAAC,GAGA,IAFA,IAAApL,EAAA,IAAAF,EAAAiL,SAAA9K,QAEApI,EAAA,EAAAiN,EAAAsG,EAAAtT,OAAAD,EAAAiN,EAAAjN,IACAmI,EAAA0H,OAAA0D,EAAAvT,IAIA,OADAmI,EAAAqL,SACArL,EAAAJ,MAYAE,EAAAiL,SAAAO,WAAA,SAAAC,GACA,MAAA,iBAAAA,EACAzL,EAAAiL,SAAAS,gBAAAD,EAAAE,KAAAF,EAAAG,cAEA5L,EAAAiL,SAAAnI,WAAA2I,EAAAE,OAmBA3L,EAAAiL,SAAAS,gBAAA,SAAAlH,EAAAoH,GASA,IARA,IAAA9L,EAAA,IAAAE,EAAAiL,SAEAY,EAAA,CAAA,CACAC,KAAAhM,EACAiM,eAAAH,EACApH,IAAAA,IAGAqH,EAAA7T,QAAA,CACA,IAKAgU,EAwBAC,EACAC,EA9BAC,EAAAN,EAAA9U,MAGA,GAAA,EAAAoV,EAAA3H,IAAAxM,QACAiU,EAAAE,EAAA3H,IAAAa,OAAA,MAGA8G,EAAAL,KAAAX,MACAa,EAAAG,EAAAL,KAAAX,MAAAc,IAEAD,EAAA,IAAAhM,EAAAiL,SACAkB,EAAAL,KAAAX,MAAAc,GAAAD,GAGA,GAAAG,EAAA3H,IAAAxM,OACAgU,EAAAd,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAE,EACAD,eAAAI,EAAAJ,eACAvH,IAAA2H,EAAA3H,IAAA1J,MAAA,KAQA,GAAA,EAAAqR,EAAAJ,gBAAA,EAAAI,EAAA3H,IAAAxM,QACAiU,EAAAE,EAAA3H,IAAAa,OAAA,MAGA8G,EAAAL,KAAAX,MACAe,EAAAC,EAAAL,KAAAX,MAAAc,IAEAC,EAAA,IAAAlM,EAAAiL,SACAkB,EAAAL,KAAAX,MAAAc,GAAAC,GAGAC,EAAA3H,IAAAxM,QAAA,EACAkU,EAAAhB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAI,EACAH,eAAAI,EAAAJ,eAAA,EACAvH,IAAA2H,EAAA3H,IAAA1J,MAAA,KAcA,GAPA,EAAAqR,EAAAJ,gBAAA,GAAAI,EAAA3H,IAAAxM,SACAmU,EAAAL,KAAAZ,OAAA,GAMA,EAAAiB,EAAAJ,gBAAA,GAAAI,EAAA3H,IAAAxM,OAAA,CACA,GAAA,MAAAmU,EAAAL,KAAAX,MACA,IAAAiB,EAAAD,EAAAL,KAAAX,MAAA,SACA,CACAiB,EAAA,IAAApM,EAAAiL,SACAkB,EAAAL,KAAAX,MAAA,KAAAiB,EAGA,GAAAD,EAAA3H,IAAAxM,OACAoU,EAAAlB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAM,EACAL,eAAAI,EAAAJ,eAAA,EACAvH,IAAA2H,EAAA3H,IAAA1J,MAAA,KAOA,GAAA,EAAAqR,EAAAJ,eAAA,CACA,GAAA,MAAAI,EAAAL,KAAAX,MACA,IAAAkB,EAAAF,EAAAL,KAAAX,MAAA,SACA,CACAkB,EAAA,IAAArM,EAAAiL,SACAkB,EAAAL,KAAAX,MAAA,KAAAkB,EAGA,GAAAF,EAAA3H,IAAAxM,OACAqU,EAAAnB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAO,EACAN,eAAAI,EAAAJ,eAAA,EACAvH,IAAA2H,EAAA3H,MAQA,GAAA,EAAA2H,EAAAJ,gBAAA,EAAAI,EAAA3H,IAAAxM,OAAA,CACA,IAEAsU,EAFAC,EAAAJ,EAAA3H,IAAAa,OAAA,GACAmH,EAAAL,EAAA3H,IAAAa,OAAA,GAGAmH,KAAAL,EAAAL,KAAAX,MACAmB,EAAAH,EAAAL,KAAAX,MAAAqB,IAEAF,EAAA,IAAAtM,EAAAiL,SACAkB,EAAAL,KAAAX,MAAAqB,GAAAF,GAGA,GAAAH,EAAA3H,IAAAxM,OACAsU,EAAApB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAQ,EACAP,eAAAI,EAAAJ,eAAA,EACAvH,IAAA+H,EAAAJ,EAAA3H,IAAA1J,MAAA,MAMA,OAAAgF,GAaAE,EAAAiL,SAAAnI,WAAA,SAAA0B,GAYA,IAXA,IAAAsH,EAAA,IAAA9L,EAAAiL,SACAnL,EAAAgM,EAUA/T,EAAA,EAAAiN,EAAAR,EAAAxM,OAAAD,EAAAiN,EAAAjN,IAAA,CACA,IAAAkU,EAAAzH,EAAAzM,GACAmT,EAAAnT,GAAAiN,EAAA,EAEA,GAAA,KAAAiH,GACAH,EAAAX,MAAAc,GAAAH,GACAZ,MAAAA,MAEA,CACA,IAAAuB,EAAA,IAAAzM,EAAAiL,SACAwB,EAAAvB,MAAAA,EAEAY,EAAAX,MAAAc,GAAAQ,EACAX,EAAAW,GAIA,OAAA3M,GASAE,EAAAiL,SAAApQ,UAAA+N,QAAA,WAQA,IAPA,IAAAkC,EAAA,GAEAe,EAAA,CAAA,CACAa,OAAA,GACAZ,KAAA7S,OAGA4S,EAAA7T,QAAA,CACA,IAAAmU,EAAAN,EAAA9U,MACAoU,EAAA/T,OAAA+K,KAAAgK,EAAAL,KAAAX,OACAnG,EAAAmG,EAAAnT,OAEAmU,EAAAL,KAAAZ,QAKAiB,EAAAO,OAAArH,OAAA,GACAyF,EAAAhH,KAAAqI,EAAAO,SAGA,IAAA,IAAA3U,EAAA,EAAAA,EAAAiN,EAAAjN,IAAA,CACA,IAAA4U,EAAAxB,EAAApT,GAEA8T,EAAA/H,KAAA,CACA4I,OAAAP,EAAAO,OAAA3I,OAAA4I,GACAb,KAAAK,EAAAL,KAAAX,MAAAwB,MAKA,OAAA7B,GAaA9K,EAAAiL,SAAApQ,UAAAmH,SAAA,WASA,GAAA/I,KAAA2T,KACA,OAAA3T,KAAA2T,KAOA,IAJA,IAAApI,EAAAvL,KAAAiS,MAAA,IAAA,IACA2B,EAAAzV,OAAA+K,KAAAlJ,KAAAkS,OAAA2B,OACA9H,EAAA6H,EAAA7U,OAEAD,EAAA,EAAAA,EAAAiN,EAAAjN,IAAA,CACA,IAAA8N,EAAAgH,EAAA9U,GAGAyM,EAAAA,EAAAqB,EAFA5M,KAAAkS,MAAAtF,GAEAtI,GAGA,OAAAiH,GAaAxE,EAAAiL,SAAApQ,UAAAyI,UAAA,SAAAM,GAUA,IATA,IAAAiF,EAAA,IAAA7I,EAAAiL,SACAkB,OAAAjJ,EAEA2I,EAAA,CAAA,CACAkB,MAAAnJ,EACAiF,OAAAA,EACAiD,KAAA7S,OAGA4S,EAAA7T,QAAA,CACAmU,EAAAN,EAAA9U,MAWA,IALA,IAAAiW,EAAA5V,OAAA+K,KAAAgK,EAAAY,MAAA5B,OACA8B,EAAAD,EAAAhV,OACAkV,EAAA9V,OAAA+K,KAAAgK,EAAAL,KAAAX,OACAgC,EAAAD,EAAAlV,OAEAoV,EAAA,EAAAA,EAAAH,EAAAG,IAGA,IAFA,IAAAC,EAAAL,EAAAI,GAEArK,EAAA,EAAAA,EAAAoK,EAAApK,IAAA,CACA,IAAAuK,EAAAJ,EAAAnK,GAEA,GAAAuK,GAAAD,GAAA,KAAAA,EAAA,CACA,IAAAvB,EAAAK,EAAAL,KAAAX,MAAAmC,GACAP,EAAAZ,EAAAY,MAAA5B,MAAAkC,GACAnC,EAAAY,EAAAZ,OAAA6B,EAAA7B,MACAuB,OAAAvJ,EAEAoK,KAAAnB,EAAAtD,OAAAsC,OAIAsB,EAAAN,EAAAtD,OAAAsC,MAAAmC,IACApC,MAAAuB,EAAAvB,OAAAA,IAMAuB,EAAA,IAAAzM,EAAAiL,UACAC,MAAAA,EACAiB,EAAAtD,OAAAsC,MAAAmC,GAAAb,GAGAZ,EAAA/H,KAAA,CACAiJ,MAAAA,EACAlE,OAAA4D,EACAX,KAAAA,MAOA,OAAAjD,GAEA7I,EAAAiL,SAAA9K,QAAA,WACAlH,KAAAsU,aAAA,GACAtU,KAAA6G,KAAA,IAAAE,EAAAiL,SACAhS,KAAAuU,eAAA,GACAvU,KAAAwU,eAAA,IAGAzN,EAAAiL,SAAA9K,QAAAtF,UAAA+M,OAAA,SAAA8F,GACA,IAAA5B,EACA6B,EAAA,EAEA,GAAAD,EAAAzU,KAAAsU,aACA,MAAA,IAAArH,MAAA,+BAGA,IAAA,IAAAnO,EAAA,EAAAA,EAAA2V,EAAA1V,QAAAD,EAAAkB,KAAAsU,aAAAvV,QACA0V,EAAA3V,IAAAkB,KAAAsU,aAAAxV,GADAA,IAEA4V,IAGA1U,KAAA2U,SAAAD,GAGA7B,EADA,GAAA7S,KAAAuU,eAAAxV,OACAiB,KAAA6G,KAEA7G,KAAAuU,eAAAvU,KAAAuU,eAAAxV,OAAA,GAAA6V,MAGA,IAAA9V,EAAA4V,EAAA5V,EAAA2V,EAAA1V,OAAAD,IAAA,CACA,IAAA+V,EAAA,IAAA9N,EAAAiL,SACAgB,EAAAyB,EAAA3V,GAEA+T,EAAAX,MAAAc,GAAA6B,EAEA7U,KAAAuU,eAAA1J,KAAA,CACAiK,OAAAjC,EACAG,KAAAA,EACA4B,MAAAC,IAGAhC,EAAAgC,EAGAhC,EAAAZ,OAAA,EACAjS,KAAAsU,aAAAG,GAGA1N,EAAAiL,SAAA9K,QAAAtF,UAAA0Q,OAAA,WACAtS,KAAA2U,SAAA,IAGA5N,EAAAiL,SAAA9K,QAAAtF,UAAA+S,SAAA,SAAAI,GACA,IAAA,IAAAjW,EAAAkB,KAAAuU,eAAAxV,OAAA,EAAAgW,GAAAjW,EAAAA,IAAA,CACA,IAAA+T,EAAA7S,KAAAuU,eAAAzV,GACAkW,EAAAnC,EAAA+B,MAAA7L,WAEAiM,KAAAhV,KAAAwU,eACA3B,EAAAiC,OAAA5C,MAAAW,EAAAG,MAAAhT,KAAAwU,eAAAQ,IAIAnC,EAAA+B,MAAAjB,KAAAqB,EAEAhV,KAAAwU,eAAAQ,GAAAnC,EAAA+B,OAGA5U,KAAAuU,eAAAzW,QAwBAiJ,EAAAkO,MAAA,SAAAC,GACAlV,KAAAmV,cAAAD,EAAAC,cACAnV,KAAAoV,aAAAF,EAAAE,aACApV,KAAAqV,SAAAH,EAAAG,SACArV,KAAAsV,OAAAJ,EAAAI,OACAtV,KAAAmH,SAAA+N,EAAA/N,UA0EAJ,EAAAkO,MAAArT,UAAA2T,OAAA,SAAAC,GACA,OAAAxV,KAAAyV,MAAA,SAAAA,GACA,IAAA1O,EAAA2O,YAAAF,EAAAC,GACAlW,WA6BAwH,EAAAkO,MAAArT,UAAA6T,MAAA,SAAA/J,GAoBA,IAZA,IAAA+J,EAAA,IAAA1O,EAAA4O,MAAA3V,KAAAsV,QACAM,EAAAzX,OAAA8K,OAAA,MACA4M,EAAA1X,OAAA8K,OAAA,MACA6M,EAAA3X,OAAA8K,OAAA,MACA8M,EAAA5X,OAAA8K,OAAA,MACA+M,EAAA7X,OAAA8K,OAAA,MAOAnK,EAAA,EAAAA,EAAAkB,KAAAsV,OAAAvW,OAAAD,IACA+W,EAAA7V,KAAAsV,OAAAxW,IAAA,IAAAiI,EAAAmH,OAGAxC,EAAA5J,KAAA2T,EAAAA,GAEA,IAAA3W,EAAA,EAAAA,EAAA2W,EAAAQ,QAAAlX,OAAAD,IAAA,CASA,IAAA0T,EAAAiD,EAAAQ,QAAAnX,GACAoX,EAAA,KACAC,EAAApP,EAAAmD,IAAAE,SAGA8L,EADA1D,EAAA4D,YACApW,KAAAmH,SAAA2G,UAAA0E,EAAAE,KAAA,CACA4C,OAAA9C,EAAA8C,SAGA,CAAA9C,EAAAE,MAGA,IAAA,IAAA2D,EAAA,EAAAA,EAAAH,EAAAnX,OAAAsX,IAAA,CACA,IAAA3D,EAAAwD,EAAAG,GAQA7D,EAAAE,KAAAA,EAOA,IAAA4D,EAAAvP,EAAAiL,SAAAO,WAAAC,GACA+D,EAAAvW,KAAAqV,SAAAhL,UAAAiM,GAAA3G,UAQA,GAAA,IAAA4G,EAAAxX,QAAAyT,EAAAgE,WAAAzP,EAAA4O,MAAAa,SAAAC,SAAA,CACA,IAAA,IAAA5I,EAAA,EAAAA,EAAA2E,EAAA8C,OAAAvW,OAAA8O,IAAA,CAEAkI,EADAW,EAAAlE,EAAA8C,OAAAzH,IACA9G,EAAAmD,IAAAM,MAGA,MAGA,IAAA,IAAAmD,EAAA,EAAAA,EAAA4I,EAAAxX,OAAA4O,IAKA,CAAA,IAAAgJ,EAAAJ,EAAA5I,GACA3C,EAAAhL,KAAAmV,cAAAwB,GACAC,EAAA5L,EAAA6L,OAEA,IAAAhJ,EAAA,EAAAA,EAAA2E,EAAA8C,OAAAvW,OAAA8O,IAAA,CASA,IACAiJ,EAAA9L,EADA0L,EAAAlE,EAAA8C,OAAAzH,IAEAkJ,EAAA5Y,OAAA+K,KAAA4N,GACAE,EAAAL,EAAA,IAAAD,EACAO,EAAA,IAAAlQ,EAAAmD,IAAA6M,GAoBA,GAbAvE,EAAAgE,UAAAzP,EAAA4O,MAAAa,SAAAC,WACAN,EAAAA,EAAA5L,MAAA0M,QAEAhN,IAAA8L,EAAAW,KACAX,EAAAW,GAAA3P,EAAAmD,IAAAE,WASAoI,EAAAgE,UAAAzP,EAAA4O,MAAAa,SAAAU,YA4BA,GANArB,EAAAa,GAAA7H,OAAA+H,EAAApE,EAAA2E,MAAA,SAAAzM,EAAAC,GAAA,OAAAD,EAAAC,KAMAmL,EAAAkB,GAAA,CAIA,IAAA,IAAAI,EAAA,EAAAA,EAAAL,EAAAhY,OAAAqY,IAAA,CAOA,IAGAC,EAHAC,EAAAP,EAAAK,GACAG,EAAA,IAAAxQ,EAAAwC,SAAA+N,EAAAZ,GACAlL,EAAAsL,EAAAQ,QAGArN,KAAAoN,EAAAzB,EAAA2B,IACA3B,EAAA2B,GAAA,IAAAxQ,EAAAyQ,UAAAb,EAAAD,EAAAlL,GAEA6L,EAAA5Z,IAAAkZ,EAAAD,EAAAlL,GAKAsK,EAAAkB,IAAA,aAnDA/M,IAAA+L,EAAAU,KACAV,EAAAU,GAAA3P,EAAAmD,IAAAM,OAGAwL,EAAAU,GAAAV,EAAAU,GAAAnM,MAAA0M,KA0DA,GAAAzE,EAAAgE,WAAAzP,EAAA4O,MAAAa,SAAAC,SACA,IAAA5I,EAAA,EAAAA,EAAA2E,EAAA8C,OAAAvW,OAAA8O,IAAA,CAEAkI,EADAW,EAAAlE,EAAA8C,OAAAzH,IACAkI,EAAAW,GAAArM,UAAA8L,IAUA,IAAAsB,EAAA1Q,EAAAmD,IAAAE,SACAsN,EAAA3Q,EAAAmD,IAAAM,MAEA,IAAA1L,EAAA,EAAAA,EAAAkB,KAAAsV,OAAAvW,OAAAD,IAAA,CACA,IAAA4X,EAEAX,EAFAW,EAAA1W,KAAAsV,OAAAxW,MAGA2Y,EAAAA,EAAApN,UAAA0L,EAAAW,KAGAV,EAAAU,KACAgB,EAAAA,EAAAnN,MAAAyL,EAAAU,KAIA,IAAAiB,EAAAxZ,OAAA+K,KAAA0M,GACAgC,EAAA,GACAza,EAAAgB,OAAA8K,OAAA,MAYA,GAAAwM,EAAAoC,YAAA,CACAF,EAAAxZ,OAAA+K,KAAAlJ,KAAAoV,cAEA,IAAAtW,EAAA,EAAAA,EAAA6Y,EAAA5Y,OAAAD,IAAA,CACAyY,EAAAI,EAAA7Y,GAAA,IACAkL,EAAAjD,EAAAwC,SAAAM,WAAA0N,GACA3B,EAAA2B,GAAA,IAAAxQ,EAAAyQ,WAIA,IAAA1Y,EAAA,EAAAA,EAAA6Y,EAAA5Y,OAAAD,IAAA,CASA,IACA0K,GADAQ,EAAAjD,EAAAwC,SAAAM,WAAA8N,EAAA7Y,KACA0K,OAEA,GAAAiO,EAAA7W,SAAA4I,KAIAkO,EAAA9W,SAAA4I,GAAA,CAIA,IAEAsO,EAFAC,EAAA/X,KAAAoV,aAAApL,GACAgO,EAAAnC,EAAA7L,EAAAP,WAAAiG,WAAAqI,GAGA,QAAA9N,KAAA6N,EAAA3a,EAAAqM,IACAsO,EAAAE,OAAAA,EACAF,EAAAG,UAAAC,QAAAtC,EAAA5L,QACA,CACA,IAAAqC,EAAA,CACA8L,IAAA3O,EACAwO,MAAAA,EACAC,UAAArC,EAAA5L,IAEA7M,EAAAqM,GAAA6C,EACAuL,EAAA/M,KAAAwB,KAOA,OAAAuL,EAAA/D,KAAA,SAAAnJ,EAAAC,GACA,OAAAA,EAAAqN,MAAAtN,EAAAsN,SAYAjR,EAAAkO,MAAArT,UAAAqM,OAAA,WACA,IAAAkH,EAAAhX,OAAA+K,KAAAlJ,KAAAmV,eACAtB,OACAjI,IAAA,SAAA8G,GACA,MAAA,CAAAA,EAAA1S,KAAAmV,cAAAzC,KACA1S,MAEAoV,EAAAjX,OAAA+K,KAAAlJ,KAAAoV,cACAxJ,IAAA,SAAAuM,GACA,MAAA,CAAAA,EAAAnY,KAAAoV,aAAA+C,GAAAlK,WACAjO,MAEA,MAAA,CACAP,QAAAsH,EAAAtH,QACA6V,OAAAtV,KAAAsV,OACAF,aAAAA,EACAD,cAAAA,EACAhO,SAAAnH,KAAAmH,SAAA8G,WAUAlH,EAAAkO,MAAAnI,KAAA,SAAAsL,GACA,IAAAlD,EAAA,GACAE,EAAA,GACAiD,EAAAD,EAAAhD,aACAD,EAAA,GACAmD,EAAAF,EAAAjD,cACAoD,EAAA,IAAAxR,EAAAiL,SAAA9K,QACAC,EAAAJ,EAAAyF,SAAAM,KAAAsL,EAAAjR,UAEAiR,EAAA3Y,SAAAsH,EAAAtH,SACAsH,EAAA0B,MAAAC,KAAA,4EAAA3B,EAAAtH,QAAA,sCAAA2Y,EAAA3Y,QAAA,KAGA,IAAA,IAAAX,EAAA,EAAAA,EAAAuZ,EAAAtZ,OAAAD,IAAA,CACA,IACAqZ,GADAK,EAAAH,EAAAvZ,IACA,GACAqL,EAAAqO,EAAA,GAEApD,EAAA+C,GAAA,IAAApR,EAAAmH,OAAA/D,GAGA,IAAArL,EAAA,EAAAA,EAAAwZ,EAAAvZ,OAAAD,IAAA,CACA,IAAA0Z,EACA9F,GADA8F,EAAAF,EAAAxZ,IACA,GACAkM,EAAAwN,EAAA,GAEAD,EAAA5J,OAAA+D,GACAyC,EAAAzC,GAAA1H,EAYA,OATAuN,EAAAjG,SAEA4C,EAAAI,OAAA8C,EAAA9C,OAEAJ,EAAAE,aAAAA,EACAF,EAAAC,cAAAA,EACAD,EAAAG,SAAAkD,EAAA1R,KACAqO,EAAA/N,SAAAA,EAEA,IAAAJ,EAAAkO,MAAAC,IA+BAnO,EAAAG,QAAA,WACAlH,KAAAyY,KAAA,KACAzY,KAAA0Y,QAAAva,OAAA8K,OAAA,MACAjJ,KAAA2Y,WAAAxa,OAAA8K,OAAA,MACAjJ,KAAAmV,cAAAhX,OAAA8K,OAAA,MACAjJ,KAAA4Y,qBAAA,GACA5Y,KAAA6Y,aAAA,GACA7Y,KAAA2L,UAAA5E,EAAA4E,UACA3L,KAAAmH,SAAA,IAAAJ,EAAAyF,SACAxM,KAAAuH,eAAA,IAAAR,EAAAyF,SACAxM,KAAAiL,cAAA,EACAjL,KAAA8Y,GAAA,IACA9Y,KAAA+Y,IAAA,IACA/Y,KAAA4W,UAAA,EACA5W,KAAAgZ,kBAAA,IAeAjS,EAAAG,QAAAtF,UAAAuW,IAAA,SAAAA,GACAnY,KAAAyY,KAAAN,GAmCApR,EAAAG,QAAAtF,UAAA8U,MAAA,SAAAjN,EAAAwP,GACA,GAAA,KAAA7Q,KAAAqB,GACA,MAAA,IAAAyP,WAAA,UAAAzP,EAAA,oCAGAzJ,KAAA0Y,QAAAjP,GAAAwP,GAAA,IAWAlS,EAAAG,QAAAtF,UAAA+I,EAAA,SAAAwO,GAEAnZ,KAAA8Y,GADAK,EAAA,EACA,EACA,EAAAA,EACA,EAEAA,GAWApS,EAAAG,QAAAtF,UAAAwX,GAAA,SAAAD,GACAnZ,KAAA+Y,IAAAI,GAoBApS,EAAAG,QAAAtF,UAAAnE,IAAA,SAAA4b,EAAAJ,GACA,IAAAzP,EAAA6P,EAAArZ,KAAAyY,MACAnD,EAAAnX,OAAA+K,KAAAlJ,KAAA0Y,SAEA1Y,KAAA2Y,WAAAnP,GAAAyP,GAAA,GACAjZ,KAAAiL,eAAA,EAEA,IAAA,IAAAnM,EAAA,EAAAA,EAAAwW,EAAAvW,OAAAD,IAAA,CACA,IAAA2K,EAAA6L,EAAAxW,GACAwa,EAAAtZ,KAAA0Y,QAAAjP,GAAA6P,UACA5C,EAAA4C,EAAAA,EAAAD,GAAAA,EAAA5P,GACAuC,EAAAhM,KAAA2L,UAAA+K,EAAA,CACApB,OAAA,CAAA7L,KAEAyM,EAAAlW,KAAAmH,SAAAqG,IAAAxB,GACAhC,EAAA,IAAAjD,EAAAwC,SAAAC,EAAAC,GACA8P,EAAApb,OAAA8K,OAAA,MAEAjJ,KAAA4Y,qBAAA5O,GAAAuP,EACAvZ,KAAA6Y,aAAA7O,GAAA,EAGAhK,KAAA6Y,aAAA7O,IAAAkM,EAAAnX,OAGA,IAAA,IAAA4O,EAAA,EAAAA,EAAAuI,EAAAnX,OAAA4O,IAAA,CACA,IAAA+E,EAAAwD,EAAAvI,GAUA,GARA1D,MAAAsP,EAAA7G,KACA6G,EAAA7G,GAAA,GAGA6G,EAAA7G,IAAA,EAIAzI,MAAAjK,KAAAmV,cAAAzC,GAAA,CACA,IAAA1H,EAAA7M,OAAA8K,OAAA,MACA+B,EAAA,OAAAhL,KAAA4W,UACA5W,KAAA4W,WAAA,EAEA,IAAA,IAAA/I,EAAA,EAAAA,EAAAyH,EAAAvW,OAAA8O,IACA7C,EAAAsK,EAAAzH,IAAA1P,OAAA8K,OAAA,MAGAjJ,KAAAmV,cAAAzC,GAAA1H,EAIAf,MAAAjK,KAAAmV,cAAAzC,GAAAjJ,GAAAD,KACAxJ,KAAAmV,cAAAzC,GAAAjJ,GAAAD,GAAArL,OAAA8K,OAAA,OAKA,IAAA,IAAAmO,EAAA,EAAAA,EAAApX,KAAAgZ,kBAAAja,OAAAqY,IAAA,CACA,IAAAoC,EAAAxZ,KAAAgZ,kBAAA5B,GACA5L,EAAAkH,EAAAlH,SAAAgO,GAEAvP,MAAAjK,KAAAmV,cAAAzC,GAAAjJ,GAAAD,GAAAgQ,KACAxZ,KAAAmV,cAAAzC,GAAAjJ,GAAAD,GAAAgQ,GAAA,IAGAxZ,KAAAmV,cAAAzC,GAAAjJ,GAAAD,GAAAgQ,GAAA3O,KAAAW,OAYAzE,EAAAG,QAAAtF,UAAA6X,6BAAA,WAOA,IALA,IAAAC,EAAAvb,OAAA+K,KAAAlJ,KAAA6Y,cACAc,EAAAD,EAAA3a,OACA6a,EAAA,GACAC,EAAA,GAEA/a,EAAA,EAAAA,EAAA6a,EAAA7a,IAAA,CACA,IAAAkL,EAAAjD,EAAAwC,SAAAM,WAAA6P,EAAA5a,IACA4X,EAAA1M,EAAAP,UAEAoQ,EAAAnD,KAAAmD,EAAAnD,GAAA,GACAmD,EAAAnD,IAAA,EAEAkD,EAAAlD,KAAAkD,EAAAlD,GAAA,GACAkD,EAAAlD,IAAA1W,KAAA6Y,aAAA7O,GAGA,IAAAsL,EAAAnX,OAAA+K,KAAAlJ,KAAA0Y,SAEA,IAAA5Z,EAAA,EAAAA,EAAAwW,EAAAvW,OAAAD,IAAA,CACA,IAAA2K,EAAA6L,EAAAxW,GACA8a,EAAAnQ,GAAAmQ,EAAAnQ,GAAAoQ,EAAApQ,GAGAzJ,KAAA8Z,mBAAAF,GAQA7S,EAAAG,QAAAtF,UAAAmY,mBAAA,WAMA,IALA,IAAA3E,EAAA,GACAsE,EAAAvb,OAAA+K,KAAAlJ,KAAA4Y,sBACAoB,EAAAN,EAAA3a,OACAkb,EAAA9b,OAAA8K,OAAA,MAEAnK,EAAA,EAAAA,EAAAkb,EAAAlb,IAAA,CAaA,IAZA,IAAAkL,EAAAjD,EAAAwC,SAAAM,WAAA6P,EAAA5a,IACA2K,EAAAO,EAAAP,UACAyQ,EAAAla,KAAA6Y,aAAA7O,GACA+N,EAAA,IAAAhR,EAAAmH,OACAiM,EAAAna,KAAA4Y,qBAAA5O,GACAkM,EAAA/X,OAAA+K,KAAAiR,GACAC,EAAAlE,EAAAnX,OAGAsb,EAAAra,KAAA0Y,QAAAjP,GAAA0N,OAAA,EACAmD,EAAAta,KAAA2Y,WAAA3O,EAAAR,QAAA2N,OAAA,EAEAxJ,EAAA,EAAAA,EAAAyM,EAAAzM,IAAA,CACA,IAGA5C,EAAAiN,EAAAuC,EAHA7H,EAAAwD,EAAAvI,GACA6M,EAAAL,EAAAzH,GACAkE,EAAA5W,KAAAmV,cAAAzC,GAAAmE,YAGA5M,IAAAgQ,EAAAvH,IACA3H,EAAAhE,EAAAgE,IAAA/K,KAAAmV,cAAAzC,GAAA1S,KAAAiL,eACAgP,EAAAvH,GAAA3H,GAEAA,EAAAkP,EAAAvH,GAGAsF,EAAAjN,IAAA/K,KAAA+Y,IAAA,GAAAyB,IAAAxa,KAAA+Y,KAAA,EAAA/Y,KAAA8Y,GAAA9Y,KAAA8Y,IAAAoB,EAAAla,KAAA8Z,mBAAArQ,KAAA+Q,GACAxC,GAAAqC,EACArC,GAAAsC,EACAC,EAAApP,KAAAsP,MAAA,IAAAzC,GAAA,IAQAD,EAAApJ,OAAAiI,EAAA2D,GAGAnF,EAAApL,GAAA+N,EAGA/X,KAAAoV,aAAAA,GAQArO,EAAAG,QAAAtF,UAAA8Y,eAAA,WACA1a,KAAAqV,SAAAtO,EAAAiL,SAAAI,UACAjU,OAAA+K,KAAAlJ,KAAAmV,eAAAtB,SAYA9M,EAAAG,QAAAtF,UAAA4F,MAAA,WAKA,OAJAxH,KAAAyZ,+BACAzZ,KAAA+Z,qBACA/Z,KAAA0a,iBAEA,IAAA3T,EAAAkO,MAAA,CACAE,cAAAnV,KAAAmV,cACAC,aAAApV,KAAAoV,aACAC,SAAArV,KAAAqV,SACAC,OAAAnX,OAAA+K,KAAAlJ,KAAA0Y,SACAvR,SAAAnH,KAAAuH,kBAkBAR,EAAAG,QAAAtF,UAAA+Y,IAAA,SAAAjP,GACA,IAAAkP,EAAAld,MAAAkE,UAAAC,MAAAC,KAAAoL,UAAA,GACA0N,EAAAC,QAAA7a,MACA0L,EAAAoP,MAAA9a,KAAA4a,IAcA7T,EAAAyQ,UAAA,SAAA9E,EAAAgE,EAAAlL,GASA,IARA,IAAAuP,EAAA5c,OAAA8K,OAAA,MACA+R,EAAA7c,OAAA+K,KAAAsC,GAAA,IAOA1M,EAAA,EAAAA,EAAAkc,EAAAjc,OAAAD,IAAA,CACA,IAAAqK,EAAA6R,EAAAlc,GACAic,EAAA5R,GAAAqC,EAAArC,GAAAtH,QAGA7B,KAAAwL,SAAArN,OAAA8K,OAAA,WAEAgB,IAAAyI,IACA1S,KAAAwL,SAAAkH,GAAAvU,OAAA8K,OAAA,MACAjJ,KAAAwL,SAAAkH,GAAAgE,GAAAqE,IAaAhU,EAAAyQ,UAAA5V,UAAAsW,QAAA,SAAA+C,GAGA,IAFA,IAAA/E,EAAA/X,OAAA+K,KAAA+R,EAAAzP,UAEA1M,EAAA,EAAAA,EAAAoX,EAAAnX,OAAAD,IAAA,CACA,IAAA4T,EAAAwD,EAAApX,GACAwW,EAAAnX,OAAA+K,KAAA+R,EAAAzP,SAAAkH,IAEAzI,MAAAjK,KAAAwL,SAAAkH,KACA1S,KAAAwL,SAAAkH,GAAAvU,OAAA8K,OAAA,OAGA,IAAA,IAAA0E,EAAA,EAAAA,EAAA2H,EAAAvW,OAAA4O,IAAA,CACA,IAAA+I,EAAApB,EAAA3H,GACAzE,EAAA/K,OAAA+K,KAAA+R,EAAAzP,SAAAkH,GAAAgE,IAEAzM,MAAAjK,KAAAwL,SAAAkH,GAAAgE,KACA1W,KAAAwL,SAAAkH,GAAAgE,GAAAvY,OAAA8K,OAAA,OAGA,IAAA,IAAA4E,EAAA,EAAAA,EAAA3E,EAAAnK,OAAA8O,IAAA,CACA,IAAA1E,EAAAD,EAAA2E,GAEA5D,MAAAjK,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GACAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAA8R,EAAAzP,SAAAkH,GAAAgE,GAAAvN,GAEAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAA2B,OAAAmQ,EAAAzP,SAAAkH,GAAAgE,GAAAvN,QAeApC,EAAAyQ,UAAA5V,UAAAnE,IAAA,SAAAiV,EAAAgE,EAAAlL,GACA,KAAAkH,KAAA1S,KAAAwL,UAGA,OAFAxL,KAAAwL,SAAAkH,GAAAvU,OAAA8K,OAAA,WACAjJ,KAAAwL,SAAAkH,GAAAgE,GAAAlL,GAIA,GAAAkL,KAAA1W,KAAAwL,SAAAkH,GAOA,IAFA,IAAAsI,EAAA7c,OAAA+K,KAAAsC,GAEA1M,EAAA,EAAAA,EAAAkc,EAAAjc,OAAAD,IAAA,CACA,IAAAqK,EAAA6R,EAAAlc,GAEAqK,KAAAnJ,KAAAwL,SAAAkH,GAAAgE,GACA1W,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAA2B,OAAAU,EAAArC,IAEAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAAqC,EAAArC,QAZAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAlL,GA2BAzE,EAAA4O,MAAA,SAAAuF,GACAlb,KAAAiW,QAAA,GACAjW,KAAAkb,UAAAA,GA2BAnU,EAAA4O,MAAAwF,SAAA,IAAAC,OAAA,KACArU,EAAA4O,MAAAwF,SAAAE,KAAA,EACAtU,EAAA4O,MAAAwF,SAAAG,QAAA,EACAvU,EAAA4O,MAAAwF,SAAAI,SAAA,EAaAxU,EAAA4O,MAAAa,SAAA,CAIAgF,SAAA,EAMA/E,SAAA,EAMAS,WAAA,GA0BAnQ,EAAA4O,MAAA/T,UAAA4Q,OAAA,SAAAA,GA+BA,MA9BA,WAAAA,IACAA,EAAA8C,OAAAtV,KAAAkb,WAGA,UAAA1I,IACAA,EAAA2E,MAAA,GAGA,gBAAA3E,IACAA,EAAA4D,aAAA,GAGA,aAAA5D,IACAA,EAAA2I,SAAApU,EAAA4O,MAAAwF,SAAAE,MAGA7I,EAAA2I,SAAApU,EAAA4O,MAAAwF,SAAAG,SAAA9I,EAAAE,KAAAtG,OAAA,IAAArF,EAAA4O,MAAAwF,WACA3I,EAAAE,KAAA,IAAAF,EAAAE,MAGAF,EAAA2I,SAAApU,EAAA4O,MAAAwF,SAAAI,UAAA/I,EAAAE,KAAA7Q,OAAA,IAAAkF,EAAA4O,MAAAwF,WACA3I,EAAAE,KAAAF,EAAAE,KAAA,KAGA,aAAAF,IACAA,EAAAgE,SAAAzP,EAAA4O,MAAAa,SAAAgF,UAGAxb,KAAAiW,QAAApL,KAAA2H,GAEAxS,MAUA+G,EAAA4O,MAAA/T,UAAAiW,UAAA,WACA,IAAA,IAAA/Y,EAAA,EAAAA,EAAAkB,KAAAiW,QAAAlX,OAAAD,IACA,GAAAkB,KAAAiW,QAAAnX,GAAA0X,UAAAzP,EAAA4O,MAAAa,SAAAU,WACA,OAAA,EAIA,OAAA,GA6BAnQ,EAAA4O,MAAA/T,UAAA8Q,KAAA,SAAAA,EAAA9T,GACA,GAAAlB,MAAA2L,QAAAqJ,GAEA,OADAA,EAAArU,QAAA,SAAAwN,GAAA7L,KAAA0S,KAAA7G,EAAA9E,EAAA0B,MAAAO,MAAApK,KAAAoB,MACAA,KAGA,IAAAwS,EAAA5T,GAAA,GAKA,OAJA4T,EAAAE,KAAAA,EAAA3J,WAEA/I,KAAAwS,OAAAA,GAEAxS,MAEA+G,EAAA0U,gBAAA,SAAA9S,EAAA2F,EAAAC,GACAvO,KAAA0b,KAAA,kBACA1b,KAAA2I,QAAAA,EACA3I,KAAAsO,MAAAA,EACAtO,KAAAuO,IAAAA,GAGAxH,EAAA0U,gBAAA7Z,UAAA,IAAAqL,MACAlG,EAAA4U,WAAA,SAAApQ,GACAvL,KAAA4b,QAAA,GACA5b,KAAAuL,IAAAA,EACAvL,KAAAjB,OAAAwM,EAAAxM,OACAiB,KAAAsN,IAAA,EACAtN,KAAAsO,MAAA,EACAtO,KAAA6b,oBAAA,IAGA9U,EAAA4U,WAAA/Z,UAAA4L,IAAA,WAGA,IAFA,IAAAsO,EAAA/U,EAAA4U,WAAAI,QAEAD,GACAA,EAAAA,EAAA9b,OAIA+G,EAAA4U,WAAA/Z,UAAAoa,YAAA,WAKA,IAJA,IAAAC,EAAA,GACA/P,EAAAlM,KAAAsO,MACArC,EAAAjM,KAAAsN,IAEAxO,EAAA,EAAAA,EAAAkB,KAAA6b,oBAAA9c,OAAAD,IACAmN,EAAAjM,KAAA6b,oBAAA/c,GACAmd,EAAApR,KAAA7K,KAAAuL,IAAA1J,MAAAqK,EAAAD,IACAC,EAAAD,EAAA,EAMA,OAHAgQ,EAAApR,KAAA7K,KAAAuL,IAAA1J,MAAAqK,EAAAlM,KAAAsN,MACAtN,KAAA6b,oBAAA9c,OAAA,EAEAkd,EAAAjZ,KAAA,KAGA+D,EAAA4U,WAAA/Z,UAAAsa,KAAA,SAAAC,GACAnc,KAAA4b,QAAA/Q,KAAA,CACAsR,KAAAA,EACA5Q,IAAAvL,KAAAgc,cACA1N,MAAAtO,KAAAsO,MACAC,IAAAvO,KAAAsN,MAGAtN,KAAAsO,MAAAtO,KAAAsN,KAGAvG,EAAA4U,WAAA/Z,UAAAwa,gBAAA,WACApc,KAAA6b,oBAAAhR,KAAA7K,KAAAsN,IAAA,GACAtN,KAAAsN,KAAA,GAGAvG,EAAA4U,WAAA/Z,UAAA4R,KAAA,WACA,GAAAxT,KAAAsN,KAAAtN,KAAAjB,OACA,OAAAgI,EAAA4U,WAAAU,IAGA,IAAArJ,EAAAhT,KAAAuL,IAAAa,OAAApM,KAAAsN,KAEA,OADAtN,KAAAsN,KAAA,EACA0F,GAGAjM,EAAA4U,WAAA/Z,UAAA0a,MAAA,WACA,OAAAtc,KAAAsN,IAAAtN,KAAAsO,OAGAvH,EAAA4U,WAAA/Z,UAAA2a,OAAA,WACAvc,KAAAsO,OAAAtO,KAAAsN,MACAtN,KAAAsN,KAAA,GAGAtN,KAAAsO,MAAAtO,KAAAsN,KAGAvG,EAAA4U,WAAA/Z,UAAA4a,OAAA,aACAxc,KAAAsN,KAGAvG,EAAA4U,WAAA/Z,UAAA6a,eAAA,WAGA,IAFA,IAAAzJ,EAAA0J,EAKA,IADAA,GADA1J,EAAAhT,KAAAwT,QACAmJ,WAAA,KACAD,EAAA,KAEA1J,GAAAjM,EAAA4U,WAAAU,KACArc,KAAAwc,UAIAzV,EAAA4U,WAAA/Z,UAAAgb,KAAA,WACA,OAAA5c,KAAAsN,IAAAtN,KAAAjB,QAGAgI,EAAA4U,WAAAU,IAAA,MACAtV,EAAA4U,WAAAkB,MAAA,QACA9V,EAAA4U,WAAAmB,KAAA,OACA/V,EAAA4U,WAAAoB,cAAA,gBACAhW,EAAA4U,WAAAqB,MAAA,QACAjW,EAAA4U,WAAAsB,SAAA,WAEAlW,EAAA4U,WAAAuB,SAAA,SAAAC,GAIA,OAHAA,EAAAX,SACAW,EAAAjB,KAAAnV,EAAA4U,WAAAkB,OACAM,EAAAZ,SACAxV,EAAA4U,WAAAI,SAGAhV,EAAA4U,WAAAyB,QAAA,SAAAD,GAQA,GAPA,EAAAA,EAAAb,UACAa,EAAAX,SACAW,EAAAjB,KAAAnV,EAAA4U,WAAAmB,OAGAK,EAAAZ,SAEAY,EAAAP,OACA,OAAA7V,EAAA4U,WAAAI,SAIAhV,EAAA4U,WAAA0B,gBAAA,SAAAF,GAIA,OAHAA,EAAAZ,SACAY,EAAAV,iBACAU,EAAAjB,KAAAnV,EAAA4U,WAAAoB,eACAhW,EAAA4U,WAAAI,SAGAhV,EAAA4U,WAAA2B,SAAA,SAAAH,GAIA,OAHAA,EAAAZ,SACAY,EAAAV,iBACAU,EAAAjB,KAAAnV,EAAA4U,WAAAqB,OACAjW,EAAA4U,WAAAI,SAGAhV,EAAA4U,WAAA4B,OAAA,SAAAJ,GACA,EAAAA,EAAAb,SACAa,EAAAjB,KAAAnV,EAAA4U,WAAAmB,OAeA/V,EAAA4U,WAAA6B,cAAAzW,EAAA4E,UAAAW,UAEAvF,EAAA4U,WAAAI,QAAA,SAAAoB,GACA,OAAA,CACA,IAAAnK,EAAAmK,EAAA3J,OAEA,GAAAR,GAAAjM,EAAA4U,WAAAU,IACA,OAAAtV,EAAA4U,WAAA4B,OAIA,GAAA,IAAAvK,EAAA2J,WAAA,GAAA,CAKA,GAAA,KAAA3J,EACA,OAAAjM,EAAA4U,WAAAuB,SAGA,GAAA,KAAAlK,EAKA,OAJAmK,EAAAX,SACA,EAAAW,EAAAb,SACAa,EAAAjB,KAAAnV,EAAA4U,WAAAmB,MAEA/V,EAAA4U,WAAA0B,gBAGA,GAAA,KAAArK,EAKA,OAJAmK,EAAAX,SACA,EAAAW,EAAAb,SACAa,EAAAjB,KAAAnV,EAAA4U,WAAAmB,MAEA/V,EAAA4U,WAAA2B,SAMA,GAAA,KAAAtK,GAAA,IAAAmK,EAAAb,QAEA,OADAa,EAAAjB,KAAAnV,EAAA4U,WAAAsB,UACAlW,EAAA4U,WAAAI,QAMA,GAAA,KAAA/I,GAAA,IAAAmK,EAAAb,QAEA,OADAa,EAAAjB,KAAAnV,EAAA4U,WAAAsB,UACAlW,EAAA4U,WAAAI,QAGA,GAAA/I,EAAA3G,MAAAtF,EAAA4U,WAAA6B,eACA,OAAAzW,EAAA4U,WAAAyB,aAzCAD,EAAAf,oBA8CArV,EAAA2O,YAAA,SAAAnK,EAAAkK,GACAzV,KAAAmd,MAAA,IAAApW,EAAA4U,WAAApQ,GACAvL,KAAAyV,MAAAA,EACAzV,KAAAyd,cAAA,GACAzd,KAAA0d,UAAA,GAGA3W,EAAA2O,YAAA9T,UAAArC,MAAA,WACAS,KAAAmd,MAAA3P,MACAxN,KAAA4b,QAAA5b,KAAAmd,MAAAvB,QAIA,IAFA,IAAAE,EAAA/U,EAAA2O,YAAAiI,YAEA7B,GACAA,EAAAA,EAAA9b,MAGA,OAAAA,KAAAyV,OAGA1O,EAAA2O,YAAA9T,UAAAgc,WAAA,WACA,OAAA5d,KAAA4b,QAAA5b,KAAA0d,YAGA3W,EAAA2O,YAAA9T,UAAAic,cAAA,WACA,IAAAC,EAAA9d,KAAA4d,aAEA,OADA5d,KAAA0d,WAAA,EACAI,GAGA/W,EAAA2O,YAAA9T,UAAAmc,WAAA,WACA,IAAAC,EAAAhe,KAAAyd,cACAzd,KAAAyV,MAAAjD,OAAAwL,GACAhe,KAAAyd,cAAA,IAGA1W,EAAA2O,YAAAiI,YAAA,SAAAM,GACA,IAAAH,EAAAG,EAAAL,aAEA,GAAA3T,MAAA6T,EAIA,OAAAA,EAAA3B,MACA,KAAApV,EAAA4U,WAAAsB,SACA,OAAAlW,EAAA2O,YAAAwI,cACA,KAAAnX,EAAA4U,WAAAkB,MACA,OAAA9V,EAAA2O,YAAAyI,WACA,KAAApX,EAAA4U,WAAAmB,KACA,OAAA/V,EAAA2O,YAAA0I,UACA,QACA,IAAAC,EAAA,4CAAAP,EAAA3B,KAMA,MAJA,GAAA2B,EAAAvS,IAAAxM,SACAsf,GAAA,gBAAAP,EAAAvS,IAAA,KAGA,IAAAxE,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,OAIAxH,EAAA2O,YAAAwI,cAAA,SAAAD,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAA5T,MAAA6T,EAAA,CAIA,OAAAA,EAAAvS,KACA,IAAA,IACA0S,EAAAR,cAAAjH,SAAAzP,EAAA4O,MAAAa,SAAAU,WACA,MACA,IAAA,IACA+G,EAAAR,cAAAjH,SAAAzP,EAAA4O,MAAAa,SAAAC,SACA,MACA,QACA,IAAA4H,EAAA,kCAAAP,EAAAvS,IAAA,IACA,MAAA,IAAAxE,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA,IAAA+P,EAAAL,EAAAL,aAEA,GAAA3T,MAAAqU,EAAA,CACAD,EAAA,yCACA,MAAA,IAAAtX,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA,OAAA+P,EAAAnC,MACA,KAAApV,EAAA4U,WAAAkB,MACA,OAAA9V,EAAA2O,YAAAyI,WACA,KAAApX,EAAA4U,WAAAmB,KACA,OAAA/V,EAAA2O,YAAA0I,UACA,QACAC,EAAA,mCAAAC,EAAAnC,KAAA,IACA,MAAA,IAAApV,EAAA0U,gBAAA4C,EAAAC,EAAAhQ,MAAAgQ,EAAA/P,QAIAxH,EAAA2O,YAAAyI,WAAA,SAAAF,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAA5T,MAAA6T,EAAA,CAIA,IAAA,GAAAG,EAAAxI,MAAAyF,UAAAnR,QAAA+T,EAAAvS,KAAA,CACA,IAAAgT,EAAAN,EAAAxI,MAAAyF,UAAAtP,IAAA,SAAA4S,GAAA,MAAA,IAAAA,EAAA,MAAAxb,KAAA,MACAqb,EAAA,uBAAAP,EAAAvS,IAAA,uBAAAgT,EAEA,MAAA,IAAAxX,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA0P,EAAAR,cAAAnI,OAAA,CAAAwI,EAAAvS,KAEA,IAAA+S,EAAAL,EAAAL,aAEA,GAAA3T,MAAAqU,EAAA,CACAD,EAAA,gCACA,MAAA,IAAAtX,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA,OAAA+P,EAAAnC,MACA,KAAApV,EAAA4U,WAAAmB,KACA,OAAA/V,EAAA2O,YAAA0I,UACA,QACAC,EAAA,0BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAApV,EAAA0U,gBAAA4C,EAAAC,EAAAhQ,MAAAgQ,EAAA/P,QAIAxH,EAAA2O,YAAA0I,UAAA,SAAAH,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAA5T,MAAA6T,EAAA,CAIAG,EAAAR,cAAA/K,KAAAoL,EAAAvS,IAAA/C,eAEA,GAAAsV,EAAAvS,IAAAxB,QAAA,OACAkU,EAAAR,cAAArH,aAAA,GAGA,IAAAkI,EAAAL,EAAAL,aAEA,GAAA3T,MAAAqU,EAKA,OAAAA,EAAAnC,MACA,KAAApV,EAAA4U,WAAAmB,KAEA,OADAmB,EAAAF,aACAhX,EAAA2O,YAAA0I,UACA,KAAArX,EAAA4U,WAAAkB,MAEA,OADAoB,EAAAF,aACAhX,EAAA2O,YAAAyI,WACA,KAAApX,EAAA4U,WAAAoB,cACA,OAAAhW,EAAA2O,YAAA+I,kBACA,KAAA1X,EAAA4U,WAAAqB,MACA,OAAAjW,EAAA2O,YAAAgJ,WACA,KAAA3X,EAAA4U,WAAAsB,SAEA,OADAgB,EAAAF,aACAhX,EAAA2O,YAAAwI,cACA,QACA,IAAAG,EAAA,2BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAApV,EAAA0U,gBAAA4C,EAAAC,EAAAhQ,MAAAgQ,EAAA/P,UApBA0P,EAAAF,eAwBAhX,EAAA2O,YAAA+I,kBAAA,SAAAR,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAA5T,MAAA6T,EAAA,CAIA,IAAAnL,EAAAgM,SAAAb,EAAAvS,IAAA,IAEA,GAAAqT,MAAAjM,GAAA,CACA,IAAA0L,EAAA,gCACA,MAAA,IAAAtX,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA0P,EAAAR,cAAA9K,aAAAA,EAEA,IAAA2L,EAAAL,EAAAL,aAEA,GAAA3T,MAAAqU,EAKA,OAAAA,EAAAnC,MACA,KAAApV,EAAA4U,WAAAmB,KAEA,OADAmB,EAAAF,aACAhX,EAAA2O,YAAA0I,UACA,KAAArX,EAAA4U,WAAAkB,MAEA,OADAoB,EAAAF,aACAhX,EAAA2O,YAAAyI,WACA,KAAApX,EAAA4U,WAAAoB,cACA,OAAAhW,EAAA2O,YAAA+I,kBACA,KAAA1X,EAAA4U,WAAAqB,MACA,OAAAjW,EAAA2O,YAAAgJ,WACA,KAAA3X,EAAA4U,WAAAsB,SAEA,OADAgB,EAAAF,aACAhX,EAAA2O,YAAAwI,cACA,QACAG,EAAA,2BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAApV,EAAA0U,gBAAA4C,EAAAC,EAAAhQ,MAAAgQ,EAAA/P,UApBA0P,EAAAF,eAwBAhX,EAAA2O,YAAAgJ,WAAA,SAAAT,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAA5T,MAAA6T,EAAA,CAIA,IAAA3G,EAAAwH,SAAAb,EAAAvS,IAAA,IAEA,GAAAqT,MAAAzH,GAAA,CACA,IAAAkH,EAAA,wBACA,MAAA,IAAAtX,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA0P,EAAAR,cAAAtG,MAAAA,EAEA,IAAAmH,EAAAL,EAAAL,aAEA,GAAA3T,MAAAqU,EAKA,OAAAA,EAAAnC,MACA,KAAApV,EAAA4U,WAAAmB,KAEA,OADAmB,EAAAF,aACAhX,EAAA2O,YAAA0I,UACA,KAAArX,EAAA4U,WAAAkB,MAEA,OADAoB,EAAAF,aACAhX,EAAA2O,YAAAyI,WACA,KAAApX,EAAA4U,WAAAoB,cACA,OAAAhW,EAAA2O,YAAA+I,kBACA,KAAA1X,EAAA4U,WAAAqB,MACA,OAAAjW,EAAA2O,YAAAgJ,WACA,KAAA3X,EAAA4U,WAAAsB,SAEA,OADAgB,EAAAF,aACAhX,EAAA2O,YAAAwI,cACA,QACAG,EAAA,2BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAApV,EAAA0U,gBAAA4C,EAAAC,EAAAhQ,MAAAgQ,EAAA/P,UApBA0P,EAAAF,eA4BAlX,EAeA7G,KAfA8G,EAeA,WAMA,OAAAC,GApBA,mBAAA8X,QAAAA,OAAAC,IAEAD,OAAA/X,GACA,iBAAAiY,QAMAC,OAAAD,QAAAjY,IAGAD,EAAAE,KAAAD,IA34GA,GCNAlJ,SAAAkC,iBAAA,mBAAA,WACA,IAAAmf,EAAArhB,SAAAJ,cAAA,2BACA0hB,EAAAthB,SAAAJ,cAAA,sCACA2hB,EAAAvhB,SAAAJ,cAAA,uCAEA,SAAA4hB,IACA,IAAAC,EAAAzhB,SAAAkD,eAAA,gBACAue,EAAAxgB,MAAA,GACAwgB,EAAAC,cAAA,IAAAC,cAAA,YAGA,SAAAC,EAAAje,GAEA,IAAAke,EAAAle,EAAAme,SAAAne,EAAAoe,MAIA,OAHA,KAGAF,GAFA,KAEAA,EAGA,SAAAG,IACA,IAAA3e,EAAArD,SAAAJ,cAAA,QACA0D,EAAAtD,SAAAJ,cAAA,qBACAqiB,EAAAjiB,SAAAJ,cAAA,gCACAsiB,EAAAliB,SAAAJ,cAAA,YACAqiB,EAAAviB,UAAAsD,SAAA,SACAif,EAAAviB,UAAAC,OAAA,QACA0D,EAAA3D,UAAAG,IAAA,QACAyD,EAAA5D,UAAAG,IAAA,QACAqiB,EAAAxiB,UAAAG,IAAA,UAEAoiB,EAAAviB,UAAAG,IAAA,QACAwD,EAAA3D,UAAAC,OAAA,QAGA,KAAA2B,OAAAwC,WACAR,EAAA5D,UAAAC,OAAA,QAEAuiB,EAAAxiB,UAAAC,OAAA,SAIA,IAAAwiB,EAAAniB,SAAAJ,cAAA,yBACAwiB,EAAApiB,SAAAJ,cAAA,iDACAuiB,EAAAziB,UAAAsD,SAAA,SACAmf,EAAAziB,UAAAC,OAAA,QACAyiB,EAAA1iB,UAAAG,IAAA,UAEAsiB,EAAAziB,UAAAG,IAAA,QACAuiB,EAAA1iB,UAAAC,OAAA,SAKA0hB,EAAAnf,iBAAA,QAAA8f,GACAX,EAAAnf,iBAAA,WAAA,SAAAyB,GACAie,EAAAje,IACAqe,MAGA,iBAAA1gB,QACA+f,EAAAnf,iBAAA,eAAA8f,GAIAV,EAAApf,iBAAA,QAAA8f,GACAV,EAAApf,iBAAA,WAAA,SAAAyB,GACAie,EAAAje,IACAqe,MAGA,iBAAA1gB,QACAggB,EAAApf,iBAAA,eAAA8f,GAIAT,EAAArf,iBAAA,QAAAsf,GACAD,EAAArf,iBAAA,WAAA,SAAAyB,GACAie,EAAAje,IACA6d,MAGA,iBAAAlgB,QACAigB,EAAArf,iBAAA,eAAAsf,KAMAlgB,OAAA+gB,WAAA,SAAAlZ,GACA,IAAAsY,EAAAzhB,SAAAkD,eAAA,gBACA+e,EAAAjiB,SAAAyE,cAAA,OACA6d,EAAAtiB,SAAAJ,cAAA,SAKA,SAAA2iB,EAAA9G,EAAAvK,GACA,IAAAsR,EAAA,GACA9R,EAAAQ,EAAA,GACA/P,EAAA+P,EAAA,GAEAlM,EAAAyW,EAAAzW,KACAyd,EAAAziB,SAAAyE,cAAA,QACAge,EAAA/iB,UAAAG,IAAA,2BACA4iB,EAAA/d,UAAAM,EAAAsF,OAAAoG,EAAAvP,GAEA,IAAAwP,EAAAD,EAAAvP,EACAuhB,EAAA1d,EAAA7D,OAAA,EAEAwhB,EAAAD,EAAA/R,EADA,GACA+R,EAAA/R,EADA,GAEAiS,EAAAlS,EAFA,GAEA,EAAA,EAAAA,EAFA,GAgBA,OAbA,IAAAA,GAAAC,IAAA+R,EACAF,EAAAvV,KAAAwV,GACA,IAAA/R,GACA8R,EAAAvV,KAAAwV,GACAD,EAAAvV,KAAAjN,SAAA6iB,eAAA7d,EAAAsF,OAAAqG,EAAAgS,MACAhS,IAAA+R,GACAF,EAAAvV,KAAAjN,SAAA6iB,eAAA7d,EAAAsF,OAAA,EAAAoG,KACA8R,EAAAvV,KAAAwV,KAEAD,EAAAvV,KAAAjN,SAAA6iB,eAAA,MAAA7d,EAAAsF,OAAAsY,EAAAlS,EAAAkS,KACAJ,EAAAvV,KAAAwV,GACAD,EAAAvV,KAAAjN,SAAA6iB,eAAA7d,EAAAsF,OAAAqG,EAAAgS,EAAAhS,GAAA,SAEA6R,EAGA,SAAAM,EAAAC,EAAAtH,EAAAvK,GACA,IAMA8R,EANAR,EAAA,GACA9R,EAAAQ,EAAA,GACA/P,EAAA+P,EAAA,GAEAuR,EAAAziB,SAAAyE,cAAA,QACAge,EAAA/iB,UAAAG,IAAA,2BAGAmjB,EADAD,EACAtH,EAAAwH,OAAAC,OAAA,SAAArgB,GACA,OAAAA,EAAA6D,KAAAqc,IACA,GAAA/d,KAEAyW,EAAAuH,MAEAP,EAAA/d,UAAAse,EAAA1Y,OAAAoG,EAAAvP,GAEA,IAAAwP,EAAAD,EAAAvP,EACAgiB,EAAAH,EAAA7hB,OAAA,EAcA,OAbA,IAAAuP,GAAAC,IAAAwS,EACAX,EAAAvV,KAAAwV,GACA,IAAA/R,GACA8R,EAAAvV,KAAAwV,GACAD,EAAAvV,KAAAjN,SAAA6iB,eAAAG,EAAA1Y,OAAAnJ,EAAAgiB,MACAxS,IAAAwS,GACAX,EAAAvV,KAAAjN,SAAA6iB,eAAAG,EAAA1Y,OAAA,EAAAoG,KACA8R,EAAAvV,KAAAwV,KAEAD,EAAAvV,KAAAjN,SAAA6iB,eAAAG,EAAA1Y,OAAA,EAAAoG,KACA8R,EAAAvV,KAAAwV,GACAD,EAAAvV,KAAAjN,SAAA6iB,eAAAG,EAAA1Y,OAAAqG,EAAAwS,MAEAX,EAsBA,SAAAY,EAAApT,EAAAqT,EAAAC,GACAtT,EAAAvP,QAAA,SAAAoC,GACA,IACAkgB,EADAQ,EAAA1gB,EAAA0X,IAEAgJ,EAAAC,SAAA,OACAT,EAAAQ,EAAAE,UAAAF,EAAApX,QAAA,KAAA,GACAoX,EAAAA,EAAA9Y,QAAA,IAAAsY,EAAA,KAEA,IAAAtH,EAAA4H,EAAAE,GAEAf,EA7BA,SAAA5U,EAAAmV,EAAAtH,GACA,IAAA+G,EAAA,GACA,IAAA,IAAArS,KAAAvC,EAAA,CACA,IAAA8J,EAAA9J,EAAAuC,GACA,IAAA,IAAA2I,KAAApB,EAAA,CACA,IAAAgM,EAAAhM,EAAAoB,GACA,GAAA4K,EAAAxS,SAAA,CACA,IAAAA,EAAAwS,EAAAxS,SAAA,GACA,UAAA4H,EACA0J,EAAAM,EAAAC,EAAAtH,EAAAvK,GACA,SAAA4H,IACA0J,EAAAD,EAAA9G,EAAAvK,MAKA,OAAAsR,EAaAmB,CADA9gB,EAAAwX,UAAAzM,SACAmV,EAAAtH,GACA6H,EAAArc,YAIA,SAAAwU,EAAA5Y,EAAA2f,GACA,IAAAoB,EAAA5jB,SAAAyE,cAAA,OACAmf,EAAAlkB,UAAAG,IAAA,gCACA+jB,EAAAlf,UAAA+W,EAAAuH,MACA,IAAAa,EAAA7jB,SAAAyE,cAAA,OACAof,EAAAnkB,UAAAG,IAAA,8BACA,IAAAikB,EAAA9jB,SAAAyE,cAAA,KACAqf,EAAAC,KAAAlhB,EAAA0X,IACAsJ,EAAA5c,YAAA6c,GACAtB,EAAA/hB,QAAA,SAAAujB,GACAF,EAAA7c,YAAA+c,KAEA,IAAAC,EAAAjkB,SAAAyE,cAAA,OAIA,OAHAwf,EAAAvkB,UAAAG,IAAA,sBACAokB,EAAAhd,YAAA2c,GACAK,EAAAhd,YAAA4c,GACAI,EApBAC,CAAAzI,EAAA5Y,EAAA2f,MAmDA,SAAA2B,EAAA1T,EAAA4S,EAAAre,GAEA,KAAAid,EAAAmC,YACAnC,EAAAoC,YAAApC,EAAAmC,YAEA,GAAA,KAAApf,EAAAkJ,OAAA,CAGA,IAxBAuC,EAAAzL,EAEAgL,EAsBAA,GAxBAhL,EAwBAA,EArBA,GADAgL,GAFAS,EAwBAA,GAtBAkH,OAAA3S,IACA7D,QAKA,GADA6O,EAAAS,EAAAkH,OAAA3S,EAAA,MACA7D,OAJA6O,EAQAA,EAAAS,EAAAkH,OAAA,IAAA3S,EAAA,MAaAse,EAAAtjB,SAAAyE,cAAA,OACA6e,EAAA5jB,UAAAG,IAAA,yBACAoiB,EAAAhb,YAAAqc,GACA,EAAAtT,EAAA7O,OACAiiB,EAAApT,EAAAqT,EAAAC,GAEAA,EAAArc,YA3CA,SAAAjC,GACA,IAAAif,EAAAjkB,SAAAyE,cAAA,OACAwf,EAAAvkB,UAAAG,IAAA,sBACA,IAAAgkB,EAAA7jB,SAAAyE,cAAA,OACAof,EAAAnkB,UAAAG,IAAA,8BACA,IAAAkL,EAAA/K,SAAAyE,cAAA,UAIA,OAHAsG,EAAArG,UAAA,+BAAAM,EAAA,IACA6e,EAAA5c,YAAA8D,GACAkZ,EAAAhd,YAAA4c,GACAI,EAkCAK,CAAAtf,KA6BA,OAnMAid,EAAAviB,UAAAG,IAAA,+BACAoiB,EAAAviB,UAAAG,IAAA,QACAyiB,EAAAzd,aAAAod,EAAAK,EAAA8B,YAiMA,CACAG,KAVA,SAAAC,GACA,IAjBAC,EAAAC,EAAAC,EACAC,EAgBAnU,EAAAlQ,OAAAskB,OAAA,CAAApU,MAAAtH,EAAAkO,MAAAnI,KAAAsV,EAAA/T,OAAA4S,MAAAmB,EAAAnB,QACA1L,GAlBA8M,EAkBA,WACAN,EAAA1T,EAAAA,MAAAA,EAAA4S,MAAA5B,EAAAxgB,QAnBAyjB,EAoBA,IAlBA,WACA,IAAAI,EAAA1iB,KACA4a,EAAA1N,UAKAyV,EAAAJ,IAAAC,EACAI,aAAAJ,GACAA,EAAA5d,WANA,WACA4d,EAAA,KACAD,GAAAF,EAAAvH,MAAA4H,EAAA9H,IAIA0H,GACAK,GAAAN,EAAAvH,MAAA4H,EAAA9H,KAUAyE,EAAAvf,iBAAA,UAAAyV,KApMA,CA0MArW,OAAA6H","file":"site.js","sourcesContent":[";(function () {\r\n  'use strict'\r\n\r\n  // expand nav to show current page\r\n  var currentPageItem = Array.from(document.querySelectorAll('.is-current-page')).pop().parentNode\r\n  expandParents(currentPageItem)\r\n\r\n  function expandParents(element) {\r\n    var panel = element.parentNode\r\n    if(!panel.matches(\".nav-children-panel\")){\r\n        return \r\n    }\r\n    var parentHeader = panel.previousElementSibling\r\n    panel.classList.remove('hide')\r\n    parentHeader.querySelector('.material-icons').classList.add('expanded')\r\n    expandParents(parentHeader)\r\n  }  \r\n\r\n  // persist version selections\r\n  var select = document.querySelectorAll('.select-version')\r\n  var versionVar = \"sdp-docs-versions\"\r\n  var versions = getVersions()\r\n\r\n  if (!versions){\r\n    versions = {}\r\n    for(var i = 0; i < select.length; i++){\r\n      versions[select[i].getAttribute('data-component')] = 0 \r\n    }\r\n    setVersions(versions)\r\n  } else { \r\n    Object.entries(versions).forEach(function(component){\r\n      var componentName = component[0]\r\n      var componentVersionIndex = component[1] \r\n      var componentSelectVersion = document.querySelector('select[data-component=\"' + componentName + '\"]')\r\n      componentSelectVersion.selectedIndex = componentVersionIndex\r\n      var componentVersion = componentSelectVersion.options[componentVersionIndex].value\r\n      setComponentVersion(componentName, componentVersion)\r\n    })\r\n  }\r\n\r\n  function setVersions(versions){\r\n    return window.sessionStorage.setItem(versionVar, JSON.stringify(versions))\r\n  }\r\n\r\n  function getVersions(){\r\n    return JSON.parse(window.sessionStorage.getItem(versionVar))\r\n  }\r\n\r\n  function setComponentVersion(component, version){\r\n    var showSelector = '.nav-container div[data-component=\"' + component + '\"][data-version=\"' + version + '\"]'\r\n    var hideSelector = '.nav-container div[data-component=\"' + component + '\"]:not(.hide)'\r\n    var navShow = document.querySelector(showSelector)\r\n    var navHide = document.querySelector(hideSelector)\r\n    navHide.classList.add('hide')\r\n    navShow.classList.remove('hide')\r\n  }\r\n\r\n  for(var i = 0; i < select.length; i++){\r\n    var s = select[i]\r\n    s.addEventListener('change', function(event){\r\n      var component = this.getAttribute('data-component')\r\n      var versionIndex = this.selectedIndex\r\n      var version = this.options[versionIndex].value\r\n      var versions = getVersions()\r\n      versions[component] = versionIndex\r\n      setVersions(versions)\r\n      setComponentVersion(component, version)\r\n    })\r\n\r\n    // Disable select if there is only one version\r\n    if (s.options.length === 1) {\r\n      s.classList.add('single-version');\r\n      s.disabled = true;\r\n    }\r\n  }\r\n\r\n\r\n  /// nav-tree\r\n  var x = document.querySelectorAll('.nav-item:not(.is-link), .nav-item.is-link .material-icons'); \r\n  for(var i = 0; i < x.length; i++){\r\n    mdc.ripple.MDCRipple.attachTo(x[i])\r\n    x[i].addEventListener('click', function(event){\r\n      var target = event.target\r\n      var item = target.matches('span') ? target.previousElementSibling : target\r\n      var panel = item.parentElement.nextElementSibling\r\n      if(item.classList.contains('expanded')){\r\n        item.classList.remove('expanded')\r\n        panel.classList.add('hide')\r\n      } else{\r\n        item.classList.add('expanded')\r\n        panel.classList.remove('hide')\r\n      }\r\n    })\r\n  }\r\n\r\n  // toolbar menu button \r\n  var navToggle = document.getElementById('toolbar-nav-toggle')\r\n  mdc.iconButton.MDCIconButtonToggle.attachTo(navToggle)\r\n  navToggle.addEventListener('click', function(){\r\n    // Toggle navigation and main content together\r\n    var mainContainer = document.querySelector('main')\r\n    var navContainer = document.querySelector('div.nav-container')\r\n    if(navContainer.classList.contains('hide')){\r\n      mainContainer.classList.add('hide')\r\n      navContainer.classList.remove('hide')\r\n\r\n    } else{\r\n      mainContainer.classList.remove('hide')\r\n      navContainer.classList.add('hide')\r\n    }\r\n  })\r\n\r\n})()\r\n","mdc.topAppBar.MDCTopAppBar.attachTo(document.querySelector('.mdc-top-app-bar'))",";(function () {\r\n  'use strict'\r\n\r\n  var toggle = document.querySelector('.page-versions .version-menu-toggle')\r\n  if (!toggle) return\r\n\r\n  var selector = document.querySelector('.page-versions')\r\n\r\n  toggle.addEventListener('click', function (e) {\r\n    selector.classList.toggle('is-active')\r\n    // don't let this event get smothered\r\n    e.stopPropagation()\r\n  })\r\n\r\n  document.documentElement.addEventListener('click', function () {\r\n    selector.classList.remove('is-active')\r\n  })\r\n})()\r\n","document.addEventListener('DOMContentLoaded', function () {\r\n  // Hide navbar on mobile\r\n  if (window.innerWidth <= 1024) {\r\n    var navContainer = document.querySelector('div.nav-container')\r\n    navContainer.classList.add('hide')\r\n  }\r\n\r\n  // Add event listeners to hamburger icons\r\n  var navbarToggles = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0)\r\n  if (navbarToggles.length === 0) return\r\n  navbarToggles.forEach(function (el) {\r\n    el.addEventListener('click', function (e) {\r\n      e.stopPropagation()\r\n      el.classList.toggle('is-active')\r\n      document.getElementById(el.dataset.target).classList.toggle('is-active')\r\n      document.documentElement.classList.toggle('is-clipped--navbar')\r\n    })\r\n  })\r\n})\r\n\r\n\r\nwindow.addEventListener('resize', function () {\r\n  // Only expand/unhide elements on resize if search isn't open\r\n  var searchTopBar = document.querySelector('.mdc-top-app-bar__row.sdp-top-app-bar__search')\r\n  if (searchTopBar.classList.contains('hide')) {\r\n    // Unhide main content\r\n    var mainContainer = document.querySelector('main')\r\n    if (mainContainer.classList.contains('hide')) {\r\n      mainContainer.classList.remove('hide')\r\n    }\r\n\r\n    // Expand navbar if window is resized from mobile to desktop\r\n    var navContainer = document.querySelector('div.nav-container')\r\n    if (window.innerWidth > 1024) {\r\n      if (navContainer.classList.contains('hide')) {\r\n        navContainer.classList.remove('hide')\r\n      }\r\n    }\r\n  }\r\n\r\n  // Hide navbar if window is resized from desktop to mobile\r\n  if (window.innerWidth < 1025) {\r\n    if (!navContainer.classList.contains('hide')) {\r\n      navContainer.classList.add('hide')\r\n    }\r\n  }\r\n});\r\n",";(function () {\r\n  \r\n  hljs.initHighlighting()\r\n\r\n})()\r\n  ",";(function () {\r\n    'use strict'\r\n    // <i class=\"material-icons mdc-icon-button search\" tabindex=\"0\" role=\"button\">search</i>\r\n    var codeBlocks = document.querySelectorAll('.doc .listingblock code')\r\n    var copyIcon = document.createElement('i')\r\n    copyIcon.classList = 'material-icons codeCopyButton'\r\n    copyIcon.innerText = 'file_copy'\r\n    for (var i = 0; i < codeBlocks.length; i++) {\r\n      var icon = copyIcon.cloneNode(true)\r\n      codeBlocks[i].insertBefore(icon, codeBlocks[i].childNodes[0])\r\n    }\r\n \r\n    /*global ClipboardJS*/\r\n    var clipboard = new ClipboardJS('.material-icons.codeCopyButton', {\r\n      text: function (target) { \r\n        var lines = target.parentNode.innerText.split(\"\\n\")\r\n        lines.splice(0,1)\r\n        return lines.join(\"\\n\") \r\n      },\r\n    })\r\n  \r\n    clipboard.on('success', function (e) {\r\n      e.trigger._tippy.setContent('copied!')\r\n    })\r\n  \r\n    tippy.delegate('.doc .listingblock code', {\r\n      target: '.material-icons.codeCopyButton',\r\n      content: 'copy to clipboard',\r\n      animation: 'shift-away',\r\n      theme: 'clipboard',\r\n      delay: [500, 0],\r\n      placement: 'bottom',\r\n      hideOnClick: false,\r\n      onHidden: function (instance) {\r\n        instance.setContent('copy to clipboard')\r\n      },\r\n    })\r\n  })()\r\n  ",";(function () {\r\n  'use strict'\r\n\r\n  // create table of contents \r\n  var headers = document.querySelector('.doc .contents').querySelectorAll('h1, h2, h3, h4, h5, h6')\r\n  var toc = document.getElementById('toc')\r\n  for(var i = 0; i < headers.length; i++){\r\n      var header = headers[i]        \r\n      var li = document.createElement('li')\r\n      li.classList.add('toc-item')\r\n      li.classList.add(header.tagName)\r\n      li.innerText = header.innerText \r\n      li.setAttribute('headerId', header.getAttribute('id'))\r\n      li.addEventListener('click', function() {\r\n          var h, id = this.getAttribute('headerId')\r\n          if(id != 'null'){ h = document.getElementById(id) } \r\n          else { h = document.querySelector('h1') }\r\n          window.scroll({\r\n              top: h.offsetTop + 30, // 30 to account for fixed header height \r\n              left: 0,\r\n              behavior: 'smooth'\r\n          })\r\n          h.classList.add('toc-highlight')\r\n          setTimeout(function(){ h.classList.remove('toc-highlight') }, 2000)\r\n      })\r\n      toc.appendChild(li)\r\n  }\r\n\r\n  // enable highlighted toc\r\n  var referenceElement = document.querySelector('article').parentNode\r\n  window.addEventListener('scroll', function () {\r\n    var activeHeader, lastActiveHeader = document.querySelector('.toc-item.active')\r\n    var referencePoint = referenceElement.offsetTop + 108.1 \r\n    for (var i = (headers.length - 1); i >= 0; i--) {\r\n      var hTop = headers[i].getBoundingClientRect().top\r\n      if (hTop < referencePoint) {\r\n        var activeId = headers[i].getAttribute('id')\r\n        activeHeader = document.querySelector('.toc-item[headerId=\"' + activeId + '\"]')\r\n        break\r\n      }\r\n    }\r\n\r\n    // there is currently an active header and it has changed\r\n    if(activeHeader && activeHeader !== lastActiveHeader){\r\n      activeHeader.classList.add('active')\r\n      if(lastActiveHeader){\r\n        lastActiveHeader.classList.remove('active')\r\n      }\r\n    }\r\n  })\r\n\r\n})()\r\n  ","/**\r\n * lunr - http://lunrjs.com - A bit like Solr, but much smaller and not as bright - 2.3.3\r\n * Copyright (C) 2018 Oliver Nightingale\r\n * @license MIT\r\n */\r\n\r\n;(function(){\r\n\r\n  /**\r\n   * A convenience function for configuring and constructing\r\n   * a new lunr Index.\r\n   *\r\n   * A lunr.Builder instance is created and the pipeline setup\r\n   * with a trimmer, stop word filter and stemmer.\r\n   *\r\n   * This builder object is yielded to the configuration function\r\n   * that is passed as a parameter, allowing the list of fields\r\n   * and other builder parameters to be customised.\r\n   *\r\n   * All documents _must_ be added within the passed config function.\r\n   *\r\n   * @example\r\n   * var idx = lunr(function () {\r\n   *   this.field('title')\r\n   *   this.field('body')\r\n   *   this.ref('id')\r\n   *\r\n   *   documents.forEach(function (doc) {\r\n   *     this.add(doc)\r\n   *   }, this)\r\n   * })\r\n   *\r\n   * @see {@link lunr.Builder}\r\n   * @see {@link lunr.Pipeline}\r\n   * @see {@link lunr.trimmer}\r\n   * @see {@link lunr.stopWordFilter}\r\n   * @see {@link lunr.stemmer}\r\n   * @namespace {function} lunr\r\n   */\r\n  var lunr = function (config) {\r\n    var builder = new lunr.Builder\r\n  \r\n    builder.pipeline.add(\r\n      lunr.trimmer,\r\n      lunr.stopWordFilter,\r\n      lunr.stemmer\r\n    )\r\n  \r\n    builder.searchPipeline.add(\r\n      lunr.stemmer\r\n    )\r\n  \r\n    config.call(builder, builder)\r\n    return builder.build()\r\n  }\r\n  \r\n  lunr.version = \"2.3.3\"\r\n  /*!\r\n   * lunr.utils\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   */\r\n  \r\n  /**\r\n   * A namespace containing utils for the rest of the lunr library\r\n   * @namespace lunr.utils\r\n   */\r\n  lunr.utils = {}\r\n  \r\n  /**\r\n   * Print a warning message to the console.\r\n   *\r\n   * @param {String} message The message to be printed.\r\n   * @memberOf lunr.utils\r\n   * @function\r\n   */\r\n  lunr.utils.warn = (function (global) {\r\n    /* eslint-disable no-console */\r\n    return function (message) {\r\n      if (global.console && console.warn) {\r\n        console.warn(message)\r\n      }\r\n    }\r\n    /* eslint-enable no-console */\r\n  })(this)\r\n  \r\n  /**\r\n   * Convert an object to a string.\r\n   *\r\n   * In the case of `null` and `undefined` the function returns\r\n   * the empty string, in all other cases the result of calling\r\n   * `toString` on the passed object is returned.\r\n   *\r\n   * @param {Any} obj The object to convert to a string.\r\n   * @return {String} string representation of the passed object.\r\n   * @memberOf lunr.utils\r\n   */\r\n  lunr.utils.asString = function (obj) {\r\n    if (obj === void 0 || obj === null) {\r\n      return \"\"\r\n    } else {\r\n      return obj.toString()\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * Clones an object.\r\n   *\r\n   * Will create a copy of an existing object such that any mutations\r\n   * on the copy cannot affect the original.\r\n   *\r\n   * Only shallow objects are supported, passing a nested object to this\r\n   * function will cause a TypeError.\r\n   *\r\n   * Objects with primitives, and arrays of primitives are supported.\r\n   *\r\n   * @param {Object} obj The object to clone.\r\n   * @return {Object} a clone of the passed object.\r\n   * @throws {TypeError} when a nested object is passed.\r\n   * @memberOf Utils\r\n   */\r\n  lunr.utils.clone = function (obj) {\r\n    if (obj === null || obj === undefined) {\r\n      return obj\r\n    }\r\n  \r\n    var clone = Object.create(null),\r\n        keys = Object.keys(obj)\r\n  \r\n    for (var i = 0; i < keys.length; i++) {\r\n      var key = keys[i],\r\n          val = obj[key]\r\n  \r\n      if (Array.isArray(val)) {\r\n        clone[key] = val.slice()\r\n        continue\r\n      }\r\n  \r\n      if (typeof val === 'string' ||\r\n          typeof val === 'number' ||\r\n          typeof val === 'boolean') {\r\n        clone[key] = val\r\n        continue\r\n      }\r\n  \r\n      throw new TypeError(\"clone is not deep and does not support nested objects\")\r\n    }\r\n  \r\n    return clone\r\n  }\r\n  lunr.FieldRef = function (docRef, fieldName, stringValue) {\r\n    this.docRef = docRef\r\n    this.fieldName = fieldName\r\n    this._stringValue = stringValue\r\n  }\r\n  \r\n  lunr.FieldRef.joiner = \"/\"\r\n  \r\n  lunr.FieldRef.fromString = function (s) {\r\n    var n = s.indexOf(lunr.FieldRef.joiner)\r\n  \r\n    if (n === -1) {\r\n      throw \"malformed field ref string\"\r\n    }\r\n  \r\n    var fieldRef = s.slice(0, n),\r\n        docRef = s.slice(n + 1)\r\n  \r\n    return new lunr.FieldRef (docRef, fieldRef, s)\r\n  }\r\n  \r\n  lunr.FieldRef.prototype.toString = function () {\r\n    if (this._stringValue == undefined) {\r\n      this._stringValue = this.fieldName + lunr.FieldRef.joiner + this.docRef\r\n    }\r\n  \r\n    return this._stringValue\r\n  }\r\n  /*!\r\n   * lunr.Set\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   */\r\n  \r\n  /**\r\n   * A lunr set.\r\n   *\r\n   * @constructor\r\n   */\r\n  lunr.Set = function (elements) {\r\n    this.elements = Object.create(null)\r\n  \r\n    if (elements) {\r\n      this.length = elements.length\r\n  \r\n      for (var i = 0; i < this.length; i++) {\r\n        this.elements[elements[i]] = true\r\n      }\r\n    } else {\r\n      this.length = 0\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * A complete set that contains all elements.\r\n   *\r\n   * @static\r\n   * @readonly\r\n   * @type {lunr.Set}\r\n   */\r\n  lunr.Set.complete = {\r\n    intersect: function (other) {\r\n      return other\r\n    },\r\n  \r\n    union: function (other) {\r\n      return other\r\n    },\r\n  \r\n    contains: function () {\r\n      return true\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * An empty set that contains no elements.\r\n   *\r\n   * @static\r\n   * @readonly\r\n   * @type {lunr.Set}\r\n   */\r\n  lunr.Set.empty = {\r\n    intersect: function () {\r\n      return this\r\n    },\r\n  \r\n    union: function (other) {\r\n      return other\r\n    },\r\n  \r\n    contains: function () {\r\n      return false\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * Returns true if this set contains the specified object.\r\n   *\r\n   * @param {object} object - Object whose presence in this set is to be tested.\r\n   * @returns {boolean} - True if this set contains the specified object.\r\n   */\r\n  lunr.Set.prototype.contains = function (object) {\r\n    return !!this.elements[object]\r\n  }\r\n  \r\n  /**\r\n   * Returns a new set containing only the elements that are present in both\r\n   * this set and the specified set.\r\n   *\r\n   * @param {lunr.Set} other - set to intersect with this set.\r\n   * @returns {lunr.Set} a new set that is the intersection of this and the specified set.\r\n   */\r\n  \r\n  lunr.Set.prototype.intersect = function (other) {\r\n    var a, b, elements, intersection = []\r\n  \r\n    if (other === lunr.Set.complete) {\r\n      return this\r\n    }\r\n  \r\n    if (other === lunr.Set.empty) {\r\n      return other\r\n    }\r\n  \r\n    if (this.length < other.length) {\r\n      a = this\r\n      b = other\r\n    } else {\r\n      a = other\r\n      b = this\r\n    }\r\n  \r\n    elements = Object.keys(a.elements)\r\n  \r\n    for (var i = 0; i < elements.length; i++) {\r\n      var element = elements[i]\r\n      if (element in b.elements) {\r\n        intersection.push(element)\r\n      }\r\n    }\r\n  \r\n    return new lunr.Set (intersection)\r\n  }\r\n  \r\n  /**\r\n   * Returns a new set combining the elements of this and the specified set.\r\n   *\r\n   * @param {lunr.Set} other - set to union with this set.\r\n   * @return {lunr.Set} a new set that is the union of this and the specified set.\r\n   */\r\n  \r\n  lunr.Set.prototype.union = function (other) {\r\n    if (other === lunr.Set.complete) {\r\n      return lunr.Set.complete\r\n    }\r\n  \r\n    if (other === lunr.Set.empty) {\r\n      return this\r\n    }\r\n  \r\n    return new lunr.Set(Object.keys(this.elements).concat(Object.keys(other.elements)))\r\n  }\r\n  /**\r\n   * A function to calculate the inverse document frequency for\r\n   * a posting. This is shared between the builder and the index\r\n   *\r\n   * @private\r\n   * @param {object} posting - The posting for a given term\r\n   * @param {number} documentCount - The total number of documents.\r\n   */\r\n  lunr.idf = function (posting, documentCount) {\r\n    var documentsWithTerm = 0\r\n  \r\n    for (var fieldName in posting) {\r\n      if (fieldName == '_index') continue // Ignore the term index, its not a field\r\n      documentsWithTerm += Object.keys(posting[fieldName]).length\r\n    }\r\n  \r\n    var x = (documentCount - documentsWithTerm + 0.5) / (documentsWithTerm + 0.5)\r\n  \r\n    return Math.log(1 + Math.abs(x))\r\n  }\r\n  \r\n  /**\r\n   * A token wraps a string representation of a token\r\n   * as it is passed through the text processing pipeline.\r\n   *\r\n   * @constructor\r\n   * @param {string} [str=''] - The string token being wrapped.\r\n   * @param {object} [metadata={}] - Metadata associated with this token.\r\n   */\r\n  lunr.Token = function (str, metadata) {\r\n    this.str = str || \"\"\r\n    this.metadata = metadata || {}\r\n  }\r\n  \r\n  /**\r\n   * Returns the token string that is being wrapped by this object.\r\n   *\r\n   * @returns {string}\r\n   */\r\n  lunr.Token.prototype.toString = function () {\r\n    return this.str\r\n  }\r\n  \r\n  /**\r\n   * A token update function is used when updating or optionally\r\n   * when cloning a token.\r\n   *\r\n   * @callback lunr.Token~updateFunction\r\n   * @param {string} str - The string representation of the token.\r\n   * @param {Object} metadata - All metadata associated with this token.\r\n   */\r\n  \r\n  /**\r\n   * Applies the given function to the wrapped string token.\r\n   *\r\n   * @example\r\n   * token.update(function (str, metadata) {\r\n   *   return str.toUpperCase()\r\n   * })\r\n   *\r\n   * @param {lunr.Token~updateFunction} fn - A function to apply to the token string.\r\n   * @returns {lunr.Token}\r\n   */\r\n  lunr.Token.prototype.update = function (fn) {\r\n    this.str = fn(this.str, this.metadata)\r\n    return this\r\n  }\r\n  \r\n  /**\r\n   * Creates a clone of this token. Optionally a function can be\r\n   * applied to the cloned token.\r\n   *\r\n   * @param {lunr.Token~updateFunction} [fn] - An optional function to apply to the cloned token.\r\n   * @returns {lunr.Token}\r\n   */\r\n  lunr.Token.prototype.clone = function (fn) {\r\n    fn = fn || function (s) { return s }\r\n    return new lunr.Token (fn(this.str, this.metadata), this.metadata)\r\n  }\r\n  /*!\r\n   * lunr.tokenizer\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   */\r\n  \r\n  /**\r\n   * A function for splitting a string into tokens ready to be inserted into\r\n   * the search index. Uses `lunr.tokenizer.separator` to split strings, change\r\n   * the value of this property to change how strings are split into tokens.\r\n   *\r\n   * This tokenizer will convert its parameter to a string by calling `toString` and\r\n   * then will split this string on the character in `lunr.tokenizer.separator`.\r\n   * Arrays will have their elements converted to strings and wrapped in a lunr.Token.\r\n   *\r\n   * Optional metadata can be passed to the tokenizer, this metadata will be cloned and\r\n   * added as metadata to every token that is created from the object to be tokenized.\r\n   *\r\n   * @static\r\n   * @param {?(string|object|object[])} obj - The object to convert into tokens\r\n   * @param {?object} metadata - Optional metadata to associate with every token\r\n   * @returns {lunr.Token[]}\r\n   * @see {@link lunr.Pipeline}\r\n   */\r\n  lunr.tokenizer = function (obj, metadata) {\r\n    if (obj == null || obj == undefined) {\r\n      return []\r\n    }\r\n  \r\n    if (Array.isArray(obj)) {\r\n      return obj.map(function (t) {\r\n        return new lunr.Token(\r\n          lunr.utils.asString(t).toLowerCase(),\r\n          lunr.utils.clone(metadata)\r\n        )\r\n      })\r\n    }\r\n  \r\n    var str = obj.toString().trim().toLowerCase(),\r\n        len = str.length,\r\n        tokens = []\r\n  \r\n    for (var sliceEnd = 0, sliceStart = 0; sliceEnd <= len; sliceEnd++) {\r\n      var char = str.charAt(sliceEnd),\r\n          sliceLength = sliceEnd - sliceStart\r\n  \r\n      if ((char.match(lunr.tokenizer.separator) || sliceEnd == len)) {\r\n  \r\n        if (sliceLength > 0) {\r\n          var tokenMetadata = lunr.utils.clone(metadata) || {}\r\n          tokenMetadata[\"position\"] = [sliceStart, sliceLength]\r\n          tokenMetadata[\"index\"] = tokens.length\r\n  \r\n          tokens.push(\r\n            new lunr.Token (\r\n              str.slice(sliceStart, sliceEnd),\r\n              tokenMetadata\r\n            )\r\n          )\r\n        }\r\n  \r\n        sliceStart = sliceEnd + 1\r\n      }\r\n  \r\n    }\r\n  \r\n    return tokens\r\n  }\r\n  \r\n  /**\r\n   * The separator used to split a string into tokens. Override this property to change the behaviour of\r\n   * `lunr.tokenizer` behaviour when tokenizing strings. By default this splits on whitespace and hyphens.\r\n   *\r\n   * @static\r\n   * @see lunr.tokenizer\r\n   */\r\n  lunr.tokenizer.separator = /[\\s\\-]+/\r\n  /*!\r\n   * lunr.Pipeline\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   */\r\n  \r\n  /**\r\n   * lunr.Pipelines maintain an ordered list of functions to be applied to all\r\n   * tokens in documents entering the search index and queries being ran against\r\n   * the index.\r\n   *\r\n   * An instance of lunr.Index created with the lunr shortcut will contain a\r\n   * pipeline with a stop word filter and an English language stemmer. Extra\r\n   * functions can be added before or after either of these functions or these\r\n   * default functions can be removed.\r\n   *\r\n   * When run the pipeline will call each function in turn, passing a token, the\r\n   * index of that token in the original list of all tokens and finally a list of\r\n   * all the original tokens.\r\n   *\r\n   * The output of functions in the pipeline will be passed to the next function\r\n   * in the pipeline. To exclude a token from entering the index the function\r\n   * should return undefined, the rest of the pipeline will not be called with\r\n   * this token.\r\n   *\r\n   * For serialisation of pipelines to work, all functions used in an instance of\r\n   * a pipeline should be registered with lunr.Pipeline. Registered functions can\r\n   * then be loaded. If trying to load a serialised pipeline that uses functions\r\n   * that are not registered an error will be thrown.\r\n   *\r\n   * If not planning on serialising the pipeline then registering pipeline functions\r\n   * is not necessary.\r\n   *\r\n   * @constructor\r\n   */\r\n  lunr.Pipeline = function () {\r\n    this._stack = []\r\n  }\r\n  \r\n  lunr.Pipeline.registeredFunctions = Object.create(null)\r\n  \r\n  /**\r\n   * A pipeline function maps lunr.Token to lunr.Token. A lunr.Token contains the token\r\n   * string as well as all known metadata. A pipeline function can mutate the token string\r\n   * or mutate (or add) metadata for a given token.\r\n   *\r\n   * A pipeline function can indicate that the passed token should be discarded by returning\r\n   * null. This token will not be passed to any downstream pipeline functions and will not be\r\n   * added to the index.\r\n   *\r\n   * Multiple tokens can be returned by returning an array of tokens. Each token will be passed\r\n   * to any downstream pipeline functions and all will returned tokens will be added to the index.\r\n   *\r\n   * Any number of pipeline functions may be chained together using a lunr.Pipeline.\r\n   *\r\n   * @interface lunr.PipelineFunction\r\n   * @param {lunr.Token} token - A token from the document being processed.\r\n   * @param {number} i - The index of this token in the complete list of tokens for this document/field.\r\n   * @param {lunr.Token[]} tokens - All tokens for this document/field.\r\n   * @returns {(?lunr.Token|lunr.Token[])}\r\n   */\r\n  \r\n  /**\r\n   * Register a function with the pipeline.\r\n   *\r\n   * Functions that are used in the pipeline should be registered if the pipeline\r\n   * needs to be serialised, or a serialised pipeline needs to be loaded.\r\n   *\r\n   * Registering a function does not add it to a pipeline, functions must still be\r\n   * added to instances of the pipeline for them to be used when running a pipeline.\r\n   *\r\n   * @param {lunr.PipelineFunction} fn - The function to check for.\r\n   * @param {String} label - The label to register this function with\r\n   */\r\n  lunr.Pipeline.registerFunction = function (fn, label) {\r\n    if (label in this.registeredFunctions) {\r\n      lunr.utils.warn('Overwriting existing registered function: ' + label)\r\n    }\r\n  \r\n    fn.label = label\r\n    lunr.Pipeline.registeredFunctions[fn.label] = fn\r\n  }\r\n  \r\n  /**\r\n   * Warns if the function is not registered as a Pipeline function.\r\n   *\r\n   * @param {lunr.PipelineFunction} fn - The function to check for.\r\n   * @private\r\n   */\r\n  lunr.Pipeline.warnIfFunctionNotRegistered = function (fn) {\r\n    var isRegistered = fn.label && (fn.label in this.registeredFunctions)\r\n  \r\n    if (!isRegistered) {\r\n      lunr.utils.warn('Function is not registered with pipeline. This may cause problems when serialising the index.\\n', fn)\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * Loads a previously serialised pipeline.\r\n   *\r\n   * All functions to be loaded must already be registered with lunr.Pipeline.\r\n   * If any function from the serialised data has not been registered then an\r\n   * error will be thrown.\r\n   *\r\n   * @param {Object} serialised - The serialised pipeline to load.\r\n   * @returns {lunr.Pipeline}\r\n   */\r\n  lunr.Pipeline.load = function (serialised) {\r\n    var pipeline = new lunr.Pipeline\r\n  \r\n    serialised.forEach(function (fnName) {\r\n      var fn = lunr.Pipeline.registeredFunctions[fnName]\r\n  \r\n      if (fn) {\r\n        pipeline.add(fn)\r\n      } else {\r\n        throw new Error('Cannot load unregistered function: ' + fnName)\r\n      }\r\n    })\r\n  \r\n    return pipeline\r\n  }\r\n  \r\n  /**\r\n   * Adds new functions to the end of the pipeline.\r\n   *\r\n   * Logs a warning if the function has not been registered.\r\n   *\r\n   * @param {lunr.PipelineFunction[]} functions - Any number of functions to add to the pipeline.\r\n   */\r\n  lunr.Pipeline.prototype.add = function () {\r\n    var fns = Array.prototype.slice.call(arguments)\r\n  \r\n    fns.forEach(function (fn) {\r\n      lunr.Pipeline.warnIfFunctionNotRegistered(fn)\r\n      this._stack.push(fn)\r\n    }, this)\r\n  }\r\n  \r\n  /**\r\n   * Adds a single function after a function that already exists in the\r\n   * pipeline.\r\n   *\r\n   * Logs a warning if the function has not been registered.\r\n   *\r\n   * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\r\n   * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\r\n   */\r\n  lunr.Pipeline.prototype.after = function (existingFn, newFn) {\r\n    lunr.Pipeline.warnIfFunctionNotRegistered(newFn)\r\n  \r\n    var pos = this._stack.indexOf(existingFn)\r\n    if (pos == -1) {\r\n      throw new Error('Cannot find existingFn')\r\n    }\r\n  \r\n    pos = pos + 1\r\n    this._stack.splice(pos, 0, newFn)\r\n  }\r\n  \r\n  /**\r\n   * Adds a single function before a function that already exists in the\r\n   * pipeline.\r\n   *\r\n   * Logs a warning if the function has not been registered.\r\n   *\r\n   * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\r\n   * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\r\n   */\r\n  lunr.Pipeline.prototype.before = function (existingFn, newFn) {\r\n    lunr.Pipeline.warnIfFunctionNotRegistered(newFn)\r\n  \r\n    var pos = this._stack.indexOf(existingFn)\r\n    if (pos == -1) {\r\n      throw new Error('Cannot find existingFn')\r\n    }\r\n  \r\n    this._stack.splice(pos, 0, newFn)\r\n  }\r\n  \r\n  /**\r\n   * Removes a function from the pipeline.\r\n   *\r\n   * @param {lunr.PipelineFunction} fn The function to remove from the pipeline.\r\n   */\r\n  lunr.Pipeline.prototype.remove = function (fn) {\r\n    var pos = this._stack.indexOf(fn)\r\n    if (pos == -1) {\r\n      return\r\n    }\r\n  \r\n    this._stack.splice(pos, 1)\r\n  }\r\n  \r\n  /**\r\n   * Runs the current list of functions that make up the pipeline against the\r\n   * passed tokens.\r\n   *\r\n   * @param {Array} tokens The tokens to run through the pipeline.\r\n   * @returns {Array}\r\n   */\r\n  lunr.Pipeline.prototype.run = function (tokens) {\r\n    var stackLength = this._stack.length\r\n  \r\n    for (var i = 0; i < stackLength; i++) {\r\n      var fn = this._stack[i]\r\n      var memo = []\r\n  \r\n      for (var j = 0; j < tokens.length; j++) {\r\n        var result = fn(tokens[j], j, tokens)\r\n  \r\n        if (result === void 0 || result === '') continue\r\n  \r\n        if (result instanceof Array) {\r\n          for (var k = 0; k < result.length; k++) {\r\n            memo.push(result[k])\r\n          }\r\n        } else {\r\n          memo.push(result)\r\n        }\r\n      }\r\n  \r\n      tokens = memo\r\n    }\r\n  \r\n    return tokens\r\n  }\r\n  \r\n  /**\r\n   * Convenience method for passing a string through a pipeline and getting\r\n   * strings out. This method takes care of wrapping the passed string in a\r\n   * token and mapping the resulting tokens back to strings.\r\n   *\r\n   * @param {string} str - The string to pass through the pipeline.\r\n   * @param {?object} metadata - Optional metadata to associate with the token\r\n   * passed to the pipeline.\r\n   * @returns {string[]}\r\n   */\r\n  lunr.Pipeline.prototype.runString = function (str, metadata) {\r\n    var token = new lunr.Token (str, metadata)\r\n  \r\n    return this.run([token]).map(function (t) {\r\n      return t.toString()\r\n    })\r\n  }\r\n  \r\n  /**\r\n   * Resets the pipeline by removing any existing processors.\r\n   *\r\n   */\r\n  lunr.Pipeline.prototype.reset = function () {\r\n    this._stack = []\r\n  }\r\n  \r\n  /**\r\n   * Returns a representation of the pipeline ready for serialisation.\r\n   *\r\n   * Logs a warning if the function has not been registered.\r\n   *\r\n   * @returns {Array}\r\n   */\r\n  lunr.Pipeline.prototype.toJSON = function () {\r\n    return this._stack.map(function (fn) {\r\n      lunr.Pipeline.warnIfFunctionNotRegistered(fn)\r\n  \r\n      return fn.label\r\n    })\r\n  }\r\n  /*!\r\n   * lunr.Vector\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   */\r\n  \r\n  /**\r\n   * A vector is used to construct the vector space of documents and queries. These\r\n   * vectors support operations to determine the similarity between two documents or\r\n   * a document and a query.\r\n   *\r\n   * Normally no parameters are required for initializing a vector, but in the case of\r\n   * loading a previously dumped vector the raw elements can be provided to the constructor.\r\n   *\r\n   * For performance reasons vectors are implemented with a flat array, where an elements\r\n   * index is immediately followed by its value. E.g. [index, value, index, value]. This\r\n   * allows the underlying array to be as sparse as possible and still offer decent\r\n   * performance when being used for vector calculations.\r\n   *\r\n   * @constructor\r\n   * @param {Number[]} [elements] - The flat list of element index and element value pairs.\r\n   */\r\n  lunr.Vector = function (elements) {\r\n    this._magnitude = 0\r\n    this.elements = elements || []\r\n  }\r\n  \r\n  \r\n  /**\r\n   * Calculates the position within the vector to insert a given index.\r\n   *\r\n   * This is used internally by insert and upsert. If there are duplicate indexes then\r\n   * the position is returned as if the value for that index were to be updated, but it\r\n   * is the callers responsibility to check whether there is a duplicate at that index\r\n   *\r\n   * @param {Number} insertIdx - The index at which the element should be inserted.\r\n   * @returns {Number}\r\n   */\r\n  lunr.Vector.prototype.positionForIndex = function (index) {\r\n    // For an empty vector the tuple can be inserted at the beginning\r\n    if (this.elements.length == 0) {\r\n      return 0\r\n    }\r\n  \r\n    var start = 0,\r\n        end = this.elements.length / 2,\r\n        sliceLength = end - start,\r\n        pivotPoint = Math.floor(sliceLength / 2),\r\n        pivotIndex = this.elements[pivotPoint * 2]\r\n  \r\n    while (sliceLength > 1) {\r\n      if (pivotIndex < index) {\r\n        start = pivotPoint\r\n      }\r\n  \r\n      if (pivotIndex > index) {\r\n        end = pivotPoint\r\n      }\r\n  \r\n      if (pivotIndex == index) {\r\n        break\r\n      }\r\n  \r\n      sliceLength = end - start\r\n      pivotPoint = start + Math.floor(sliceLength / 2)\r\n      pivotIndex = this.elements[pivotPoint * 2]\r\n    }\r\n  \r\n    if (pivotIndex == index) {\r\n      return pivotPoint * 2\r\n    }\r\n  \r\n    if (pivotIndex > index) {\r\n      return pivotPoint * 2\r\n    }\r\n  \r\n    if (pivotIndex < index) {\r\n      return (pivotPoint + 1) * 2\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * Inserts an element at an index within the vector.\r\n   *\r\n   * Does not allow duplicates, will throw an error if there is already an entry\r\n   * for this index.\r\n   *\r\n   * @param {Number} insertIdx - The index at which the element should be inserted.\r\n   * @param {Number} val - The value to be inserted into the vector.\r\n   */\r\n  lunr.Vector.prototype.insert = function (insertIdx, val) {\r\n    this.upsert(insertIdx, val, function () {\r\n      throw \"duplicate index\"\r\n    })\r\n  }\r\n  \r\n  /**\r\n   * Inserts or updates an existing index within the vector.\r\n   *\r\n   * @param {Number} insertIdx - The index at which the element should be inserted.\r\n   * @param {Number} val - The value to be inserted into the vector.\r\n   * @param {function} fn - A function that is called for updates, the existing value and the\r\n   * requested value are passed as arguments\r\n   */\r\n  lunr.Vector.prototype.upsert = function (insertIdx, val, fn) {\r\n    this._magnitude = 0\r\n    var position = this.positionForIndex(insertIdx)\r\n  \r\n    if (this.elements[position] == insertIdx) {\r\n      this.elements[position + 1] = fn(this.elements[position + 1], val)\r\n    } else {\r\n      this.elements.splice(position, 0, insertIdx, val)\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * Calculates the magnitude of this vector.\r\n   *\r\n   * @returns {Number}\r\n   */\r\n  lunr.Vector.prototype.magnitude = function () {\r\n    if (this._magnitude) return this._magnitude\r\n  \r\n    var sumOfSquares = 0,\r\n        elementsLength = this.elements.length\r\n  \r\n    for (var i = 1; i < elementsLength; i += 2) {\r\n      var val = this.elements[i]\r\n      sumOfSquares += val * val\r\n    }\r\n  \r\n    return this._magnitude = Math.sqrt(sumOfSquares)\r\n  }\r\n  \r\n  /**\r\n   * Calculates the dot product of this vector and another vector.\r\n   *\r\n   * @param {lunr.Vector} otherVector - The vector to compute the dot product with.\r\n   * @returns {Number}\r\n   */\r\n  lunr.Vector.prototype.dot = function (otherVector) {\r\n    var dotProduct = 0,\r\n        a = this.elements, b = otherVector.elements,\r\n        aLen = a.length, bLen = b.length,\r\n        aVal = 0, bVal = 0,\r\n        i = 0, j = 0\r\n  \r\n    while (i < aLen && j < bLen) {\r\n      aVal = a[i], bVal = b[j]\r\n      if (aVal < bVal) {\r\n        i += 2\r\n      } else if (aVal > bVal) {\r\n        j += 2\r\n      } else if (aVal == bVal) {\r\n        dotProduct += a[i + 1] * b[j + 1]\r\n        i += 2\r\n        j += 2\r\n      }\r\n    }\r\n  \r\n    return dotProduct\r\n  }\r\n  \r\n  /**\r\n   * Calculates the similarity between this vector and another vector.\r\n   *\r\n   * @param {lunr.Vector} otherVector - The other vector to calculate the\r\n   * similarity with.\r\n   * @returns {Number}\r\n   */\r\n  lunr.Vector.prototype.similarity = function (otherVector) {\r\n    return this.dot(otherVector) / this.magnitude() || 0\r\n  }\r\n  \r\n  /**\r\n   * Converts the vector to an array of the elements within the vector.\r\n   *\r\n   * @returns {Number[]}\r\n   */\r\n  lunr.Vector.prototype.toArray = function () {\r\n    var output = new Array (this.elements.length / 2)\r\n  \r\n    for (var i = 1, j = 0; i < this.elements.length; i += 2, j++) {\r\n      output[j] = this.elements[i]\r\n    }\r\n  \r\n    return output\r\n  }\r\n  \r\n  /**\r\n   * A JSON serializable representation of the vector.\r\n   *\r\n   * @returns {Number[]}\r\n   */\r\n  lunr.Vector.prototype.toJSON = function () {\r\n    return this.elements\r\n  }\r\n  /* eslint-disable */\r\n  /*!\r\n   * lunr.stemmer\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\r\n   */\r\n  \r\n  /**\r\n   * lunr.stemmer is an english language stemmer, this is a JavaScript\r\n   * implementation of the PorterStemmer taken from http://tartarus.org/~martin\r\n   *\r\n   * @static\r\n   * @implements {lunr.PipelineFunction}\r\n   * @param {lunr.Token} token - The string to stem\r\n   * @returns {lunr.Token}\r\n   * @see {@link lunr.Pipeline}\r\n   * @function\r\n   */\r\n  lunr.stemmer = (function(){\r\n    var step2list = {\r\n        \"ational\" : \"ate\",\r\n        \"tional\" : \"tion\",\r\n        \"enci\" : \"ence\",\r\n        \"anci\" : \"ance\",\r\n        \"izer\" : \"ize\",\r\n        \"bli\" : \"ble\",\r\n        \"alli\" : \"al\",\r\n        \"entli\" : \"ent\",\r\n        \"eli\" : \"e\",\r\n        \"ousli\" : \"ous\",\r\n        \"ization\" : \"ize\",\r\n        \"ation\" : \"ate\",\r\n        \"ator\" : \"ate\",\r\n        \"alism\" : \"al\",\r\n        \"iveness\" : \"ive\",\r\n        \"fulness\" : \"ful\",\r\n        \"ousness\" : \"ous\",\r\n        \"aliti\" : \"al\",\r\n        \"iviti\" : \"ive\",\r\n        \"biliti\" : \"ble\",\r\n        \"logi\" : \"log\"\r\n      },\r\n  \r\n      step3list = {\r\n        \"icate\" : \"ic\",\r\n        \"ative\" : \"\",\r\n        \"alize\" : \"al\",\r\n        \"iciti\" : \"ic\",\r\n        \"ical\" : \"ic\",\r\n        \"ful\" : \"\",\r\n        \"ness\" : \"\"\r\n      },\r\n  \r\n      c = \"[^aeiou]\",          // consonant\r\n      v = \"[aeiouy]\",          // vowel\r\n      C = c + \"[^aeiouy]*\",    // consonant sequence\r\n      V = v + \"[aeiou]*\",      // vowel sequence\r\n  \r\n      mgr0 = \"^(\" + C + \")?\" + V + C,               // [C]VC... is m>0\r\n      meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\",  // [C]VC[V] is m=1\r\n      mgr1 = \"^(\" + C + \")?\" + V + C + V + C,       // [C]VCVC... is m>1\r\n      s_v = \"^(\" + C + \")?\" + v;                   // vowel in stem\r\n  \r\n    var re_mgr0 = new RegExp(mgr0);\r\n    var re_mgr1 = new RegExp(mgr1);\r\n    var re_meq1 = new RegExp(meq1);\r\n    var re_s_v = new RegExp(s_v);\r\n  \r\n    var re_1a = /^(.+?)(ss|i)es$/;\r\n    var re2_1a = /^(.+?)([^s])s$/;\r\n    var re_1b = /^(.+?)eed$/;\r\n    var re2_1b = /^(.+?)(ed|ing)$/;\r\n    var re_1b_2 = /.$/;\r\n    var re2_1b_2 = /(at|bl|iz)$/;\r\n    var re3_1b_2 = new RegExp(\"([^aeiouylsz])\\\\1$\");\r\n    var re4_1b_2 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\r\n  \r\n    var re_1c = /^(.+?[^aeiou])y$/;\r\n    var re_2 = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\r\n  \r\n    var re_3 = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\r\n  \r\n    var re_4 = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\r\n    var re2_4 = /^(.+?)(s|t)(ion)$/;\r\n  \r\n    var re_5 = /^(.+?)e$/;\r\n    var re_5_1 = /ll$/;\r\n    var re3_5 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\r\n  \r\n    var porterStemmer = function porterStemmer(w) {\r\n      var stem,\r\n        suffix,\r\n        firstch,\r\n        re,\r\n        re2,\r\n        re3,\r\n        re4;\r\n  \r\n      if (w.length < 3) { return w; }\r\n  \r\n      firstch = w.substr(0,1);\r\n      if (firstch == \"y\") {\r\n        w = firstch.toUpperCase() + w.substr(1);\r\n      }\r\n  \r\n      // Step 1a\r\n      re = re_1a\r\n      re2 = re2_1a;\r\n  \r\n      if (re.test(w)) { w = w.replace(re,\"$1$2\"); }\r\n      else if (re2.test(w)) { w = w.replace(re2,\"$1$2\"); }\r\n  \r\n      // Step 1b\r\n      re = re_1b;\r\n      re2 = re2_1b;\r\n      if (re.test(w)) {\r\n        var fp = re.exec(w);\r\n        re = re_mgr0;\r\n        if (re.test(fp[1])) {\r\n          re = re_1b_2;\r\n          w = w.replace(re,\"\");\r\n        }\r\n      } else if (re2.test(w)) {\r\n        var fp = re2.exec(w);\r\n        stem = fp[1];\r\n        re2 = re_s_v;\r\n        if (re2.test(stem)) {\r\n          w = stem;\r\n          re2 = re2_1b_2;\r\n          re3 = re3_1b_2;\r\n          re4 = re4_1b_2;\r\n          if (re2.test(w)) { w = w + \"e\"; }\r\n          else if (re3.test(w)) { re = re_1b_2; w = w.replace(re,\"\"); }\r\n          else if (re4.test(w)) { w = w + \"e\"; }\r\n        }\r\n      }\r\n  \r\n      // Step 1c - replace suffix y or Y by i if preceded by a non-vowel which is not the first letter of the word (so cry -> cri, by -> by, say -> say)\r\n      re = re_1c;\r\n      if (re.test(w)) {\r\n        var fp = re.exec(w);\r\n        stem = fp[1];\r\n        w = stem + \"i\";\r\n      }\r\n  \r\n      // Step 2\r\n      re = re_2;\r\n      if (re.test(w)) {\r\n        var fp = re.exec(w);\r\n        stem = fp[1];\r\n        suffix = fp[2];\r\n        re = re_mgr0;\r\n        if (re.test(stem)) {\r\n          w = stem + step2list[suffix];\r\n        }\r\n      }\r\n  \r\n      // Step 3\r\n      re = re_3;\r\n      if (re.test(w)) {\r\n        var fp = re.exec(w);\r\n        stem = fp[1];\r\n        suffix = fp[2];\r\n        re = re_mgr0;\r\n        if (re.test(stem)) {\r\n          w = stem + step3list[suffix];\r\n        }\r\n      }\r\n  \r\n      // Step 4\r\n      re = re_4;\r\n      re2 = re2_4;\r\n      if (re.test(w)) {\r\n        var fp = re.exec(w);\r\n        stem = fp[1];\r\n        re = re_mgr1;\r\n        if (re.test(stem)) {\r\n          w = stem;\r\n        }\r\n      } else if (re2.test(w)) {\r\n        var fp = re2.exec(w);\r\n        stem = fp[1] + fp[2];\r\n        re2 = re_mgr1;\r\n        if (re2.test(stem)) {\r\n          w = stem;\r\n        }\r\n      }\r\n  \r\n      // Step 5\r\n      re = re_5;\r\n      if (re.test(w)) {\r\n        var fp = re.exec(w);\r\n        stem = fp[1];\r\n        re = re_mgr1;\r\n        re2 = re_meq1;\r\n        re3 = re3_5;\r\n        if (re.test(stem) || (re2.test(stem) && !(re3.test(stem)))) {\r\n          w = stem;\r\n        }\r\n      }\r\n  \r\n      re = re_5_1;\r\n      re2 = re_mgr1;\r\n      if (re.test(w) && re2.test(w)) {\r\n        re = re_1b_2;\r\n        w = w.replace(re,\"\");\r\n      }\r\n  \r\n      // and turn initial Y back to y\r\n  \r\n      if (firstch == \"y\") {\r\n        w = firstch.toLowerCase() + w.substr(1);\r\n      }\r\n  \r\n      return w;\r\n    };\r\n  \r\n    return function (token) {\r\n      return token.update(porterStemmer);\r\n    }\r\n  })();\r\n  \r\n  lunr.Pipeline.registerFunction(lunr.stemmer, 'stemmer')\r\n  /*!\r\n   * lunr.stopWordFilter\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   */\r\n  \r\n  /**\r\n   * lunr.generateStopWordFilter builds a stopWordFilter function from the provided\r\n   * list of stop words.\r\n   *\r\n   * The built in lunr.stopWordFilter is built using this generator and can be used\r\n   * to generate custom stopWordFilters for applications or non English languages.\r\n   *\r\n   * @function\r\n   * @param {Array} token The token to pass through the filter\r\n   * @returns {lunr.PipelineFunction}\r\n   * @see lunr.Pipeline\r\n   * @see lunr.stopWordFilter\r\n   */\r\n  lunr.generateStopWordFilter = function (stopWords) {\r\n    var words = stopWords.reduce(function (memo, stopWord) {\r\n      memo[stopWord] = stopWord\r\n      return memo\r\n    }, {})\r\n  \r\n    return function (token) {\r\n      if (token && words[token.toString()] !== token.toString()) return token\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * lunr.stopWordFilter is an English language stop word list filter, any words\r\n   * contained in the list will not be passed through the filter.\r\n   *\r\n   * This is intended to be used in the Pipeline. If the token does not pass the\r\n   * filter then undefined will be returned.\r\n   *\r\n   * @function\r\n   * @implements {lunr.PipelineFunction}\r\n   * @params {lunr.Token} token - A token to check for being a stop word.\r\n   * @returns {lunr.Token}\r\n   * @see {@link lunr.Pipeline}\r\n   */\r\n  lunr.stopWordFilter = lunr.generateStopWordFilter([\r\n    'a',\r\n    'able',\r\n    'about',\r\n    'across',\r\n    'after',\r\n    'all',\r\n    'almost',\r\n    'also',\r\n    'am',\r\n    'among',\r\n    'an',\r\n    'and',\r\n    'any',\r\n    'are',\r\n    'as',\r\n    'at',\r\n    'be',\r\n    'because',\r\n    'been',\r\n    'but',\r\n    'by',\r\n    'can',\r\n    'cannot',\r\n    'could',\r\n    'dear',\r\n    'did',\r\n    'do',\r\n    'does',\r\n    'either',\r\n    'else',\r\n    'ever',\r\n    'every',\r\n    'for',\r\n    'from',\r\n    'get',\r\n    'got',\r\n    'had',\r\n    'has',\r\n    'have',\r\n    'he',\r\n    'her',\r\n    'hers',\r\n    'him',\r\n    'his',\r\n    'how',\r\n    'however',\r\n    'i',\r\n    'if',\r\n    'in',\r\n    'into',\r\n    'is',\r\n    'it',\r\n    'its',\r\n    'just',\r\n    'least',\r\n    'let',\r\n    'like',\r\n    'likely',\r\n    'may',\r\n    'me',\r\n    'might',\r\n    'most',\r\n    'must',\r\n    'my',\r\n    'neither',\r\n    'no',\r\n    'nor',\r\n    'not',\r\n    'of',\r\n    'off',\r\n    'often',\r\n    'on',\r\n    'only',\r\n    'or',\r\n    'other',\r\n    'our',\r\n    'own',\r\n    'rather',\r\n    'said',\r\n    'say',\r\n    'says',\r\n    'she',\r\n    'should',\r\n    'since',\r\n    'so',\r\n    'some',\r\n    'than',\r\n    'that',\r\n    'the',\r\n    'their',\r\n    'them',\r\n    'then',\r\n    'there',\r\n    'these',\r\n    'they',\r\n    'this',\r\n    'tis',\r\n    'to',\r\n    'too',\r\n    'twas',\r\n    'us',\r\n    'wants',\r\n    'was',\r\n    'we',\r\n    'were',\r\n    'what',\r\n    'when',\r\n    'where',\r\n    'which',\r\n    'while',\r\n    'who',\r\n    'whom',\r\n    'why',\r\n    'will',\r\n    'with',\r\n    'would',\r\n    'yet',\r\n    'you',\r\n    'your'\r\n  ])\r\n  \r\n  lunr.Pipeline.registerFunction(lunr.stopWordFilter, 'stopWordFilter')\r\n  /*!\r\n   * lunr.trimmer\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   */\r\n  \r\n  /**\r\n   * lunr.trimmer is a pipeline function for trimming non word\r\n   * characters from the beginning and end of tokens before they\r\n   * enter the index.\r\n   *\r\n   * This implementation may not work correctly for non latin\r\n   * characters and should either be removed or adapted for use\r\n   * with languages with non-latin characters.\r\n   *\r\n   * @static\r\n   * @implements {lunr.PipelineFunction}\r\n   * @param {lunr.Token} token The token to pass through the filter\r\n   * @returns {lunr.Token}\r\n   * @see lunr.Pipeline\r\n   */\r\n  lunr.trimmer = function (token) {\r\n    return token.update(function (s) {\r\n      return s.replace(/^\\W+/, '').replace(/\\W+$/, '')\r\n    })\r\n  }\r\n  \r\n  lunr.Pipeline.registerFunction(lunr.trimmer, 'trimmer')\r\n  /*!\r\n   * lunr.TokenSet\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   */\r\n  \r\n  /**\r\n   * A token set is used to store the unique list of all tokens\r\n   * within an index. Token sets are also used to represent an\r\n   * incoming query to the index, this query token set and index\r\n   * token set are then intersected to find which tokens to look\r\n   * up in the inverted index.\r\n   *\r\n   * A token set can hold multiple tokens, as in the case of the\r\n   * index token set, or it can hold a single token as in the\r\n   * case of a simple query token set.\r\n   *\r\n   * Additionally token sets are used to perform wildcard matching.\r\n   * Leading, contained and trailing wildcards are supported, and\r\n   * from this edit distance matching can also be provided.\r\n   *\r\n   * Token sets are implemented as a minimal finite state automata,\r\n   * where both common prefixes and suffixes are shared between tokens.\r\n   * This helps to reduce the space used for storing the token set.\r\n   *\r\n   * @constructor\r\n   */\r\n  lunr.TokenSet = function () {\r\n    this.final = false\r\n    this.edges = {}\r\n    this.id = lunr.TokenSet._nextId\r\n    lunr.TokenSet._nextId += 1\r\n  }\r\n  \r\n  /**\r\n   * Keeps track of the next, auto increment, identifier to assign\r\n   * to a new tokenSet.\r\n   *\r\n   * TokenSets require a unique identifier to be correctly minimised.\r\n   *\r\n   * @private\r\n   */\r\n  lunr.TokenSet._nextId = 1\r\n  \r\n  /**\r\n   * Creates a TokenSet instance from the given sorted array of words.\r\n   *\r\n   * @param {String[]} arr - A sorted array of strings to create the set from.\r\n   * @returns {lunr.TokenSet}\r\n   * @throws Will throw an error if the input array is not sorted.\r\n   */\r\n  lunr.TokenSet.fromArray = function (arr) {\r\n    var builder = new lunr.TokenSet.Builder\r\n  \r\n    for (var i = 0, len = arr.length; i < len; i++) {\r\n      builder.insert(arr[i])\r\n    }\r\n  \r\n    builder.finish()\r\n    return builder.root\r\n  }\r\n  \r\n  /**\r\n   * Creates a token set from a query clause.\r\n   *\r\n   * @private\r\n   * @param {Object} clause - A single clause from lunr.Query.\r\n   * @param {string} clause.term - The query clause term.\r\n   * @param {number} [clause.editDistance] - The optional edit distance for the term.\r\n   * @returns {lunr.TokenSet}\r\n   */\r\n  lunr.TokenSet.fromClause = function (clause) {\r\n    if ('editDistance' in clause) {\r\n      return lunr.TokenSet.fromFuzzyString(clause.term, clause.editDistance)\r\n    } else {\r\n      return lunr.TokenSet.fromString(clause.term)\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * Creates a token set representing a single string with a specified\r\n   * edit distance.\r\n   *\r\n   * Insertions, deletions, substitutions and transpositions are each\r\n   * treated as an edit distance of 1.\r\n   *\r\n   * Increasing the allowed edit distance will have a dramatic impact\r\n   * on the performance of both creating and intersecting these TokenSets.\r\n   * It is advised to keep the edit distance less than 3.\r\n   *\r\n   * @param {string} str - The string to create the token set from.\r\n   * @param {number} editDistance - The allowed edit distance to match.\r\n   * @returns {lunr.Vector}\r\n   */\r\n  lunr.TokenSet.fromFuzzyString = function (str, editDistance) {\r\n    var root = new lunr.TokenSet\r\n  \r\n    var stack = [{\r\n      node: root,\r\n      editsRemaining: editDistance,\r\n      str: str\r\n    }]\r\n  \r\n    while (stack.length) {\r\n      var frame = stack.pop()\r\n  \r\n      // no edit\r\n      if (frame.str.length > 0) {\r\n        var char = frame.str.charAt(0),\r\n            noEditNode\r\n  \r\n        if (char in frame.node.edges) {\r\n          noEditNode = frame.node.edges[char]\r\n        } else {\r\n          noEditNode = new lunr.TokenSet\r\n          frame.node.edges[char] = noEditNode\r\n        }\r\n  \r\n        if (frame.str.length == 1) {\r\n          noEditNode.final = true\r\n        } else {\r\n          stack.push({\r\n            node: noEditNode,\r\n            editsRemaining: frame.editsRemaining,\r\n            str: frame.str.slice(1)\r\n          })\r\n        }\r\n      }\r\n  \r\n      // deletion\r\n      // can only do a deletion if we have enough edits remaining\r\n      // and if there are characters left to delete in the string\r\n      if (frame.editsRemaining > 0 && frame.str.length > 1) {\r\n        var char = frame.str.charAt(1),\r\n            deletionNode\r\n  \r\n        if (char in frame.node.edges) {\r\n          deletionNode = frame.node.edges[char]\r\n        } else {\r\n          deletionNode = new lunr.TokenSet\r\n          frame.node.edges[char] = deletionNode\r\n        }\r\n  \r\n        if (frame.str.length <= 2) {\r\n          deletionNode.final = true\r\n        } else {\r\n          stack.push({\r\n            node: deletionNode,\r\n            editsRemaining: frame.editsRemaining - 1,\r\n            str: frame.str.slice(2)\r\n          })\r\n        }\r\n      }\r\n  \r\n      // deletion\r\n      // just removing the last character from the str\r\n      if (frame.editsRemaining > 0 && frame.str.length == 1) {\r\n        frame.node.final = true\r\n      }\r\n  \r\n      // substitution\r\n      // can only do a substitution if we have enough edits remaining\r\n      // and if there are characters left to substitute\r\n      if (frame.editsRemaining > 0 && frame.str.length >= 1) {\r\n        if (\"*\" in frame.node.edges) {\r\n          var substitutionNode = frame.node.edges[\"*\"]\r\n        } else {\r\n          var substitutionNode = new lunr.TokenSet\r\n          frame.node.edges[\"*\"] = substitutionNode\r\n        }\r\n  \r\n        if (frame.str.length == 1) {\r\n          substitutionNode.final = true\r\n        } else {\r\n          stack.push({\r\n            node: substitutionNode,\r\n            editsRemaining: frame.editsRemaining - 1,\r\n            str: frame.str.slice(1)\r\n          })\r\n        }\r\n      }\r\n  \r\n      // insertion\r\n      // can only do insertion if there are edits remaining\r\n      if (frame.editsRemaining > 0) {\r\n        if (\"*\" in frame.node.edges) {\r\n          var insertionNode = frame.node.edges[\"*\"]\r\n        } else {\r\n          var insertionNode = new lunr.TokenSet\r\n          frame.node.edges[\"*\"] = insertionNode\r\n        }\r\n  \r\n        if (frame.str.length == 0) {\r\n          insertionNode.final = true\r\n        } else {\r\n          stack.push({\r\n            node: insertionNode,\r\n            editsRemaining: frame.editsRemaining - 1,\r\n            str: frame.str\r\n          })\r\n        }\r\n      }\r\n  \r\n      // transposition\r\n      // can only do a transposition if there are edits remaining\r\n      // and there are enough characters to transpose\r\n      if (frame.editsRemaining > 0 && frame.str.length > 1) {\r\n        var charA = frame.str.charAt(0),\r\n            charB = frame.str.charAt(1),\r\n            transposeNode\r\n  \r\n        if (charB in frame.node.edges) {\r\n          transposeNode = frame.node.edges[charB]\r\n        } else {\r\n          transposeNode = new lunr.TokenSet\r\n          frame.node.edges[charB] = transposeNode\r\n        }\r\n  \r\n        if (frame.str.length == 1) {\r\n          transposeNode.final = true\r\n        } else {\r\n          stack.push({\r\n            node: transposeNode,\r\n            editsRemaining: frame.editsRemaining - 1,\r\n            str: charA + frame.str.slice(2)\r\n          })\r\n        }\r\n      }\r\n    }\r\n  \r\n    return root\r\n  }\r\n  \r\n  /**\r\n   * Creates a TokenSet from a string.\r\n   *\r\n   * The string may contain one or more wildcard characters (*)\r\n   * that will allow wildcard matching when intersecting with\r\n   * another TokenSet.\r\n   *\r\n   * @param {string} str - The string to create a TokenSet from.\r\n   * @returns {lunr.TokenSet}\r\n   */\r\n  lunr.TokenSet.fromString = function (str) {\r\n    var node = new lunr.TokenSet,\r\n        root = node\r\n  \r\n    /*\r\n     * Iterates through all characters within the passed string\r\n     * appending a node for each character.\r\n     *\r\n     * When a wildcard character is found then a self\r\n     * referencing edge is introduced to continually match\r\n     * any number of any characters.\r\n     */\r\n    for (var i = 0, len = str.length; i < len; i++) {\r\n      var char = str[i],\r\n          final = (i == len - 1)\r\n  \r\n      if (char == \"*\") {\r\n        node.edges[char] = node\r\n        node.final = final\r\n  \r\n      } else {\r\n        var next = new lunr.TokenSet\r\n        next.final = final\r\n  \r\n        node.edges[char] = next\r\n        node = next\r\n      }\r\n    }\r\n  \r\n    return root\r\n  }\r\n  \r\n  /**\r\n   * Converts this TokenSet into an array of strings\r\n   * contained within the TokenSet.\r\n   *\r\n   * @returns {string[]}\r\n   */\r\n  lunr.TokenSet.prototype.toArray = function () {\r\n    var words = []\r\n  \r\n    var stack = [{\r\n      prefix: \"\",\r\n      node: this\r\n    }]\r\n  \r\n    while (stack.length) {\r\n      var frame = stack.pop(),\r\n          edges = Object.keys(frame.node.edges),\r\n          len = edges.length\r\n  \r\n      if (frame.node.final) {\r\n        /* In Safari, at this point the prefix is sometimes corrupted, see:\r\n         * https://github.com/olivernn/lunr.js/issues/279 Calling any\r\n         * String.prototype method forces Safari to \"cast\" this string to what\r\n         * it's supposed to be, fixing the bug. */\r\n        frame.prefix.charAt(0)\r\n        words.push(frame.prefix)\r\n      }\r\n  \r\n      for (var i = 0; i < len; i++) {\r\n        var edge = edges[i]\r\n  \r\n        stack.push({\r\n          prefix: frame.prefix.concat(edge),\r\n          node: frame.node.edges[edge]\r\n        })\r\n      }\r\n    }\r\n  \r\n    return words\r\n  }\r\n  \r\n  /**\r\n   * Generates a string representation of a TokenSet.\r\n   *\r\n   * This is intended to allow TokenSets to be used as keys\r\n   * in objects, largely to aid the construction and minimisation\r\n   * of a TokenSet. As such it is not designed to be a human\r\n   * friendly representation of the TokenSet.\r\n   *\r\n   * @returns {string}\r\n   */\r\n  lunr.TokenSet.prototype.toString = function () {\r\n    // NOTE: Using Object.keys here as this.edges is very likely\r\n    // to enter 'hash-mode' with many keys being added\r\n    //\r\n    // avoiding a for-in loop here as it leads to the function\r\n    // being de-optimised (at least in V8). From some simple\r\n    // benchmarks the performance is comparable, but allowing\r\n    // V8 to optimize may mean easy performance wins in the future.\r\n  \r\n    if (this._str) {\r\n      return this._str\r\n    }\r\n  \r\n    var str = this.final ? '1' : '0',\r\n        labels = Object.keys(this.edges).sort(),\r\n        len = labels.length\r\n  \r\n    for (var i = 0; i < len; i++) {\r\n      var label = labels[i],\r\n          node = this.edges[label]\r\n  \r\n      str = str + label + node.id\r\n    }\r\n  \r\n    return str\r\n  }\r\n  \r\n  /**\r\n   * Returns a new TokenSet that is the intersection of\r\n   * this TokenSet and the passed TokenSet.\r\n   *\r\n   * This intersection will take into account any wildcards\r\n   * contained within the TokenSet.\r\n   *\r\n   * @param {lunr.TokenSet} b - An other TokenSet to intersect with.\r\n   * @returns {lunr.TokenSet}\r\n   */\r\n  lunr.TokenSet.prototype.intersect = function (b) {\r\n    var output = new lunr.TokenSet,\r\n        frame = undefined\r\n  \r\n    var stack = [{\r\n      qNode: b,\r\n      output: output,\r\n      node: this\r\n    }]\r\n  \r\n    while (stack.length) {\r\n      frame = stack.pop()\r\n  \r\n      // NOTE: As with the #toString method, we are using\r\n      // Object.keys and a for loop instead of a for-in loop\r\n      // as both of these objects enter 'hash' mode, causing\r\n      // the function to be de-optimised in V8\r\n      var qEdges = Object.keys(frame.qNode.edges),\r\n          qLen = qEdges.length,\r\n          nEdges = Object.keys(frame.node.edges),\r\n          nLen = nEdges.length\r\n  \r\n      for (var q = 0; q < qLen; q++) {\r\n        var qEdge = qEdges[q]\r\n  \r\n        for (var n = 0; n < nLen; n++) {\r\n          var nEdge = nEdges[n]\r\n  \r\n          if (nEdge == qEdge || qEdge == '*') {\r\n            var node = frame.node.edges[nEdge],\r\n                qNode = frame.qNode.edges[qEdge],\r\n                final = node.final && qNode.final,\r\n                next = undefined\r\n  \r\n            if (nEdge in frame.output.edges) {\r\n              // an edge already exists for this character\r\n              // no need to create a new node, just set the finality\r\n              // bit unless this node is already final\r\n              next = frame.output.edges[nEdge]\r\n              next.final = next.final || final\r\n  \r\n            } else {\r\n              // no edge exists yet, must create one\r\n              // set the finality bit and insert it\r\n              // into the output\r\n              next = new lunr.TokenSet\r\n              next.final = final\r\n              frame.output.edges[nEdge] = next\r\n            }\r\n  \r\n            stack.push({\r\n              qNode: qNode,\r\n              output: next,\r\n              node: node\r\n            })\r\n          }\r\n        }\r\n      }\r\n    }\r\n  \r\n    return output\r\n  }\r\n  lunr.TokenSet.Builder = function () {\r\n    this.previousWord = \"\"\r\n    this.root = new lunr.TokenSet\r\n    this.uncheckedNodes = []\r\n    this.minimizedNodes = {}\r\n  }\r\n  \r\n  lunr.TokenSet.Builder.prototype.insert = function (word) {\r\n    var node,\r\n        commonPrefix = 0\r\n  \r\n    if (word < this.previousWord) {\r\n      throw new Error (\"Out of order word insertion\")\r\n    }\r\n  \r\n    for (var i = 0; i < word.length && i < this.previousWord.length; i++) {\r\n      if (word[i] != this.previousWord[i]) break\r\n      commonPrefix++\r\n    }\r\n  \r\n    this.minimize(commonPrefix)\r\n  \r\n    if (this.uncheckedNodes.length == 0) {\r\n      node = this.root\r\n    } else {\r\n      node = this.uncheckedNodes[this.uncheckedNodes.length - 1].child\r\n    }\r\n  \r\n    for (var i = commonPrefix; i < word.length; i++) {\r\n      var nextNode = new lunr.TokenSet,\r\n          char = word[i]\r\n  \r\n      node.edges[char] = nextNode\r\n  \r\n      this.uncheckedNodes.push({\r\n        parent: node,\r\n        char: char,\r\n        child: nextNode\r\n      })\r\n  \r\n      node = nextNode\r\n    }\r\n  \r\n    node.final = true\r\n    this.previousWord = word\r\n  }\r\n  \r\n  lunr.TokenSet.Builder.prototype.finish = function () {\r\n    this.minimize(0)\r\n  }\r\n  \r\n  lunr.TokenSet.Builder.prototype.minimize = function (downTo) {\r\n    for (var i = this.uncheckedNodes.length - 1; i >= downTo; i--) {\r\n      var node = this.uncheckedNodes[i],\r\n          childKey = node.child.toString()\r\n  \r\n      if (childKey in this.minimizedNodes) {\r\n        node.parent.edges[node.char] = this.minimizedNodes[childKey]\r\n      } else {\r\n        // Cache the key for this node since\r\n        // we know it can't change anymore\r\n        node.child._str = childKey\r\n  \r\n        this.minimizedNodes[childKey] = node.child\r\n      }\r\n  \r\n      this.uncheckedNodes.pop()\r\n    }\r\n  }\r\n  /*!\r\n   * lunr.Index\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   */\r\n  \r\n  /**\r\n   * An index contains the built index of all documents and provides a query interface\r\n   * to the index.\r\n   *\r\n   * Usually instances of lunr.Index will not be created using this constructor, instead\r\n   * lunr.Builder should be used to construct new indexes, or lunr.Index.load should be\r\n   * used to load previously built and serialized indexes.\r\n   *\r\n   * @constructor\r\n   * @param {Object} attrs - The attributes of the built search index.\r\n   * @param {Object} attrs.invertedIndex - An index of term/field to document reference.\r\n   * @param {Object<string, lunr.Vector>} attrs.fieldVectors - Field vectors\r\n   * @param {lunr.TokenSet} attrs.tokenSet - An set of all corpus tokens.\r\n   * @param {string[]} attrs.fields - The names of indexed document fields.\r\n   * @param {lunr.Pipeline} attrs.pipeline - The pipeline to use for search terms.\r\n   */\r\n  lunr.Index = function (attrs) {\r\n    this.invertedIndex = attrs.invertedIndex\r\n    this.fieldVectors = attrs.fieldVectors\r\n    this.tokenSet = attrs.tokenSet\r\n    this.fields = attrs.fields\r\n    this.pipeline = attrs.pipeline\r\n  }\r\n  \r\n  /**\r\n   * A result contains details of a document matching a search query.\r\n   * @typedef {Object} lunr.Index~Result\r\n   * @property {string} ref - The reference of the document this result represents.\r\n   * @property {number} score - A number between 0 and 1 representing how similar this document is to the query.\r\n   * @property {lunr.MatchData} matchData - Contains metadata about this match including which term(s) caused the match.\r\n   */\r\n  \r\n  /**\r\n   * Although lunr provides the ability to create queries using lunr.Query, it also provides a simple\r\n   * query language which itself is parsed into an instance of lunr.Query.\r\n   *\r\n   * For programmatically building queries it is advised to directly use lunr.Query, the query language\r\n   * is best used for human entered text rather than program generated text.\r\n   *\r\n   * At its simplest queries can just be a single term, e.g. `hello`, multiple terms are also supported\r\n   * and will be combined with OR, e.g `hello world` will match documents that contain either 'hello'\r\n   * or 'world', though those that contain both will rank higher in the results.\r\n   *\r\n   * Wildcards can be included in terms to match one or more unspecified characters, these wildcards can\r\n   * be inserted anywhere within the term, and more than one wildcard can exist in a single term. Adding\r\n   * wildcards will increase the number of documents that will be found but can also have a negative\r\n   * impact on query performance, especially with wildcards at the beginning of a term.\r\n   *\r\n   * Terms can be restricted to specific fields, e.g. `title:hello`, only documents with the term\r\n   * hello in the title field will match this query. Using a field not present in the index will lead\r\n   * to an error being thrown.\r\n   *\r\n   * Modifiers can also be added to terms, lunr supports edit distance and boost modifiers on terms. A term\r\n   * boost will make documents matching that term score higher, e.g. `foo^5`. Edit distance is also supported\r\n   * to provide fuzzy matching, e.g. 'hello~2' will match documents with hello with an edit distance of 2.\r\n   * Avoid large values for edit distance to improve query performance.\r\n   *\r\n   * Each term also supports a presence modifier. By default a term's presence in document is optional, however\r\n   * this can be changed to either required or prohibited. For a term's presence to be required in a document the\r\n   * term should be prefixed with a '+', e.g. `+foo bar` is a search for documents that must contain 'foo' and\r\n   * optionally contain 'bar'. Conversely a leading '-' sets the terms presence to prohibited, i.e. it must not\r\n   * appear in a document, e.g. `-foo bar` is a search for documents that do not contain 'foo' but may contain 'bar'.\r\n   *\r\n   * To escape special characters the backslash character '\\' can be used, this allows searches to include\r\n   * characters that would normally be considered modifiers, e.g. `foo\\~2` will search for a term \"foo~2\" instead\r\n   * of attempting to apply a boost of 2 to the search term \"foo\".\r\n   *\r\n   * @typedef {string} lunr.Index~QueryString\r\n   * @example <caption>Simple single term query</caption>\r\n   * hello\r\n   * @example <caption>Multiple term query</caption>\r\n   * hello world\r\n   * @example <caption>term scoped to a field</caption>\r\n   * title:hello\r\n   * @example <caption>term with a boost of 10</caption>\r\n   * hello^10\r\n   * @example <caption>term with an edit distance of 2</caption>\r\n   * hello~2\r\n   * @example <caption>terms with presence modifiers</caption>\r\n   * -foo +bar baz\r\n   */\r\n  \r\n  /**\r\n   * Performs a search against the index using lunr query syntax.\r\n   *\r\n   * Results will be returned sorted by their score, the most relevant results\r\n   * will be returned first.  For details on how the score is calculated, please see\r\n   * the {@link https://lunrjs.com/guides/searching.html#scoring|guide}.\r\n   *\r\n   * For more programmatic querying use lunr.Index#query.\r\n   *\r\n   * @param {lunr.Index~QueryString} queryString - A string containing a lunr query.\r\n   * @throws {lunr.QueryParseError} If the passed query string cannot be parsed.\r\n   * @returns {lunr.Index~Result[]}\r\n   */\r\n  lunr.Index.prototype.search = function (queryString) {\r\n    return this.query(function (query) {\r\n      var parser = new lunr.QueryParser(queryString, query)\r\n      parser.parse()\r\n    })\r\n  }\r\n  \r\n  /**\r\n   * A query builder callback provides a query object to be used to express\r\n   * the query to perform on the index.\r\n   *\r\n   * @callback lunr.Index~queryBuilder\r\n   * @param {lunr.Query} query - The query object to build up.\r\n   * @this lunr.Query\r\n   */\r\n  \r\n  /**\r\n   * Performs a query against the index using the yielded lunr.Query object.\r\n   *\r\n   * If performing programmatic queries against the index, this method is preferred\r\n   * over lunr.Index#search so as to avoid the additional query parsing overhead.\r\n   *\r\n   * A query object is yielded to the supplied function which should be used to\r\n   * express the query to be run against the index.\r\n   *\r\n   * Note that although this function takes a callback parameter it is _not_ an\r\n   * asynchronous operation, the callback is just yielded a query object to be\r\n   * customized.\r\n   *\r\n   * @param {lunr.Index~queryBuilder} fn - A function that is used to build the query.\r\n   * @returns {lunr.Index~Result[]}\r\n   */\r\n  lunr.Index.prototype.query = function (fn) {\r\n    // for each query clause\r\n    // * process terms\r\n    // * expand terms from token set\r\n    // * find matching documents and metadata\r\n    // * get document vectors\r\n    // * score documents\r\n  \r\n    var query = new lunr.Query(this.fields),\r\n        matchingFields = Object.create(null),\r\n        queryVectors = Object.create(null),\r\n        termFieldCache = Object.create(null),\r\n        requiredMatches = Object.create(null),\r\n        prohibitedMatches = Object.create(null)\r\n  \r\n    /*\r\n     * To support field level boosts a query vector is created per\r\n     * field. An empty vector is eagerly created to support negated\r\n     * queries.\r\n     */\r\n    for (var i = 0; i < this.fields.length; i++) {\r\n      queryVectors[this.fields[i]] = new lunr.Vector\r\n    }\r\n  \r\n    fn.call(query, query)\r\n  \r\n    for (var i = 0; i < query.clauses.length; i++) {\r\n      /*\r\n       * Unless the pipeline has been disabled for this term, which is\r\n       * the case for terms with wildcards, we need to pass the clause\r\n       * term through the search pipeline. A pipeline returns an array\r\n       * of processed terms. Pipeline functions may expand the passed\r\n       * term, which means we may end up performing multiple index lookups\r\n       * for a single query term.\r\n       */\r\n      var clause = query.clauses[i],\r\n          terms = null,\r\n          clauseMatches = lunr.Set.complete\r\n  \r\n      if (clause.usePipeline) {\r\n        terms = this.pipeline.runString(clause.term, {\r\n          fields: clause.fields\r\n        })\r\n      } else {\r\n        terms = [clause.term]\r\n      }\r\n  \r\n      for (var m = 0; m < terms.length; m++) {\r\n        var term = terms[m]\r\n  \r\n        /*\r\n         * Each term returned from the pipeline needs to use the same query\r\n         * clause object, e.g. the same boost and or edit distance. The\r\n         * simplest way to do this is to re-use the clause object but mutate\r\n         * its term property.\r\n         */\r\n        clause.term = term\r\n  \r\n        /*\r\n         * From the term in the clause we create a token set which will then\r\n         * be used to intersect the indexes token set to get a list of terms\r\n         * to lookup in the inverted index\r\n         */\r\n        var termTokenSet = lunr.TokenSet.fromClause(clause),\r\n            expandedTerms = this.tokenSet.intersect(termTokenSet).toArray()\r\n  \r\n        /*\r\n         * If a term marked as required does not exist in the tokenSet it is\r\n         * impossible for the search to return any matches. We set all the field\r\n         * scoped required matches set to empty and stop examining any further\r\n         * clauses.\r\n         */\r\n        if (expandedTerms.length === 0 && clause.presence === lunr.Query.presence.REQUIRED) {\r\n          for (var k = 0; k < clause.fields.length; k++) {\r\n            var field = clause.fields[k]\r\n            requiredMatches[field] = lunr.Set.empty\r\n          }\r\n  \r\n          break\r\n        }\r\n  \r\n        for (var j = 0; j < expandedTerms.length; j++) {\r\n          /*\r\n           * For each term get the posting and termIndex, this is required for\r\n           * building the query vector.\r\n           */\r\n          var expandedTerm = expandedTerms[j],\r\n              posting = this.invertedIndex[expandedTerm],\r\n              termIndex = posting._index\r\n  \r\n          for (var k = 0; k < clause.fields.length; k++) {\r\n            /*\r\n             * For each field that this query term is scoped by (by default\r\n             * all fields are in scope) we need to get all the document refs\r\n             * that have this term in that field.\r\n             *\r\n             * The posting is the entry in the invertedIndex for the matching\r\n             * term from above.\r\n             */\r\n            var field = clause.fields[k],\r\n                fieldPosting = posting[field],\r\n                matchingDocumentRefs = Object.keys(fieldPosting),\r\n                termField = expandedTerm + \"/\" + field,\r\n                matchingDocumentsSet = new lunr.Set(matchingDocumentRefs)\r\n  \r\n            /*\r\n             * if the presence of this term is required ensure that the matching\r\n             * documents are added to the set of required matches for this clause.\r\n             *\r\n             */\r\n            if (clause.presence == lunr.Query.presence.REQUIRED) {\r\n              clauseMatches = clauseMatches.union(matchingDocumentsSet)\r\n  \r\n              if (requiredMatches[field] === undefined) {\r\n                requiredMatches[field] = lunr.Set.complete\r\n              }\r\n            }\r\n  \r\n            /*\r\n             * if the presence of this term is prohibited ensure that the matching\r\n             * documents are added to the set of prohibited matches for this field,\r\n             * creating that set if it does not yet exist.\r\n             */\r\n            if (clause.presence == lunr.Query.presence.PROHIBITED) {\r\n              if (prohibitedMatches[field] === undefined) {\r\n                prohibitedMatches[field] = lunr.Set.empty\r\n              }\r\n  \r\n              prohibitedMatches[field] = prohibitedMatches[field].union(matchingDocumentsSet)\r\n  \r\n              /*\r\n               * Prohibited matches should not be part of the query vector used for\r\n               * similarity scoring and no metadata should be extracted so we continue\r\n               * to the next field\r\n               */\r\n              continue\r\n            }\r\n  \r\n            /*\r\n             * The query field vector is populated using the termIndex found for\r\n             * the term and a unit value with the appropriate boost applied.\r\n             * Using upsert because there could already be an entry in the vector\r\n             * for the term we are working with. In that case we just add the scores\r\n             * together.\r\n             */\r\n            queryVectors[field].upsert(termIndex, clause.boost, function (a, b) { return a + b })\r\n  \r\n            /**\r\n             * If we've already seen this term, field combo then we've already collected\r\n             * the matching documents and metadata, no need to go through all that again\r\n             */\r\n            if (termFieldCache[termField]) {\r\n              continue\r\n            }\r\n  \r\n            for (var l = 0; l < matchingDocumentRefs.length; l++) {\r\n              /*\r\n               * All metadata for this term/field/document triple\r\n               * are then extracted and collected into an instance\r\n               * of lunr.MatchData ready to be returned in the query\r\n               * results\r\n               */\r\n              var matchingDocumentRef = matchingDocumentRefs[l],\r\n                  matchingFieldRef = new lunr.FieldRef (matchingDocumentRef, field),\r\n                  metadata = fieldPosting[matchingDocumentRef],\r\n                  fieldMatch\r\n  \r\n              if ((fieldMatch = matchingFields[matchingFieldRef]) === undefined) {\r\n                matchingFields[matchingFieldRef] = new lunr.MatchData (expandedTerm, field, metadata)\r\n              } else {\r\n                fieldMatch.add(expandedTerm, field, metadata)\r\n              }\r\n  \r\n            }\r\n  \r\n            termFieldCache[termField] = true\r\n          }\r\n        }\r\n      }\r\n  \r\n      /**\r\n       * If the presence was required we need to update the requiredMatches field sets.\r\n       * We do this after all fields for the term have collected their matches because\r\n       * the clause terms presence is required in _any_ of the fields not _all_ of the\r\n       * fields.\r\n       */\r\n      if (clause.presence === lunr.Query.presence.REQUIRED) {\r\n        for (var k = 0; k < clause.fields.length; k++) {\r\n          var field = clause.fields[k]\r\n          requiredMatches[field] = requiredMatches[field].intersect(clauseMatches)\r\n        }\r\n      }\r\n    }\r\n  \r\n    /**\r\n     * Need to combine the field scoped required and prohibited\r\n     * matching documents into a global set of required and prohibited\r\n     * matches\r\n     */\r\n    var allRequiredMatches = lunr.Set.complete,\r\n        allProhibitedMatches = lunr.Set.empty\r\n  \r\n    for (var i = 0; i < this.fields.length; i++) {\r\n      var field = this.fields[i]\r\n  \r\n      if (requiredMatches[field]) {\r\n        allRequiredMatches = allRequiredMatches.intersect(requiredMatches[field])\r\n      }\r\n  \r\n      if (prohibitedMatches[field]) {\r\n        allProhibitedMatches = allProhibitedMatches.union(prohibitedMatches[field])\r\n      }\r\n    }\r\n  \r\n    var matchingFieldRefs = Object.keys(matchingFields),\r\n        results = [],\r\n        matches = Object.create(null)\r\n  \r\n    /*\r\n     * If the query is negated (contains only prohibited terms)\r\n     * we need to get _all_ fieldRefs currently existing in the\r\n     * index. This is only done when we know that the query is\r\n     * entirely prohibited terms to avoid any cost of getting all\r\n     * fieldRefs unnecessarily.\r\n     *\r\n     * Additionally, blank MatchData must be created to correctly\r\n     * populate the results.\r\n     */\r\n    if (query.isNegated()) {\r\n      matchingFieldRefs = Object.keys(this.fieldVectors)\r\n  \r\n      for (var i = 0; i < matchingFieldRefs.length; i++) {\r\n        var matchingFieldRef = matchingFieldRefs[i]\r\n        var fieldRef = lunr.FieldRef.fromString(matchingFieldRef)\r\n        matchingFields[matchingFieldRef] = new lunr.MatchData\r\n      }\r\n    }\r\n  \r\n    for (var i = 0; i < matchingFieldRefs.length; i++) {\r\n      /*\r\n       * Currently we have document fields that match the query, but we\r\n       * need to return documents. The matchData and scores are combined\r\n       * from multiple fields belonging to the same document.\r\n       *\r\n       * Scores are calculated by field, using the query vectors created\r\n       * above, and combined into a final document score using addition.\r\n       */\r\n      var fieldRef = lunr.FieldRef.fromString(matchingFieldRefs[i]),\r\n          docRef = fieldRef.docRef\r\n  \r\n      if (!allRequiredMatches.contains(docRef)) {\r\n        continue\r\n      }\r\n  \r\n      if (allProhibitedMatches.contains(docRef)) {\r\n        continue\r\n      }\r\n  \r\n      var fieldVector = this.fieldVectors[fieldRef],\r\n          score = queryVectors[fieldRef.fieldName].similarity(fieldVector),\r\n          docMatch\r\n  \r\n      if ((docMatch = matches[docRef]) !== undefined) {\r\n        docMatch.score += score\r\n        docMatch.matchData.combine(matchingFields[fieldRef])\r\n      } else {\r\n        var match = {\r\n          ref: docRef,\r\n          score: score,\r\n          matchData: matchingFields[fieldRef]\r\n        }\r\n        matches[docRef] = match\r\n        results.push(match)\r\n      }\r\n    }\r\n  \r\n    /*\r\n     * Sort the results objects by score, highest first.\r\n     */\r\n    return results.sort(function (a, b) {\r\n      return b.score - a.score\r\n    })\r\n  }\r\n  \r\n  /**\r\n   * Prepares the index for JSON serialization.\r\n   *\r\n   * The schema for this JSON blob will be described in a\r\n   * separate JSON schema file.\r\n   *\r\n   * @returns {Object}\r\n   */\r\n  lunr.Index.prototype.toJSON = function () {\r\n    var invertedIndex = Object.keys(this.invertedIndex)\r\n      .sort()\r\n      .map(function (term) {\r\n        return [term, this.invertedIndex[term]]\r\n      }, this)\r\n  \r\n    var fieldVectors = Object.keys(this.fieldVectors)\r\n      .map(function (ref) {\r\n        return [ref, this.fieldVectors[ref].toJSON()]\r\n      }, this)\r\n  \r\n    return {\r\n      version: lunr.version,\r\n      fields: this.fields,\r\n      fieldVectors: fieldVectors,\r\n      invertedIndex: invertedIndex,\r\n      pipeline: this.pipeline.toJSON()\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * Loads a previously serialized lunr.Index\r\n   *\r\n   * @param {Object} serializedIndex - A previously serialized lunr.Index\r\n   * @returns {lunr.Index}\r\n   */\r\n  lunr.Index.load = function (serializedIndex) {\r\n    var attrs = {},\r\n        fieldVectors = {},\r\n        serializedVectors = serializedIndex.fieldVectors,\r\n        invertedIndex = {},\r\n        serializedInvertedIndex = serializedIndex.invertedIndex,\r\n        tokenSetBuilder = new lunr.TokenSet.Builder,\r\n        pipeline = lunr.Pipeline.load(serializedIndex.pipeline)\r\n  \r\n    if (serializedIndex.version != lunr.version) {\r\n      lunr.utils.warn(\"Version mismatch when loading serialised index. Current version of lunr '\" + lunr.version + \"' does not match serialized index '\" + serializedIndex.version + \"'\")\r\n    }\r\n  \r\n    for (var i = 0; i < serializedVectors.length; i++) {\r\n      var tuple = serializedVectors[i],\r\n          ref = tuple[0],\r\n          elements = tuple[1]\r\n  \r\n      fieldVectors[ref] = new lunr.Vector(elements)\r\n    }\r\n  \r\n    for (var i = 0; i < serializedInvertedIndex.length; i++) {\r\n      var tuple = serializedInvertedIndex[i],\r\n          term = tuple[0],\r\n          posting = tuple[1]\r\n  \r\n      tokenSetBuilder.insert(term)\r\n      invertedIndex[term] = posting\r\n    }\r\n  \r\n    tokenSetBuilder.finish()\r\n  \r\n    attrs.fields = serializedIndex.fields\r\n  \r\n    attrs.fieldVectors = fieldVectors\r\n    attrs.invertedIndex = invertedIndex\r\n    attrs.tokenSet = tokenSetBuilder.root\r\n    attrs.pipeline = pipeline\r\n  \r\n    return new lunr.Index(attrs)\r\n  }\r\n  /*!\r\n   * lunr.Builder\r\n   * Copyright (C) 2018 Oliver Nightingale\r\n   */\r\n  \r\n  /**\r\n   * lunr.Builder performs indexing on a set of documents and\r\n   * returns instances of lunr.Index ready for querying.\r\n   *\r\n   * All configuration of the index is done via the builder, the\r\n   * fields to index, the document reference, the text processing\r\n   * pipeline and document scoring parameters are all set on the\r\n   * builder before indexing.\r\n   *\r\n   * @constructor\r\n   * @property {string} _ref - Internal reference to the document reference field.\r\n   * @property {string[]} _fields - Internal reference to the document fields to index.\r\n   * @property {object} invertedIndex - The inverted index maps terms to document fields.\r\n   * @property {object} documentTermFrequencies - Keeps track of document term frequencies.\r\n   * @property {object} documentLengths - Keeps track of the length of documents added to the index.\r\n   * @property {lunr.tokenizer} tokenizer - Function for splitting strings into tokens for indexing.\r\n   * @property {lunr.Pipeline} pipeline - The pipeline performs text processing on tokens before indexing.\r\n   * @property {lunr.Pipeline} searchPipeline - A pipeline for processing search terms before querying the index.\r\n   * @property {number} documentCount - Keeps track of the total number of documents indexed.\r\n   * @property {number} _b - A parameter to control field length normalization, setting this to 0 disabled normalization, 1 fully normalizes field lengths, the default value is 0.75.\r\n   * @property {number} _k1 - A parameter to control how quickly an increase in term frequency results in term frequency saturation, the default value is 1.2.\r\n   * @property {number} termIndex - A counter incremented for each unique term, used to identify a terms position in the vector space.\r\n   * @property {array} metadataWhitelist - A list of metadata keys that have been whitelisted for entry in the index.\r\n   */\r\n  lunr.Builder = function () {\r\n    this._ref = \"id\"\r\n    this._fields = Object.create(null)\r\n    this._documents = Object.create(null)\r\n    this.invertedIndex = Object.create(null)\r\n    this.fieldTermFrequencies = {}\r\n    this.fieldLengths = {}\r\n    this.tokenizer = lunr.tokenizer\r\n    this.pipeline = new lunr.Pipeline\r\n    this.searchPipeline = new lunr.Pipeline\r\n    this.documentCount = 0\r\n    this._b = 0.75\r\n    this._k1 = 1.2\r\n    this.termIndex = 0\r\n    this.metadataWhitelist = []\r\n  }\r\n  \r\n  /**\r\n   * Sets the document field used as the document reference. Every document must have this field.\r\n   * The type of this field in the document should be a string, if it is not a string it will be\r\n   * coerced into a string by calling toString.\r\n   *\r\n   * The default ref is 'id'.\r\n   *\r\n   * The ref should _not_ be changed during indexing, it should be set before any documents are\r\n   * added to the index. Changing it during indexing can lead to inconsistent results.\r\n   *\r\n   * @param {string} ref - The name of the reference field in the document.\r\n   */\r\n  lunr.Builder.prototype.ref = function (ref) {\r\n    this._ref = ref\r\n  }\r\n  \r\n  /**\r\n   * A function that is used to extract a field from a document.\r\n   *\r\n   * Lunr expects a field to be at the top level of a document, if however the field\r\n   * is deeply nested within a document an extractor function can be used to extract\r\n   * the right field for indexing.\r\n   *\r\n   * @callback fieldExtractor\r\n   * @param {object} doc - The document being added to the index.\r\n   * @returns {?(string|object|object[])} obj - The object that will be indexed for this field.\r\n   * @example <caption>Extracting a nested field</caption>\r\n   * function (doc) { return doc.nested.field }\r\n   */\r\n  \r\n  /**\r\n   * Adds a field to the list of document fields that will be indexed. Every document being\r\n   * indexed should have this field. Null values for this field in indexed documents will\r\n   * not cause errors but will limit the chance of that document being retrieved by searches.\r\n   *\r\n   * All fields should be added before adding documents to the index. Adding fields after\r\n   * a document has been indexed will have no effect on already indexed documents.\r\n   *\r\n   * Fields can be boosted at build time. This allows terms within that field to have more\r\n   * importance when ranking search results. Use a field boost to specify that matches within\r\n   * one field are more important than other fields.\r\n   *\r\n   * @param {string} fieldName - The name of a field to index in all documents.\r\n   * @param {object} attributes - Optional attributes associated with this field.\r\n   * @param {number} [attributes.boost=1] - Boost applied to all terms within this field.\r\n   * @param {fieldExtractor} [attributes.extractor] - Function to extract a field from a document.\r\n   * @throws {RangeError} fieldName cannot contain unsupported characters '/'\r\n   */\r\n  lunr.Builder.prototype.field = function (fieldName, attributes) {\r\n    if (/\\//.test(fieldName)) {\r\n      throw new RangeError (\"Field '\" + fieldName + \"' contains illegal character '/'\")\r\n    }\r\n  \r\n    this._fields[fieldName] = attributes || {}\r\n  }\r\n  \r\n  /**\r\n   * A parameter to tune the amount of field length normalisation that is applied when\r\n   * calculating relevance scores. A value of 0 will completely disable any normalisation\r\n   * and a value of 1 will fully normalise field lengths. The default is 0.75. Values of b\r\n   * will be clamped to the range 0 - 1.\r\n   *\r\n   * @param {number} number - The value to set for this tuning parameter.\r\n   */\r\n  lunr.Builder.prototype.b = function (number) {\r\n    if (number < 0) {\r\n      this._b = 0\r\n    } else if (number > 1) {\r\n      this._b = 1\r\n    } else {\r\n      this._b = number\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * A parameter that controls the speed at which a rise in term frequency results in term\r\n   * frequency saturation. The default value is 1.2. Setting this to a higher value will give\r\n   * slower saturation levels, a lower value will result in quicker saturation.\r\n   *\r\n   * @param {number} number - The value to set for this tuning parameter.\r\n   */\r\n  lunr.Builder.prototype.k1 = function (number) {\r\n    this._k1 = number\r\n  }\r\n  \r\n  /**\r\n   * Adds a document to the index.\r\n   *\r\n   * Before adding fields to the index the index should have been fully setup, with the document\r\n   * ref and all fields to index already having been specified.\r\n   *\r\n   * The document must have a field name as specified by the ref (by default this is 'id') and\r\n   * it should have all fields defined for indexing, though null or undefined values will not\r\n   * cause errors.\r\n   *\r\n   * Entire documents can be boosted at build time. Applying a boost to a document indicates that\r\n   * this document should rank higher in search results than other documents.\r\n   *\r\n   * @param {object} doc - The document to add to the index.\r\n   * @param {object} attributes - Optional attributes associated with this document.\r\n   * @param {number} [attributes.boost=1] - Boost applied to all terms within this document.\r\n   */\r\n  lunr.Builder.prototype.add = function (doc, attributes) {\r\n    var docRef = doc[this._ref],\r\n        fields = Object.keys(this._fields)\r\n  \r\n    this._documents[docRef] = attributes || {}\r\n    this.documentCount += 1\r\n  \r\n    for (var i = 0; i < fields.length; i++) {\r\n      var fieldName = fields[i],\r\n          extractor = this._fields[fieldName].extractor,\r\n          field = extractor ? extractor(doc) : doc[fieldName],\r\n          tokens = this.tokenizer(field, {\r\n            fields: [fieldName]\r\n          }),\r\n          terms = this.pipeline.run(tokens),\r\n          fieldRef = new lunr.FieldRef (docRef, fieldName),\r\n          fieldTerms = Object.create(null)\r\n  \r\n      this.fieldTermFrequencies[fieldRef] = fieldTerms\r\n      this.fieldLengths[fieldRef] = 0\r\n  \r\n      // store the length of this field for this document\r\n      this.fieldLengths[fieldRef] += terms.length\r\n  \r\n      // calculate term frequencies for this field\r\n      for (var j = 0; j < terms.length; j++) {\r\n        var term = terms[j]\r\n  \r\n        if (fieldTerms[term] == undefined) {\r\n          fieldTerms[term] = 0\r\n        }\r\n  \r\n        fieldTerms[term] += 1\r\n  \r\n        // add to inverted index\r\n        // create an initial posting if one doesn't exist\r\n        if (this.invertedIndex[term] == undefined) {\r\n          var posting = Object.create(null)\r\n          posting[\"_index\"] = this.termIndex\r\n          this.termIndex += 1\r\n  \r\n          for (var k = 0; k < fields.length; k++) {\r\n            posting[fields[k]] = Object.create(null)\r\n          }\r\n  \r\n          this.invertedIndex[term] = posting\r\n        }\r\n  \r\n        // add an entry for this term/fieldName/docRef to the invertedIndex\r\n        if (this.invertedIndex[term][fieldName][docRef] == undefined) {\r\n          this.invertedIndex[term][fieldName][docRef] = Object.create(null)\r\n        }\r\n  \r\n        // store all whitelisted metadata about this token in the\r\n        // inverted index\r\n        for (var l = 0; l < this.metadataWhitelist.length; l++) {\r\n          var metadataKey = this.metadataWhitelist[l],\r\n              metadata = term.metadata[metadataKey]\r\n  \r\n          if (this.invertedIndex[term][fieldName][docRef][metadataKey] == undefined) {\r\n            this.invertedIndex[term][fieldName][docRef][metadataKey] = []\r\n          }\r\n  \r\n          this.invertedIndex[term][fieldName][docRef][metadataKey].push(metadata)\r\n        }\r\n      }\r\n  \r\n    }\r\n  }\r\n  \r\n  /**\r\n   * Calculates the average document length for this index\r\n   *\r\n   * @private\r\n   */\r\n  lunr.Builder.prototype.calculateAverageFieldLengths = function () {\r\n  \r\n    var fieldRefs = Object.keys(this.fieldLengths),\r\n        numberOfFields = fieldRefs.length,\r\n        accumulator = {},\r\n        documentsWithField = {}\r\n  \r\n    for (var i = 0; i < numberOfFields; i++) {\r\n      var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]),\r\n          field = fieldRef.fieldName\r\n  \r\n      documentsWithField[field] || (documentsWithField[field] = 0)\r\n      documentsWithField[field] += 1\r\n  \r\n      accumulator[field] || (accumulator[field] = 0)\r\n      accumulator[field] += this.fieldLengths[fieldRef]\r\n    }\r\n  \r\n    var fields = Object.keys(this._fields)\r\n  \r\n    for (var i = 0; i < fields.length; i++) {\r\n      var fieldName = fields[i]\r\n      accumulator[fieldName] = accumulator[fieldName] / documentsWithField[fieldName]\r\n    }\r\n  \r\n    this.averageFieldLength = accumulator\r\n  }\r\n  \r\n  /**\r\n   * Builds a vector space model of every document using lunr.Vector\r\n   *\r\n   * @private\r\n   */\r\n  lunr.Builder.prototype.createFieldVectors = function () {\r\n    var fieldVectors = {},\r\n        fieldRefs = Object.keys(this.fieldTermFrequencies),\r\n        fieldRefsLength = fieldRefs.length,\r\n        termIdfCache = Object.create(null)\r\n  \r\n    for (var i = 0; i < fieldRefsLength; i++) {\r\n      var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]),\r\n          fieldName = fieldRef.fieldName,\r\n          fieldLength = this.fieldLengths[fieldRef],\r\n          fieldVector = new lunr.Vector,\r\n          termFrequencies = this.fieldTermFrequencies[fieldRef],\r\n          terms = Object.keys(termFrequencies),\r\n          termsLength = terms.length\r\n  \r\n  \r\n      var fieldBoost = this._fields[fieldName].boost || 1,\r\n          docBoost = this._documents[fieldRef.docRef].boost || 1\r\n  \r\n      for (var j = 0; j < termsLength; j++) {\r\n        var term = terms[j],\r\n            tf = termFrequencies[term],\r\n            termIndex = this.invertedIndex[term]._index,\r\n            idf, score, scoreWithPrecision\r\n  \r\n        if (termIdfCache[term] === undefined) {\r\n          idf = lunr.idf(this.invertedIndex[term], this.documentCount)\r\n          termIdfCache[term] = idf\r\n        } else {\r\n          idf = termIdfCache[term]\r\n        }\r\n  \r\n        score = idf * ((this._k1 + 1) * tf) / (this._k1 * (1 - this._b + this._b * (fieldLength / this.averageFieldLength[fieldName])) + tf)\r\n        score *= fieldBoost\r\n        score *= docBoost\r\n        scoreWithPrecision = Math.round(score * 1000) / 1000\r\n        // Converts 1.23456789 to 1.234.\r\n        // Reducing the precision so that the vectors take up less\r\n        // space when serialised. Doing it now so that they behave\r\n        // the same before and after serialisation. Also, this is\r\n        // the fastest approach to reducing a number's precision in\r\n        // JavaScript.\r\n  \r\n        fieldVector.insert(termIndex, scoreWithPrecision)\r\n      }\r\n  \r\n      fieldVectors[fieldRef] = fieldVector\r\n    }\r\n  \r\n    this.fieldVectors = fieldVectors\r\n  }\r\n  \r\n  /**\r\n   * Creates a token set of all tokens in the index using lunr.TokenSet\r\n   *\r\n   * @private\r\n   */\r\n  lunr.Builder.prototype.createTokenSet = function () {\r\n    this.tokenSet = lunr.TokenSet.fromArray(\r\n      Object.keys(this.invertedIndex).sort()\r\n    )\r\n  }\r\n  \r\n  /**\r\n   * Builds the index, creating an instance of lunr.Index.\r\n   *\r\n   * This completes the indexing process and should only be called\r\n   * once all documents have been added to the index.\r\n   *\r\n   * @returns {lunr.Index}\r\n   */\r\n  lunr.Builder.prototype.build = function () {\r\n    this.calculateAverageFieldLengths()\r\n    this.createFieldVectors()\r\n    this.createTokenSet()\r\n  \r\n    return new lunr.Index({\r\n      invertedIndex: this.invertedIndex,\r\n      fieldVectors: this.fieldVectors,\r\n      tokenSet: this.tokenSet,\r\n      fields: Object.keys(this._fields),\r\n      pipeline: this.searchPipeline\r\n    })\r\n  }\r\n  \r\n  /**\r\n   * Applies a plugin to the index builder.\r\n   *\r\n   * A plugin is a function that is called with the index builder as its context.\r\n   * Plugins can be used to customise or extend the behaviour of the index\r\n   * in some way. A plugin is just a function, that encapsulated the custom\r\n   * behaviour that should be applied when building the index.\r\n   *\r\n   * The plugin function will be called with the index builder as its argument, additional\r\n   * arguments can also be passed when calling use. The function will be called\r\n   * with the index builder as its context.\r\n   *\r\n   * @param {Function} plugin The plugin to apply.\r\n   */\r\n  lunr.Builder.prototype.use = function (fn) {\r\n    var args = Array.prototype.slice.call(arguments, 1)\r\n    args.unshift(this)\r\n    fn.apply(this, args)\r\n  }\r\n  /**\r\n   * Contains and collects metadata about a matching document.\r\n   * A single instance of lunr.MatchData is returned as part of every\r\n   * lunr.Index~Result.\r\n   *\r\n   * @constructor\r\n   * @param {string} term - The term this match data is associated with\r\n   * @param {string} field - The field in which the term was found\r\n   * @param {object} metadata - The metadata recorded about this term in this field\r\n   * @property {object} metadata - A cloned collection of metadata associated with this document.\r\n   * @see {@link lunr.Index~Result}\r\n   */\r\n  lunr.MatchData = function (term, field, metadata) {\r\n    var clonedMetadata = Object.create(null),\r\n        metadataKeys = Object.keys(metadata || {})\r\n  \r\n    // Cloning the metadata to prevent the original\r\n    // being mutated during match data combination.\r\n    // Metadata is kept in an array within the inverted\r\n    // index so cloning the data can be done with\r\n    // Array#slice\r\n    for (var i = 0; i < metadataKeys.length; i++) {\r\n      var key = metadataKeys[i]\r\n      clonedMetadata[key] = metadata[key].slice()\r\n    }\r\n  \r\n    this.metadata = Object.create(null)\r\n  \r\n    if (term !== undefined) {\r\n      this.metadata[term] = Object.create(null)\r\n      this.metadata[term][field] = clonedMetadata\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * An instance of lunr.MatchData will be created for every term that matches a\r\n   * document. However only one instance is required in a lunr.Index~Result. This\r\n   * method combines metadata from another instance of lunr.MatchData with this\r\n   * objects metadata.\r\n   *\r\n   * @param {lunr.MatchData} otherMatchData - Another instance of match data to merge with this one.\r\n   * @see {@link lunr.Index~Result}\r\n   */\r\n  lunr.MatchData.prototype.combine = function (otherMatchData) {\r\n    var terms = Object.keys(otherMatchData.metadata)\r\n  \r\n    for (var i = 0; i < terms.length; i++) {\r\n      var term = terms[i],\r\n          fields = Object.keys(otherMatchData.metadata[term])\r\n  \r\n      if (this.metadata[term] == undefined) {\r\n        this.metadata[term] = Object.create(null)\r\n      }\r\n  \r\n      for (var j = 0; j < fields.length; j++) {\r\n        var field = fields[j],\r\n            keys = Object.keys(otherMatchData.metadata[term][field])\r\n  \r\n        if (this.metadata[term][field] == undefined) {\r\n          this.metadata[term][field] = Object.create(null)\r\n        }\r\n  \r\n        for (var k = 0; k < keys.length; k++) {\r\n          var key = keys[k]\r\n  \r\n          if (this.metadata[term][field][key] == undefined) {\r\n            this.metadata[term][field][key] = otherMatchData.metadata[term][field][key]\r\n          } else {\r\n            this.metadata[term][field][key] = this.metadata[term][field][key].concat(otherMatchData.metadata[term][field][key])\r\n          }\r\n  \r\n        }\r\n      }\r\n    }\r\n  }\r\n  \r\n  /**\r\n   * Add metadata for a term/field pair to this instance of match data.\r\n   *\r\n   * @param {string} term - The term this match data is associated with\r\n   * @param {string} field - The field in which the term was found\r\n   * @param {object} metadata - The metadata recorded about this term in this field\r\n   */\r\n  lunr.MatchData.prototype.add = function (term, field, metadata) {\r\n    if (!(term in this.metadata)) {\r\n      this.metadata[term] = Object.create(null)\r\n      this.metadata[term][field] = metadata\r\n      return\r\n    }\r\n  \r\n    if (!(field in this.metadata[term])) {\r\n      this.metadata[term][field] = metadata\r\n      return\r\n    }\r\n  \r\n    var metadataKeys = Object.keys(metadata)\r\n  \r\n    for (var i = 0; i < metadataKeys.length; i++) {\r\n      var key = metadataKeys[i]\r\n  \r\n      if (key in this.metadata[term][field]) {\r\n        this.metadata[term][field][key] = this.metadata[term][field][key].concat(metadata[key])\r\n      } else {\r\n        this.metadata[term][field][key] = metadata[key]\r\n      }\r\n    }\r\n  }\r\n  /**\r\n   * A lunr.Query provides a programmatic way of defining queries to be performed\r\n   * against a {@link lunr.Index}.\r\n   *\r\n   * Prefer constructing a lunr.Query using the {@link lunr.Index#query} method\r\n   * so the query object is pre-initialized with the right index fields.\r\n   *\r\n   * @constructor\r\n   * @property {lunr.Query~Clause[]} clauses - An array of query clauses.\r\n   * @property {string[]} allFields - An array of all available fields in a lunr.Index.\r\n   */\r\n  lunr.Query = function (allFields) {\r\n    this.clauses = []\r\n    this.allFields = allFields\r\n  }\r\n  \r\n  /**\r\n   * Constants for indicating what kind of automatic wildcard insertion will be used when constructing a query clause.\r\n   *\r\n   * This allows wildcards to be added to the beginning and end of a term without having to manually do any string\r\n   * concatenation.\r\n   *\r\n   * The wildcard constants can be bitwise combined to select both leading and trailing wildcards.\r\n   *\r\n   * @constant\r\n   * @default\r\n   * @property {number} wildcard.NONE - The term will have no wildcards inserted, this is the default behaviour\r\n   * @property {number} wildcard.LEADING - Prepend the term with a wildcard, unless a leading wildcard already exists\r\n   * @property {number} wildcard.TRAILING - Append a wildcard to the term, unless a trailing wildcard already exists\r\n   * @see lunr.Query~Clause\r\n   * @see lunr.Query#clause\r\n   * @see lunr.Query#term\r\n   * @example <caption>query term with trailing wildcard</caption>\r\n   * query.term('foo', { wildcard: lunr.Query.wildcard.TRAILING })\r\n   * @example <caption>query term with leading and trailing wildcard</caption>\r\n   * query.term('foo', {\r\n   *   wildcard: lunr.Query.wildcard.LEADING | lunr.Query.wildcard.TRAILING\r\n   * })\r\n   */\r\n  \r\n  lunr.Query.wildcard = new String (\"*\")\r\n  lunr.Query.wildcard.NONE = 0\r\n  lunr.Query.wildcard.LEADING = 1\r\n  lunr.Query.wildcard.TRAILING = 2\r\n  \r\n  /**\r\n   * Constants for indicating what kind of presence a term must have in matching documents.\r\n   *\r\n   * @constant\r\n   * @enum {number}\r\n   * @see lunr.Query~Clause\r\n   * @see lunr.Query#clause\r\n   * @see lunr.Query#term\r\n   * @example <caption>query term with required presence</caption>\r\n   * query.term('foo', { presence: lunr.Query.presence.REQUIRED })\r\n   */\r\n  lunr.Query.presence = {\r\n    /**\r\n     * Term's presence in a document is optional, this is the default value.\r\n     */\r\n    OPTIONAL: 1,\r\n  \r\n    /**\r\n     * Term's presence in a document is required, documents that do not contain\r\n     * this term will not be returned.\r\n     */\r\n    REQUIRED: 2,\r\n  \r\n    /**\r\n     * Term's presence in a document is prohibited, documents that do contain\r\n     * this term will not be returned.\r\n     */\r\n    PROHIBITED: 3\r\n  }\r\n  \r\n  /**\r\n   * A single clause in a {@link lunr.Query} contains a term and details on how to\r\n   * match that term against a {@link lunr.Index}.\r\n   *\r\n   * @typedef {Object} lunr.Query~Clause\r\n   * @property {string[]} fields - The fields in an index this clause should be matched against.\r\n   * @property {number} [boost=1] - Any boost that should be applied when matching this clause.\r\n   * @property {number} [editDistance] - Whether the term should have fuzzy matching applied, and how fuzzy the match should be.\r\n   * @property {boolean} [usePipeline] - Whether the term should be passed through the search pipeline.\r\n   * @property {number} [wildcard=lunr.Query.wildcard.NONE] - Whether the term should have wildcards appended or prepended.\r\n   * @property {number} [presence=lunr.Query.presence.OPTIONAL] - The terms presence in any matching documents.\r\n   */\r\n  \r\n  /**\r\n   * Adds a {@link lunr.Query~Clause} to this query.\r\n   *\r\n   * Unless the clause contains the fields to be matched all fields will be matched. In addition\r\n   * a default boost of 1 is applied to the clause.\r\n   *\r\n   * @param {lunr.Query~Clause} clause - The clause to add to this query.\r\n   * @see lunr.Query~Clause\r\n   * @returns {lunr.Query}\r\n   */\r\n  lunr.Query.prototype.clause = function (clause) {\r\n    if (!('fields' in clause)) {\r\n      clause.fields = this.allFields\r\n    }\r\n  \r\n    if (!('boost' in clause)) {\r\n      clause.boost = 1\r\n    }\r\n  \r\n    if (!('usePipeline' in clause)) {\r\n      clause.usePipeline = true\r\n    }\r\n  \r\n    if (!('wildcard' in clause)) {\r\n      clause.wildcard = lunr.Query.wildcard.NONE\r\n    }\r\n  \r\n    if ((clause.wildcard & lunr.Query.wildcard.LEADING) && (clause.term.charAt(0) != lunr.Query.wildcard)) {\r\n      clause.term = \"*\" + clause.term\r\n    }\r\n  \r\n    if ((clause.wildcard & lunr.Query.wildcard.TRAILING) && (clause.term.slice(-1) != lunr.Query.wildcard)) {\r\n      clause.term = \"\" + clause.term + \"*\"\r\n    }\r\n  \r\n    if (!('presence' in clause)) {\r\n      clause.presence = lunr.Query.presence.OPTIONAL\r\n    }\r\n  \r\n    this.clauses.push(clause)\r\n  \r\n    return this\r\n  }\r\n  \r\n  /**\r\n   * A negated query is one in which every clause has a presence of\r\n   * prohibited. These queries require some special processing to return\r\n   * the expected results.\r\n   *\r\n   * @returns boolean\r\n   */\r\n  lunr.Query.prototype.isNegated = function () {\r\n    for (var i = 0; i < this.clauses.length; i++) {\r\n      if (this.clauses[i].presence != lunr.Query.presence.PROHIBITED) {\r\n        return false\r\n      }\r\n    }\r\n  \r\n    return true\r\n  }\r\n  \r\n  /**\r\n   * Adds a term to the current query, under the covers this will create a {@link lunr.Query~Clause}\r\n   * to the list of clauses that make up this query.\r\n   *\r\n   * The term is used as is, i.e. no tokenization will be performed by this method. Instead conversion\r\n   * to a token or token-like string should be done before calling this method.\r\n   *\r\n   * The term will be converted to a string by calling `toString`. Multiple terms can be passed as an\r\n   * array, each term in the array will share the same options.\r\n   *\r\n   * @param {object|object[]} term - The term(s) to add to the query.\r\n   * @param {object} [options] - Any additional properties to add to the query clause.\r\n   * @returns {lunr.Query}\r\n   * @see lunr.Query#clause\r\n   * @see lunr.Query~Clause\r\n   * @example <caption>adding a single term to a query</caption>\r\n   * query.term(\"foo\")\r\n   * @example <caption>adding a single term to a query and specifying search fields, term boost and automatic trailing wildcard</caption>\r\n   * query.term(\"foo\", {\r\n   *   fields: [\"title\"],\r\n   *   boost: 10,\r\n   *   wildcard: lunr.Query.wildcard.TRAILING\r\n   * })\r\n   * @example <caption>using lunr.tokenizer to convert a string to tokens before using them as terms</caption>\r\n   * query.term(lunr.tokenizer(\"foo bar\"))\r\n   */\r\n  lunr.Query.prototype.term = function (term, options) {\r\n    if (Array.isArray(term)) {\r\n      term.forEach(function (t) { this.term(t, lunr.utils.clone(options)) }, this)\r\n      return this\r\n    }\r\n  \r\n    var clause = options || {}\r\n    clause.term = term.toString()\r\n  \r\n    this.clause(clause)\r\n  \r\n    return this\r\n  }\r\n  lunr.QueryParseError = function (message, start, end) {\r\n    this.name = \"QueryParseError\"\r\n    this.message = message\r\n    this.start = start\r\n    this.end = end\r\n  }\r\n  \r\n  lunr.QueryParseError.prototype = new Error\r\n  lunr.QueryLexer = function (str) {\r\n    this.lexemes = []\r\n    this.str = str\r\n    this.length = str.length\r\n    this.pos = 0\r\n    this.start = 0\r\n    this.escapeCharPositions = []\r\n  }\r\n  \r\n  lunr.QueryLexer.prototype.run = function () {\r\n    var state = lunr.QueryLexer.lexText\r\n  \r\n    while (state) {\r\n      state = state(this)\r\n    }\r\n  }\r\n  \r\n  lunr.QueryLexer.prototype.sliceString = function () {\r\n    var subSlices = [],\r\n        sliceStart = this.start,\r\n        sliceEnd = this.pos\r\n  \r\n    for (var i = 0; i < this.escapeCharPositions.length; i++) {\r\n      sliceEnd = this.escapeCharPositions[i]\r\n      subSlices.push(this.str.slice(sliceStart, sliceEnd))\r\n      sliceStart = sliceEnd + 1\r\n    }\r\n  \r\n    subSlices.push(this.str.slice(sliceStart, this.pos))\r\n    this.escapeCharPositions.length = 0\r\n  \r\n    return subSlices.join('')\r\n  }\r\n  \r\n  lunr.QueryLexer.prototype.emit = function (type) {\r\n    this.lexemes.push({\r\n      type: type,\r\n      str: this.sliceString(),\r\n      start: this.start,\r\n      end: this.pos\r\n    })\r\n  \r\n    this.start = this.pos\r\n  }\r\n  \r\n  lunr.QueryLexer.prototype.escapeCharacter = function () {\r\n    this.escapeCharPositions.push(this.pos - 1)\r\n    this.pos += 1\r\n  }\r\n  \r\n  lunr.QueryLexer.prototype.next = function () {\r\n    if (this.pos >= this.length) {\r\n      return lunr.QueryLexer.EOS\r\n    }\r\n  \r\n    var char = this.str.charAt(this.pos)\r\n    this.pos += 1\r\n    return char\r\n  }\r\n  \r\n  lunr.QueryLexer.prototype.width = function () {\r\n    return this.pos - this.start\r\n  }\r\n  \r\n  lunr.QueryLexer.prototype.ignore = function () {\r\n    if (this.start == this.pos) {\r\n      this.pos += 1\r\n    }\r\n  \r\n    this.start = this.pos\r\n  }\r\n  \r\n  lunr.QueryLexer.prototype.backup = function () {\r\n    this.pos -= 1\r\n  }\r\n  \r\n  lunr.QueryLexer.prototype.acceptDigitRun = function () {\r\n    var char, charCode\r\n  \r\n    do {\r\n      char = this.next()\r\n      charCode = char.charCodeAt(0)\r\n    } while (charCode > 47 && charCode < 58)\r\n  \r\n    if (char != lunr.QueryLexer.EOS) {\r\n      this.backup()\r\n    }\r\n  }\r\n  \r\n  lunr.QueryLexer.prototype.more = function () {\r\n    return this.pos < this.length\r\n  }\r\n  \r\n  lunr.QueryLexer.EOS = 'EOS'\r\n  lunr.QueryLexer.FIELD = 'FIELD'\r\n  lunr.QueryLexer.TERM = 'TERM'\r\n  lunr.QueryLexer.EDIT_DISTANCE = 'EDIT_DISTANCE'\r\n  lunr.QueryLexer.BOOST = 'BOOST'\r\n  lunr.QueryLexer.PRESENCE = 'PRESENCE'\r\n  \r\n  lunr.QueryLexer.lexField = function (lexer) {\r\n    lexer.backup()\r\n    lexer.emit(lunr.QueryLexer.FIELD)\r\n    lexer.ignore()\r\n    return lunr.QueryLexer.lexText\r\n  }\r\n  \r\n  lunr.QueryLexer.lexTerm = function (lexer) {\r\n    if (lexer.width() > 1) {\r\n      lexer.backup()\r\n      lexer.emit(lunr.QueryLexer.TERM)\r\n    }\r\n  \r\n    lexer.ignore()\r\n  \r\n    if (lexer.more()) {\r\n      return lunr.QueryLexer.lexText\r\n    }\r\n  }\r\n  \r\n  lunr.QueryLexer.lexEditDistance = function (lexer) {\r\n    lexer.ignore()\r\n    lexer.acceptDigitRun()\r\n    lexer.emit(lunr.QueryLexer.EDIT_DISTANCE)\r\n    return lunr.QueryLexer.lexText\r\n  }\r\n  \r\n  lunr.QueryLexer.lexBoost = function (lexer) {\r\n    lexer.ignore()\r\n    lexer.acceptDigitRun()\r\n    lexer.emit(lunr.QueryLexer.BOOST)\r\n    return lunr.QueryLexer.lexText\r\n  }\r\n  \r\n  lunr.QueryLexer.lexEOS = function (lexer) {\r\n    if (lexer.width() > 0) {\r\n      lexer.emit(lunr.QueryLexer.TERM)\r\n    }\r\n  }\r\n  \r\n  // This matches the separator used when tokenising fields\r\n  // within a document. These should match otherwise it is\r\n  // not possible to search for some tokens within a document.\r\n  //\r\n  // It is possible for the user to change the separator on the\r\n  // tokenizer so it _might_ clash with any other of the special\r\n  // characters already used within the search string, e.g. :.\r\n  //\r\n  // This means that it is possible to change the separator in\r\n  // such a way that makes some words unsearchable using a search\r\n  // string.\r\n  lunr.QueryLexer.termSeparator = lunr.tokenizer.separator\r\n  \r\n  lunr.QueryLexer.lexText = function (lexer) {\r\n    while (true) {\r\n      var char = lexer.next()\r\n  \r\n      if (char == lunr.QueryLexer.EOS) {\r\n        return lunr.QueryLexer.lexEOS\r\n      }\r\n  \r\n      // Escape character is '\\'\r\n      if (char.charCodeAt(0) == 92) {\r\n        lexer.escapeCharacter()\r\n        continue\r\n      }\r\n  \r\n      if (char == \":\") {\r\n        return lunr.QueryLexer.lexField\r\n      }\r\n  \r\n      if (char == \"~\") {\r\n        lexer.backup()\r\n        if (lexer.width() > 0) {\r\n          lexer.emit(lunr.QueryLexer.TERM)\r\n        }\r\n        return lunr.QueryLexer.lexEditDistance\r\n      }\r\n  \r\n      if (char == \"^\") {\r\n        lexer.backup()\r\n        if (lexer.width() > 0) {\r\n          lexer.emit(lunr.QueryLexer.TERM)\r\n        }\r\n        return lunr.QueryLexer.lexBoost\r\n      }\r\n  \r\n      // \"+\" indicates term presence is required\r\n      // checking for length to ensure that only\r\n      // leading \"+\" are considered\r\n      if (char == \"+\" && lexer.width() === 1) {\r\n        lexer.emit(lunr.QueryLexer.PRESENCE)\r\n        return lunr.QueryLexer.lexText\r\n      }\r\n  \r\n      // \"-\" indicates term presence is prohibited\r\n      // checking for length to ensure that only\r\n      // leading \"-\" are considered\r\n      if (char == \"-\" && lexer.width() === 1) {\r\n        lexer.emit(lunr.QueryLexer.PRESENCE)\r\n        return lunr.QueryLexer.lexText\r\n      }\r\n  \r\n      if (char.match(lunr.QueryLexer.termSeparator)) {\r\n        return lunr.QueryLexer.lexTerm\r\n      }\r\n    }\r\n  }\r\n  \r\n  lunr.QueryParser = function (str, query) {\r\n    this.lexer = new lunr.QueryLexer (str)\r\n    this.query = query\r\n    this.currentClause = {}\r\n    this.lexemeIdx = 0\r\n  }\r\n  \r\n  lunr.QueryParser.prototype.parse = function () {\r\n    this.lexer.run()\r\n    this.lexemes = this.lexer.lexemes\r\n  \r\n    var state = lunr.QueryParser.parseClause\r\n  \r\n    while (state) {\r\n      state = state(this)\r\n    }\r\n  \r\n    return this.query\r\n  }\r\n  \r\n  lunr.QueryParser.prototype.peekLexeme = function () {\r\n    return this.lexemes[this.lexemeIdx]\r\n  }\r\n  \r\n  lunr.QueryParser.prototype.consumeLexeme = function () {\r\n    var lexeme = this.peekLexeme()\r\n    this.lexemeIdx += 1\r\n    return lexeme\r\n  }\r\n  \r\n  lunr.QueryParser.prototype.nextClause = function () {\r\n    var completedClause = this.currentClause\r\n    this.query.clause(completedClause)\r\n    this.currentClause = {}\r\n  }\r\n  \r\n  lunr.QueryParser.parseClause = function (parser) {\r\n    var lexeme = parser.peekLexeme()\r\n  \r\n    if (lexeme == undefined) {\r\n      return\r\n    }\r\n  \r\n    switch (lexeme.type) {\r\n      case lunr.QueryLexer.PRESENCE:\r\n        return lunr.QueryParser.parsePresence\r\n      case lunr.QueryLexer.FIELD:\r\n        return lunr.QueryParser.parseField\r\n      case lunr.QueryLexer.TERM:\r\n        return lunr.QueryParser.parseTerm\r\n      default:\r\n        var errorMessage = \"expected either a field or a term, found \" + lexeme.type\r\n  \r\n        if (lexeme.str.length >= 1) {\r\n          errorMessage += \" with value '\" + lexeme.str + \"'\"\r\n        }\r\n  \r\n        throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\r\n    }\r\n  }\r\n  \r\n  lunr.QueryParser.parsePresence = function (parser) {\r\n    var lexeme = parser.consumeLexeme()\r\n  \r\n    if (lexeme == undefined) {\r\n      return\r\n    }\r\n  \r\n    switch (lexeme.str) {\r\n      case \"-\":\r\n        parser.currentClause.presence = lunr.Query.presence.PROHIBITED\r\n        break\r\n      case \"+\":\r\n        parser.currentClause.presence = lunr.Query.presence.REQUIRED\r\n        break\r\n      default:\r\n        var errorMessage = \"unrecognised presence operator'\" + lexeme.str + \"'\"\r\n        throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\r\n    }\r\n  \r\n    var nextLexeme = parser.peekLexeme()\r\n  \r\n    if (nextLexeme == undefined) {\r\n      var errorMessage = \"expecting term or field, found nothing\"\r\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\r\n    }\r\n  \r\n    switch (nextLexeme.type) {\r\n      case lunr.QueryLexer.FIELD:\r\n        return lunr.QueryParser.parseField\r\n      case lunr.QueryLexer.TERM:\r\n        return lunr.QueryParser.parseTerm\r\n      default:\r\n        var errorMessage = \"expecting term or field, found '\" + nextLexeme.type + \"'\"\r\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\r\n    }\r\n  }\r\n  \r\n  lunr.QueryParser.parseField = function (parser) {\r\n    var lexeme = parser.consumeLexeme()\r\n  \r\n    if (lexeme == undefined) {\r\n      return\r\n    }\r\n  \r\n    if (parser.query.allFields.indexOf(lexeme.str) == -1) {\r\n      var possibleFields = parser.query.allFields.map(function (f) { return \"'\" + f + \"'\" }).join(', '),\r\n          errorMessage = \"unrecognised field '\" + lexeme.str + \"', possible fields: \" + possibleFields\r\n  \r\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\r\n    }\r\n  \r\n    parser.currentClause.fields = [lexeme.str]\r\n  \r\n    var nextLexeme = parser.peekLexeme()\r\n  \r\n    if (nextLexeme == undefined) {\r\n      var errorMessage = \"expecting term, found nothing\"\r\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\r\n    }\r\n  \r\n    switch (nextLexeme.type) {\r\n      case lunr.QueryLexer.TERM:\r\n        return lunr.QueryParser.parseTerm\r\n      default:\r\n        var errorMessage = \"expecting term, found '\" + nextLexeme.type + \"'\"\r\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\r\n    }\r\n  }\r\n  \r\n  lunr.QueryParser.parseTerm = function (parser) {\r\n    var lexeme = parser.consumeLexeme()\r\n  \r\n    if (lexeme == undefined) {\r\n      return\r\n    }\r\n  \r\n    parser.currentClause.term = lexeme.str.toLowerCase()\r\n  \r\n    if (lexeme.str.indexOf(\"*\") != -1) {\r\n      parser.currentClause.usePipeline = false\r\n    }\r\n  \r\n    var nextLexeme = parser.peekLexeme()\r\n  \r\n    if (nextLexeme == undefined) {\r\n      parser.nextClause()\r\n      return\r\n    }\r\n  \r\n    switch (nextLexeme.type) {\r\n      case lunr.QueryLexer.TERM:\r\n        parser.nextClause()\r\n        return lunr.QueryParser.parseTerm\r\n      case lunr.QueryLexer.FIELD:\r\n        parser.nextClause()\r\n        return lunr.QueryParser.parseField\r\n      case lunr.QueryLexer.EDIT_DISTANCE:\r\n        return lunr.QueryParser.parseEditDistance\r\n      case lunr.QueryLexer.BOOST:\r\n        return lunr.QueryParser.parseBoost\r\n      case lunr.QueryLexer.PRESENCE:\r\n        parser.nextClause()\r\n        return lunr.QueryParser.parsePresence\r\n      default:\r\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\r\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\r\n    }\r\n  }\r\n  \r\n  lunr.QueryParser.parseEditDistance = function (parser) {\r\n    var lexeme = parser.consumeLexeme()\r\n  \r\n    if (lexeme == undefined) {\r\n      return\r\n    }\r\n  \r\n    var editDistance = parseInt(lexeme.str, 10)\r\n  \r\n    if (isNaN(editDistance)) {\r\n      var errorMessage = \"edit distance must be numeric\"\r\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\r\n    }\r\n  \r\n    parser.currentClause.editDistance = editDistance\r\n  \r\n    var nextLexeme = parser.peekLexeme()\r\n  \r\n    if (nextLexeme == undefined) {\r\n      parser.nextClause()\r\n      return\r\n    }\r\n  \r\n    switch (nextLexeme.type) {\r\n      case lunr.QueryLexer.TERM:\r\n        parser.nextClause()\r\n        return lunr.QueryParser.parseTerm\r\n      case lunr.QueryLexer.FIELD:\r\n        parser.nextClause()\r\n        return lunr.QueryParser.parseField\r\n      case lunr.QueryLexer.EDIT_DISTANCE:\r\n        return lunr.QueryParser.parseEditDistance\r\n      case lunr.QueryLexer.BOOST:\r\n        return lunr.QueryParser.parseBoost\r\n      case lunr.QueryLexer.PRESENCE:\r\n        parser.nextClause()\r\n        return lunr.QueryParser.parsePresence\r\n      default:\r\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\r\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\r\n    }\r\n  }\r\n  \r\n  lunr.QueryParser.parseBoost = function (parser) {\r\n    var lexeme = parser.consumeLexeme()\r\n  \r\n    if (lexeme == undefined) {\r\n      return\r\n    }\r\n  \r\n    var boost = parseInt(lexeme.str, 10)\r\n  \r\n    if (isNaN(boost)) {\r\n      var errorMessage = \"boost must be numeric\"\r\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\r\n    }\r\n  \r\n    parser.currentClause.boost = boost\r\n  \r\n    var nextLexeme = parser.peekLexeme()\r\n  \r\n    if (nextLexeme == undefined) {\r\n      parser.nextClause()\r\n      return\r\n    }\r\n  \r\n    switch (nextLexeme.type) {\r\n      case lunr.QueryLexer.TERM:\r\n        parser.nextClause()\r\n        return lunr.QueryParser.parseTerm\r\n      case lunr.QueryLexer.FIELD:\r\n        parser.nextClause()\r\n        return lunr.QueryParser.parseField\r\n      case lunr.QueryLexer.EDIT_DISTANCE:\r\n        return lunr.QueryParser.parseEditDistance\r\n      case lunr.QueryLexer.BOOST:\r\n        return lunr.QueryParser.parseBoost\r\n      case lunr.QueryLexer.PRESENCE:\r\n        parser.nextClause()\r\n        return lunr.QueryParser.parsePresence\r\n      default:\r\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\r\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\r\n    }\r\n  }\r\n  \r\n    /**\r\n     * export the module via AMD, CommonJS or as a browser global\r\n     * Export code from https://github.com/umdjs/umd/blob/master/returnExports.js\r\n     */\r\n    ;(function (root, factory) {\r\n      if (typeof define === 'function' && define.amd) {\r\n        // AMD. Register as an anonymous module.\r\n        define(factory)\r\n      } else if (typeof exports === 'object') {\r\n        /**\r\n         * Node. Does not work with strict CommonJS, but\r\n         * only CommonJS-like enviroments that support module.exports,\r\n         * like Node.\r\n         */\r\n        module.exports = factory()\r\n      } else {\r\n        // Browser globals (root is window)\r\n        root.lunr = factory()\r\n      }\r\n    }(this, function () {\r\n      /**\r\n       * Just return a value to define the module export.\r\n       * This example returns an object, but the module\r\n       * can return a function as the exported value.\r\n       */\r\n      return lunr\r\n    }))\r\n  })();","document.addEventListener('DOMContentLoaded', function () {\r\n  var searchButton = document.querySelector('.mdc-icon-button.search')\r\n  var searchCancelButton = document.querySelector('.mdc-icon-button.search-arrow-back')\r\n  var searchClearButton = document.querySelector('.mdc-icon-button.search-clear-query')\r\n\r\n  function clearSearch() {\r\n    var searchInput = document.getElementById('search-input')\r\n    searchInput.value = '';\r\n    searchInput.dispatchEvent(new KeyboardEvent('keydown')); // trigger rerender of results\r\n  }\r\n\r\n  function enterOrSpacebarPressed(e) {\r\n    // Need both, 'keyCode' and 'which' to work in all browsers.\r\n    var code = e.keyCode || e.which;\r\n    var enterKey = 13;\r\n    var spaceKey = 32;\r\n\r\n    return (code === enterKey || code === spaceKey);\r\n  }\r\n\r\n  function toggleSearch() {\r\n    var mainContainer = document.querySelector('main')\r\n    var navContainer = document.querySelector('div.nav-container')\r\n    var searchResult = document.querySelector('.search-result-dropdown-menu')\r\n    var toolbarContainer = document.querySelector('.toolbar')\r\n    if(searchResult.classList.contains('hide')){\r\n      searchResult.classList.remove('hide')\r\n      mainContainer.classList.add('hide')\r\n      navContainer.classList.add('hide')\r\n      toolbarContainer.classList.add('hide')\r\n    } else{\r\n      searchResult.classList.add('hide')\r\n      mainContainer.classList.remove('hide')\r\n\r\n      // Toolbar should stay hidden on desktop and navbar should stay hidden on mobile.\r\n      if (window.innerWidth > 1024) {\r\n        navContainer.classList.remove('hide')\r\n      } else {\r\n        toolbarContainer.classList.remove('hide')\r\n      }\r\n    }\r\n\r\n    var regularTopBar = document.querySelector('.mdc-top-app-bar__row')\r\n    var searchTopBar = document.querySelector('.mdc-top-app-bar__row.sdp-top-app-bar__search')\r\n    if(regularTopBar.classList.contains('hide')){\r\n      regularTopBar.classList.remove('hide')\r\n      searchTopBar.classList.add('hide')\r\n    } else{\r\n      regularTopBar.classList.add('hide')\r\n      searchTopBar.classList.remove('hide')\r\n    }\r\n  }\r\n\r\n  // Add event listeners to search icon\r\n  searchButton.addEventListener('click', toggleSearch)\r\n  searchButton.addEventListener('keypress', function (e) {\r\n    if (enterOrSpacebarPressed(e)) {\r\n      toggleSearch()\r\n    }\r\n  })\r\n  if ('ontouchstart' in window) {\r\n    searchButton.addEventListener('ontouchstart', toggleSearch)\r\n  }\r\n\r\n  // Add event listeners to search back/cancel icon\r\n  searchCancelButton.addEventListener('click', toggleSearch)\r\n  searchCancelButton.addEventListener('keypress', function (e) {\r\n    if (enterOrSpacebarPressed(e)) {\r\n      toggleSearch()\r\n    }\r\n  })\r\n  if ('ontouchstart' in window) {\r\n    searchCancelButton.addEventListener('ontouchstart', toggleSearch)\r\n  }\r\n\r\n  // Add event listeners to clear search button\r\n  searchClearButton.addEventListener('click', clearSearch)\r\n  searchClearButton.addEventListener('keypress', function (e) {\r\n    if (enterOrSpacebarPressed(e)) {\r\n      clearSearch()\r\n    }\r\n  })\r\n  if ('ontouchstart' in window) {\r\n    searchClearButton.addEventListener('ontouchstart', clearSearch)\r\n  }\r\n});\r\n\r\n\r\n/* eslint-env browser */\r\nwindow.antoraLunr = (function (lunr) {\r\n  var searchInput = document.getElementById('search-input')\r\n  var searchResult = document.createElement('div')\r\n  var body = document.querySelector('.body')\r\n  searchResult.classList.add('search-result-dropdown-menu')\r\n  searchResult.classList.add('hide')\r\n  body.insertBefore(searchResult, body.firstChild)\r\n\r\n  function highlightText (doc, position) {\r\n    var hits = []\r\n    var start = position[0]\r\n    var length = position[1]\r\n\r\n    var text = doc.text\r\n    var highlightSpan = document.createElement('span')\r\n    highlightSpan.classList.add('search-result-highlight')\r\n    highlightSpan.innerText = text.substr(start, length)\r\n\r\n    var end = start + length\r\n    var textEnd = text.length - 1\r\n    var contextOffset = 15\r\n    var contextAfter = end + contextOffset > textEnd ? textEnd : end + contextOffset\r\n    var contextBefore = start - contextOffset < 0 ? 0 : start - contextOffset\r\n    if (start === 0 && end === textEnd) {\r\n      hits.push(highlightSpan)\r\n    } else if (start === 0) {\r\n      hits.push(highlightSpan)\r\n      hits.push(document.createTextNode(text.substr(end, contextAfter)))\r\n    } else if (end === textEnd) {\r\n      hits.push(document.createTextNode(text.substr(0, start)))\r\n      hits.push(highlightSpan)\r\n    } else {\r\n      hits.push(document.createTextNode('...' + text.substr(contextBefore, start - contextBefore)))\r\n      hits.push(highlightSpan)\r\n      hits.push(document.createTextNode(text.substr(end, contextAfter - end) + '...'))\r\n    }\r\n    return hits\r\n  }\r\n\r\n  function highlightTitle (hash, doc, position) {\r\n    var hits = []\r\n    var start = position[0]\r\n    var length = position[1]\r\n\r\n    var highlightSpan = document.createElement('span')\r\n    highlightSpan.classList.add('search-result-highlight')\r\n    var title\r\n    if (hash) {\r\n      title = doc.titles.filter(function (item) {\r\n        return item.id === hash\r\n      })[0].text\r\n    } else {\r\n      title = doc.title\r\n    }\r\n    highlightSpan.innerText = title.substr(start, length)\r\n\r\n    var end = start + length\r\n    var titleEnd = title.length - 1\r\n    if (start === 0 && end === titleEnd) {\r\n      hits.push(highlightSpan)\r\n    } else if (start === 0) {\r\n      hits.push(highlightSpan)\r\n      hits.push(document.createTextNode(title.substr(length, titleEnd)))\r\n    } else if (end === titleEnd) {\r\n      hits.push(document.createTextNode(title.substr(0, start)))\r\n      hits.push(highlightSpan)\r\n    } else {\r\n      hits.push(document.createTextNode(title.substr(0, start)))\r\n      hits.push(highlightSpan)\r\n      hits.push(document.createTextNode(title.substr(end, titleEnd)))\r\n    }\r\n    return hits\r\n  }\r\n\r\n  function highlightHit (metadata, hash, doc) {\r\n    var hits = []\r\n    for (var token in metadata) {\r\n      var fields = metadata[token]\r\n      for (var field in fields) {\r\n        var positions = fields[field]\r\n        if (positions.position) {\r\n          var position = positions.position[0] // only higlight the first match\r\n          if (field === 'title') {\r\n            hits = highlightTitle(hash, doc, position)\r\n          } else if (field === 'text') {\r\n            hits = highlightText(doc, position)\r\n          }\r\n        }\r\n      }\r\n    }\r\n    return hits\r\n  }\r\n\r\n  function createSearchResult(result, store, searchResultDataset) {\r\n    result.forEach(function (item) {\r\n      var url = item.ref\r\n      var hash\r\n      if (url.includes('#')) {\r\n        hash = url.substring(url.indexOf('#') + 1)\r\n        url = url.replace('#' + hash, '')\r\n      }\r\n      var doc = store[url]\r\n      var metadata = item.matchData.metadata\r\n      var hits = highlightHit(metadata, hash, doc)\r\n      searchResultDataset.appendChild(createSearchResultItem(doc, item, hits))\r\n    })\r\n  }\r\n\r\n  function createSearchResultItem (doc, item, hits) {\r\n    var documentTitle = document.createElement('div')\r\n    documentTitle.classList.add('search-result-document-title')\r\n    documentTitle.innerText = doc.title\r\n    var documentHit = document.createElement('div')\r\n    documentHit.classList.add('search-result-document-hit')\r\n    var documentHitLink = document.createElement('a')\r\n    documentHitLink.href = item.ref\r\n    documentHit.appendChild(documentHitLink)\r\n    hits.forEach(function (hit) {\r\n      documentHitLink.appendChild(hit)\r\n    })\r\n    var searchResultItem = document.createElement('div')\r\n    searchResultItem.classList.add('search-result-item')\r\n    searchResultItem.appendChild(documentTitle)\r\n    searchResultItem.appendChild(documentHit)\r\n    return searchResultItem\r\n  }\r\n\r\n  function createNoResult (text) {\r\n    var searchResultItem = document.createElement('div')\r\n    searchResultItem.classList.add('search-result-item')\r\n    var documentHit = document.createElement('div')\r\n    documentHit.classList.add('search-result-document-hit')\r\n    var message = document.createElement('strong')\r\n    message.innerText = 'No results found for query \"' + text + '\"'\r\n    documentHit.appendChild(message)\r\n    searchResultItem.appendChild(documentHit)\r\n    return searchResultItem\r\n  }\r\n\r\n  function search (index, text) {\r\n    // execute an exact match search\r\n    var result = index.search(text)\r\n    if (result.length > 0) {\r\n      return result\r\n    }\r\n    // no result, use a begins with search\r\n    result = index.search(text + '*')\r\n    if (result.length > 0) {\r\n      return result\r\n    }\r\n    // no result, use a contains search\r\n    result = index.search('*' + text + '*')\r\n    return result\r\n  }\r\n\r\n  function searchIndex (index, store, text) {\r\n    // reset search result\r\n    while (searchResult.firstChild) {\r\n      searchResult.removeChild(searchResult.firstChild)\r\n    }\r\n    if (text.trim() === '') {\r\n      return\r\n    }\r\n    var result = search(index, text)\r\n    var searchResultDataset = document.createElement('div')\r\n    searchResultDataset.classList.add('search-result-dataset')\r\n    searchResult.appendChild(searchResultDataset)\r\n    if (result.length > 0) {\r\n      createSearchResult(result, store, searchResultDataset)\r\n    } else {\r\n      searchResultDataset.appendChild(createNoResult(text))\r\n    }\r\n  }\r\n\r\n  function debounce (func, wait, immediate) {\r\n    var timeout\r\n    return function () {\r\n      var context = this\r\n      var args = arguments\r\n      var later = function () {\r\n        timeout = null\r\n        if (!immediate) func.apply(context, args)\r\n      }\r\n      var callNow = immediate && !timeout\r\n      clearTimeout(timeout)\r\n      timeout = setTimeout(later, wait)\r\n      if (callNow) func.apply(context, args)\r\n    }\r\n  }\r\n\r\n  function init (data) {\r\n    var index = Object.assign({index: lunr.Index.load(data.index), store: data.store})\r\n    var search = debounce(function () {\r\n      searchIndex(index.index, index.store, searchInput.value)\r\n    }, 100)\r\n    // TODO listen to blur, focus and input events\r\n    searchInput.addEventListener('keydown', search)\r\n  }\r\n\r\n  return {\r\n    init: init,\r\n  }\r\n})(window.lunr)\r\n"]}